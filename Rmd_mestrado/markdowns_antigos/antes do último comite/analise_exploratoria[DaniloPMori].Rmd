---
title: "Análise dos Dados"
author: ''
date: ''
output: pdf_document
---
```{r global_options, include=FALSE}
knitr::opts_chunk$set(
                      fig.width=15, 
                      fig.height=12, 
                      echo=FALSE, 
                      message=FALSE, 
                      warning=FALSE,
                      cache=TRUE
                      )
```

```{r global packages, echo=FALSE}
#setwd("/home/danilo/Documents/dissertacao/dados/imagens/paisagens_selecionadas")
library(car)
library(ggfortify)
library(ggplot2) 
library(reshape2)
library(gridExtra) 
library(magrittr)
library(plyr)
library(dplyr)
load("/home/danilo/Documents/dissertacao/dados/resultados_DaniloPMori.Rdata")
```
<!--### ANOTAÇÕES GERAIS ###
modificar a paleta de cores para scale_fill_brewer( type = "div" , palette = "RdBu" ) e tirar o fundo branco

-->
## Apresentação do documento ##

  Esse documento apresenta a análise gráfica geral dos resultados. Ele é um recorte de um outro texto em que estou organizando minhas análises. O texto abre com o objetivo geral. Como vocês sabem ele não está 100% definido, mas serve como um norte. Sigo resumindo parte dos métodos, essa sessão é mais como um esqueletão de ideias. Existem diversos buracos nessa sessão pois não tive tempo para preencher, mas está em construção. 


OBJETIVO: Aqui utilizamos o modelo neutro como uma fonte de predições para avaliar o impacto da fragmentação e perda de habitat nas comunidades arbóreas da Mata Atlântica, Brasil. A abordagem é similar à de Gilbert et al. (2006), contudo investigamos aspectos diferentes da diversidade das comunidades. Os aspectos da diversidade que investigamos são: i) taxa de especiação/imigração/perda de espécies no equilíbrio (U), ii) Distribuição de abundância de espécies (SAD).
<!-- 
# Material e métodos #
# TreeCo #
# Hansen #
# Modelo Neutro e simulação #
# análise exploratória #
# protocolo de criação de modelo cheio
# seleção de modelos per se #
# produção dos resultados #
-->

## Modelo Neutro e simulação ##
<!-- essa sessão vai provavelmente para o começo do material e métodos assim com um box resumindo a dinâmica neutra e o algoritmo coalescente-->
  O modelo neutro pressupõem que a comunidade é regida por processos aleatórios de morte, nascimento, imigração e especiação. Todas as espécies estão sujeitas a estocasticidade demográfica. No tempo infinito, o sistema entra em equilibrio onde a perda de espécies por deriva ecológica é compensada pelos processos de introdução de novas espécies no sistema (imigração para a comunidade local e especiação na metacomunidade). Quando o equilíbrio é alcançado não há variação no número de espécies e na forma com que a abundância se distribui nas espécies. A manutenção da diversidade depende da taxa de imigração, a probabilidade de um indivíduo de uma nova espécie substituir um indivíduo da comunidade local por evento de morte ("U").No equilíbrio, essa valor também corresponde a taxa com que singletons (espécies com apenas 1 indivíduo) se extinguem por evento de morte na comunidade local.
  
<!--aqui poderia ter um box explicando como que funciona o modelo neutro e o algoritmo coalescente. ou seja um resumo da dinâmica no modelo no tempo normal e para trás-->
  O algoritmo coalescente simula uma dinâmica neutra espacialmente explicíta que ocorre em uma matriz de posições concêntrica a uma matriz da paisagem (BOX explicação modelo e algoritmo). A simulação retorna a identidade, i.e., a espécie, de cada indivíduo na matriz de posições em um momento no equilíbrio. Apesar da simulação não acompanhar a identidade dos indivíduos fora da matriz de posições, esses indivíduos participam da dinâmica. A distribuição que descreve a probabilidade de um propagulo se estabelecer em função da distância da árvore mãe, 'kernel', [modula o impacto da paisagem na dinâmica local - REESCREVER: como traduzir o que o kernel faz na dinamica?]. Assim, as simulações e seus produtos ('U' e SAD réplica) dependem de duas variáveis de exposição: o tamanho de matriz de posições (J) e o tamanho da matriz de paisagem (Jl; l - landscape). Jl é a soma das unidades de espaço que são habitat  e não habitat, que também pode ser obtido pelo produto da densidade de indivíduos de cada levantamento (indivíduos/ha) e do número de hectares do recorte de paisagem (500 ha). Assim, obtemos uma estimativa do número de indivíduos que a paisagem suporta se toda ela fosse preenchida por habitat. Nesse contexto, a variável de interesse "cobertura" pode ser entendido como porcentagem remanescente de Jl ('p'). 

  A taxa de imigração ("U") pode ser entendido como o parâmetro de escala de uma distribuição que descreve a probabilidade de substituição de um indivíduo qualquer da comunidade de tamanho 'J' por um indivíduo de uma nova espécie por evento de morte (REFERÊNCIA). Os eventos de substituição ocorrem de maneira independente, não há correlação temporal. A probabilidade de substituição é constante no tempo e para todo o intervalo das variáveis preditoras. Apenas um evento de substituição ocorre por ciclo. As simulações distinguem-se em J e em Jl, assim algumas variáveis serão calculadas a partir de U para compensar a diferença de J (Jl será considerada efeito aleatório ou offset). Do modelo clássico com espaço implicito, podemos calcular o fluxo de imigrantes para a comunidade local (I), que leva em conta J: I = U*(J-1)/(1-U) (Etienne et al. 2011). E tambem vai ser calculado a taxa de imigração per capita U..J: probabilidade de substituição de um indivíduo da comunidade local por um indivíduo de uma espécie nova/(morte * indivívuo) (REFERÊNCIA) (faz sentido?). Segundo Etienne et al. (2011) os parâmetros do modelo neutro implicito e explicíto (algoritmo coalescente) não são necessariamente analogos [DESENVOLVER MAIS: eu preciso reler para entender a parte q ele fala que I tem 'tanto imigração quanto especiação'].

## Divergência entre as SADs obs e SADs sim - teste de Kolmogorov ##

-descrever a rotina de análise do resultado do teste usado para comparar as SADs obs e réplicas 


```{r echo = FALSE, include=FALSE}
df_resultados$SiteCode %<>% factor
names(df_resultados)[c(2:3,17,20)] <- c("kernel","U", "p", "J")
df_resultados$kernel %<>% as.numeric 
df_resultados %<>% mutate(Jl = DA * 500, # tamanho da comunidade da paisagem,produto da densidade de indivíduos (N/ha) pelo número de hectares do recorte de paisagem (500 ha)
                          Jl.p = DA * 500 * p)  #número de indivíduos presentes na paisagem ou número de pixels do tipo "habitat"
                          # I = U*(J-1)/(1-U), # fluxo de imigrantes para a comunidade local (Rosindell et al. 2011)
                          # U..J = U/J) # taxa de imigração per capita;
lm_S <- lm(S.medio ~ S.obs, df_resultados)
```
<!--####################################################################################################################################
#################################### -1o sessão: objetivo da análise exploratória , resumo do que foi feito ############################
#####################################################################################################################################-->

<!-- revisar os termos usados para descrever as variáveis, de qualquer maneira esses nomes tem relevância internamente no texto  -->  

### glossário de variáveis para as análises ###
p: porcentagem de habitat remanescente, porcentagem de cobertura vegetal

S.obs: riqueza observada

J: tamanho da comunidade

Jl: número de pixels na matriz de paisagem

Jl.p: numero de indivíduos na simulação (area monitorada + area não monitorada)

kernel = kernel = parâmetro de escala de uma distribuição que descreve a probabilidade de um propagulo se estabelecer em função da distância da planta progenitora (m)

U: taxa de imigração

KS: estatística de KS, maior distância entre as curvas acumuladas de dois vetores númericos.

KS.p: probabilidade de se rejeitar a hipótese nula quando ela é verdadedeira, dado KS e a distribuição nula de KS. H0: os dois vetores são amostras de uma mesma distribuição.

GOF: número de SAD réplicas que apresentaram KS.p > 0.05. "Goodness of Fit" abordagem similar à de Etienne & Rosindell (2011)

KS.abund: abundância onde se observou KS

KS.ac.obs: posição na curva acumulada da SAD observada onde KS foi observado.

KS.ac.sim: idem para SAD simulada.

KS.obs.sim: media da maior distância entre as acumuladas. KS sem ser diferença absoluta 

estado: estados brasileiros

disturbance: histórico de perturbação

succession: estágio de sucessão

forest: fitofisionomia

UC: unidade de conservação

  
## Análise Gráfica dos dados ##

  As simulações foram realizados utilizando valores empíricos, assim, não é possível assumir que todas as combinações de parâmetros são possíveis. Estamos presos aos padrões existentes na natureza. Aqui, busco entender a influência que as eventuais relações entre covariáveis têm na relação investigada: efeito da fragmentação na diferença entre o observado e o simulado neutro com diferentes kerneis de dispersão(REESCREVER). Utilizo gráficos exploratórios e modelos lineares para investigar as relações entre:
  i) variáveis de controle (VC) e cobertura vegetal ('p'). VC: S.obs, J, Jl, Jl.p. 
  ii) variáveis respostas (VR) com 'p' e 'kernel', ponderando por classes de VC, quando pertinente. VR: U, KS, KS.p, GOF
  iii) variáveis biogeográficas e históricas e 'p'. estado (e.g. São Paulo), disturbio, fitofisio, unidade de conservação. 
  De antemão, spero que a riqueza observada tenha grande impacto na simulação e nas métricas utilizadas, pois: i) U é estimada para produzir em média S.obs; ii) as SADs dependem de U; iii) a métrica de comparação das SADs, a estatística de KS, pode ser influênciada por S.obs (ela determina o número médio de ranks em que a comparação será realizada - CONFIRMAR; PROCURAR). Também espero que exista uma relação entre Jl e Jl.p e p e Jl.p, afinal Jl.p é obtido do produto dessas variáveis. [PROCURAR: se existe mesmo uma tendência de aumenta da cobertura vegetal com o aumento da cobertura vegetal na paisagem]. Gráficos mais detalhados e que permitem a comparação ficaram para o final do documento em anexo. A seguir eu resumo os achados da análise exploratória.

<!--####################################################################################################################################
########################################## 2o sessão: resumo do que foi encontrado ###################################
#####################################################################################################################################-->

## Resumo dos Achados ##
  
  O primeiro diagnóstico para avaliar se a simulação está fazendo tudo como deveria fazer é o modelo linear S.medio ~ S.obs. O parâmetro "U" (taxa de imigração) é estimado para gerar em média a riqueza observada. O modelo linear S.medio ~ S.obs apresenta: F(1, 766) = 1.255e+06, p-value < 2.2e-166, R² = 0.994  'S.medio = `r round(lm_S$coefficients[1], 4)` + `r round(lm_S$coefficients[2], 4)` * S.obs'. Assim, me parece que a simulação está fazendo o esperado.
  
  Na figura 1 temos a relação de todas as variáveis de controle e cobertura par a par. Argumentei que parece ser mais adequado retirar 3 observações que divergem muito dos demais valores de J. Com exceção de S.obs, VC estão bem distribuidas no gradiente de p (fig 1). Na figura 2, avalio como que S.obs e p se relacionam, parece que existe uma correção positiva entre elas. Concluo que as quatro variáveis de controle podem ser usadas no modelo, mas não simultaneamente, há muita informação em comum. 
  
  Olhando para as variáveis de interesse (VR, cobertura e kernel), a única relação que parece ser mais notória aos olhos é KS ~ p, que apresenta relação negativa (fig 5): quanto maior a cobertura vegetal menor KS. U também parece apresentar relação com p, mas ela parece ser modulada pelo kernel(fig 3). O aumento do kernel, consegue reverter a relação de U ~ p, esse efeito não parece acontecer com KS.

  A correlação positiva entre S.obs e p parece ter influência na relação de U ~ p. Ao utilizar os resíduos do modelo linear de U ~ S.obs contra p, o efeito de p em U torna-se mais evidente(fig 4 e 3b). O mesmo procedimento não teve impacto em KS, apesar da correlação entre KS e S.obs, não notei melhora alguma em usarmos os resíduos (fig 5 e 6).
 e negativa  Por conta da correlação positiva entre S.obs e p (fig 2) e da importância de S.obs para a simulação, avaliei o impacto de S.obs na relação de interesse VR ~ cobertura * kernel (fig 3-10). Em anexos, há os mesmos gráficos para as outras VCs.

  As variáveis 'forest disturbance' e 'forest age' apresentam muitos NAs (90 e 73 respectivamente) e serão excluidas do conjunto de dados. As demais variáveis não apresentam NAs ou são poucos (UC: 6, succession: 1). Não acredito que vamos usar todas as vaiáveis de efeito aleatório, pois a amostra não está muito bem balanceada (fig 11). Fundir níveis, quando pertinente, pode ser uma boa estratégia se houver problemas com a estimação.

  Na próxima sessão os gráficos que criei que me permitiram realizar tais interpretações.

## Análise Gráficos ##
<!--####################################################################################################################################
######################################################### Início da análise ############################################################
#####################################################################################################################################-->

<!--####################################################################################################################################
-VC ~ p: correlação entre os parâmetros da simulação; variáveis de controle da simulação
  -objetivo do recorte e resumo do que foi feito
  -gráficos VC ~ p + interpretação do gráfico } S.obs, J, Jl, Jlp
#####################################################################################################################################-->

### Covariáveis de Controle (S.obs, J, Jl) e Cobertura Vegetal ('p') ###  

  Primeiramente, vou analisar a relação entre as variáveis de controle (VC), riqueza observada (S.obs), tamanho da comunidade (J), Jl, Jlp e cobertura vegetal, p. Podemos imaginar que esse conjunto de variáveis descrevem as combinações de parâmetros que utilizamos para rodar o conjunto de simulações.

```{r, fig.width=12, fig.height=12}
df_ae <- df_resultados[,c(1,17,22,20,29:30)] %>% unique %>% arrange(p)
# x11()
scatterplotMatrix(~ p + S.obs + J + Jl + Jl.p, df_ae)
# df_ae %>% filter(J>5000) # trabalhos que distoam dos demais em termos de tamanho da comunidade
# df_ae %>% summary
# mean(df_ae[df_ae$J>5000,4]-mean(df_ae$J))
# sd(df_ae$J[df_ae$J<5000])
# sd(df_ae$J)
# df_ae[df_ae$J>5000,4]/mean(df_ae$J)
#amplitude_s<- diff(range(df_ae[df_ae$J<5000,4]))
#amplitude_c<- diff(range(df_ae[,4]))
```

Figura 1. Cobertura vegetal e variáveis de controle, os "inputs observados". 

```{r echo=FALSE, include=FALSE}
sd(df_ae$J[df_ae$J<5000])
sd(df_ae$J)
```


<!-- #### TABELA 1: estatísticas descritivas de VC #### --> 

  As variáveis parecem ser assimétricas, com duas corcovas e serem platicúrtica, com exceção de J, que tem um forma leptocurtico. Parece que os SiteCodes SPeea1, SPeec1, SPpecb1 são valores que distoam dos demais dentro do conjunto de dados de J. Sem esses três valores o desvio padrão de J é 583.426 indivíduos, com eles sobe para 2596.384 indivíduos, um aumento de  445.023%. Eu acredito que J precisa ter variação bem distribuida ao longo do gradiente de p e S, olhando para os paineis dessas variáveis (e das demais), vemos que esses valores distoam dos demais. Se a amostra estivesse melhor balanceada, tivessem mais pontos com J dessas magnitudes poderiamos considerar como três classes de comunidades seria possívelusa-las como variável de efeito aleatório(Bolker et al. 2008).  Assim, afi de minimizar a variação de J, eu irei remover as observações de SPeea1, SPeec1, SPeeb1. <!-- DISCUTIR QUESTÃO E VER QUAIS SÃO OS TRABALHOS, ELES  -->
  
```{r}
df_resultados %<>% filter(SiteCode != "SPeea1" & SiteCode != "SPeec1" & SiteCode != "SPpecb1")
```
  
  Com exceção de S.obs e Jl.p que parecem apresentar alguma correlação com p, parece que todas as variáveis estão bem distribuidas ao longo de p. A correlação entre Jl.p e p era esperada, afinal a primeira é uma transformação da segunda, contudo, a correlação de S.obs pode ter uma grande influência nos resultados da simulação, dado que a simulação estima U a partir de S.obs. Se existe uma correlação entre dois parâmetros de uma simulação significa que nem todos as combinações entre eles eram possíveis. Na próxima sessão vou investigar a influência de S.obs na relação de interesse. Em anexo os mesmos gráficos para as outras VC. 

## S.obs ~ p ##


```{r }
df_ae <- df_resultados[,c(1,17,22)] %>% unique
names(df_ae)[3] <- "S"
df_ae %<>% mutate(.,S_factor = cut(S,10),
                    p_factor = cut(p,4))
lm_S.p <- lm(S ~ p, data = df_ae)
#df_ae$fit <- lm_S.p$fitted.values
#df_ae$res <- lm_S.p$residuals
# df_ae %>% mutate(S_true = S - (fit + res) ) %>% .$S_true %>% summary # OK
# summary(lm_S.p)
# plots #
p_S.p_bx <- ggplot(df_ae, aes(y=p, x=S)) +
              geom_boxplot(aes(colour=S_factor)) + 
              geom_jitter() +
              theme(plot.background=element_blank()) + 
              coord_flip()
p_p.S_bx <- ggplot(df_ae, aes(y = S, x=p, group = p_factor)) + geom_boxplot(aes(colour=p_factor)) + geom_jitter() +
              geom_jitter() +
              theme(plot.background=element_blank()) 
p_S.p_lm <- ggplot(df_ae, aes(x=p, y=S)) + geom_smooth(method="lm", se=FALSE, colour = "#003300") +
              geom_point(aes(colour=S_factor ,shape = S_factor, size = 10)) +
              scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none") +
              annotate("rect", xmin = -0.01, xmax = 0.11, ymin = 170, ymax = 220, fill="white", colour="red") + #caixa
              annotate("text", x=0.05, y=c(213,196,179), label = c("R^2 == 0.367","alpha == 50.854", "beta == 83.290"), parse=T, size = 3)
p_S.p_lm.diag <- autoplot(lm_S.p) + theme_bw()
# diagnostic grafics #
#p1<-ggplot(df_ae, aes(x = fit, y = res)) + #Residual vs Fitted Plot
#      geom_point(aes(colour=S_factor ,shape = S_factor, size = 10)) + 
#      stat_smooth(method="loess") + geom_hline(yintercept=0, col="red", linetype="dashed") +
#      scale_shape_manual(values=LETTERS[1:10]) +
#      xlab("Fitted values") + ylab("Residuals")
#      ggtitle("Residual vs Fitted Plot") +
#      theme(legend.position="none", panel.background=element_blank(), panel.border=element_blank(),
#            panel.grid.major=element_blank(), panel.grid.minor=element_blank(),plot.background=element_blank())
lay <- rbind(c(1,1,3,3),
             c(1,1,3,3),
             c(2,2,4,5),
             c(2,2,6,7))
grid.arrange(p_S.p_bx,
             p_S.p_lm,
             p_p.S_bx,
             p_S.p_lm.diag[[1]], p_S.p_lm.diag[[2]], p_S.p_lm.diag[[3]], p_S.p_lm.diag[[4]],
             ncol = 4, nrow = 4, layout_matrix = lay)
ggplot()
df_md <- df_md[,-11]

ggplot(df_md,aes(x=p,y=S.obs))
```
Figura 2 - Riqueza observada e Cobertura vegetal. canto superior esquerdo, S ~ p: boxplots classe de riqueza. Acima na direita, S ~ p: boxplot por classe de p. embaixo na esquerda, regressão linear S ~ p, p-value = 3.3634e-11. Na porção da direita, gráficas diagnósticos da regressão linear de S ~ p.


  Dividi S.obs em 10 classes de igual comprimento e marqueis os pontos segundo essas classes em gráficos relacionado S.obs e p (figura 2). Os valores de S.obs não parecem estar igualmente distribuidos ao longo do gradiente de cobertura. As observações se iniciam em valores de p próximos de zero, com S.obs variando de 26 até 128 espécies, o maior valor de S.obs é 230 espécies. As classes médias de S.obs (]46;128] espécies) estão bem distribuidas em p, enquanto as classes baixas (]25.8;46.4] espécies) e altas (]128;230] espécies) estão concentrados em cantos do gradiente de p. Existe uma tendência de que com o aumento da cobertura, ocorra um aumento nos valores de S.obs (figura 2, esquerda em baixo). Olhando para p, a riqueza não esta bem distribuida ao longo de todo seu gradiente, quanto maio a cobertura maior a variância e a média (figura 2, canto superior direito. Portanto, existe uma correlação entre S.obs e cobertura. O modelo linear confirma o padrão visto nos boxplots. Contudo, não sei se a relação positiva entre as covariáveis pode interferir no resultado das simulações. Intuitivamente, me parece que relações entre covariáveis podem mascarar relações de sinal oposto entre variáveis resposta e as variáveis de interesse p e kernel. O impacto que essa correlação têm, vai depender da sensibilidade da simulação aos dados.
  J, Jl e Jl.p serão considerados tanto como variáveis de efeito aleatório quanto como variáveis de efeito fixo, pois estão relacionadas com um questão da amostra, do viés da amostra do TreeCo, e também estão relacionados com o funcionamento da simulação, ou seja, da dinâmica neutra, então, possuem valor teórico. 
  Vou investigar mais a influênciad de S.obs na simulação. Provavelmente irei utiliza-la como variável aleatória, acredito que S.obs teve um grande impacto nos resultados da simulação, como argumentado anteriormente. Colocando S.obs como variável aleatória eu consigo ponderar o efeito que o gradiente de espécies pode ter no gradiente de fragmentação.

<!--####################################################################################################################################
-VR ~ p * kernel * VC <!-- variáveis resposta da simulação
  -objetivo do recorte e resumo do que foi feito
  -gráficos VR ~ p * kernel * VC } VR: U, KS, KS.p, GOF, KS.abund, KS.ac.obs, KS.ac.sim, KS.obs.sim 
                                   VC: S.obs, J, Jl, Jlp <!-- fazer gráfico de VR linhas e VC colunas para vizualização dos resultados marcados por classe de  ANEXO
#####################################################################################################################################-->
  Aqui, penso na relação de todas as variáveis respostas, p e kernel. Para comparação par a par de todas as variáveis utilizadas, exceto as biogeográficas e históricas (figura A1 ). Para VR ~ p * kernel para cada VC ver gráficos em anexo. A seguir um recorte de VR ~ p * kernel por classe de S.obs.

## A influência da riqueza no resultado da simulação ##


### U ~ p * kernel * S ###


```{r}
df_ae <- df_resultados[,c(1,18,2,17,3)] %>% arrange(p, kernel)
df_ae$kernel %<>% factor
df_ae %<>% mutate(p_factor = cut(p,10))
p_U.p <- ggplot(df_ae, aes(x=p,y=U)) + geom_smooth(method="lm") + geom_point() + theme_bw()
p_U.p.kernel <- ggplot(df_ae, aes(x=p,y=U, group = kernel)) + geom_smooth(method="lm", se= FALSE, aes(colour=kernel)) +
                  geom_point(aes(colour=kernel)) + theme_bw()
p_U.kernel.p <- ggplot(df_ae, aes(y=U,x=kernel, group=SiteCode)) + geom_line(aes(colour=kernel)) + facet_grid(~p_factor)  + theme_bw()
lay <- rbind(rep(1:2,each=5),
             rep(3,10))
grid.arrange(p_U.p, p_U.p.kernel, p_U.kernel.p, ncol=8, layout_matrix=lay)
```
figura 3 Taxa de imigração (U), cobertura (p) e kernel de dispersão. No painel de baixo, cada linha representa um SiteCode, simulada com diferentes kerneis de dispersão (cores)

  Parece não haver relação entre U e cobertura vegetal (figura 3, painel canto superior esquerdo). Quando ponderado por kernel, parece emergir um padrão. O kernel com valor mais baixo (31.1 m), apresenta pouca mudança ao longo do gradiente de fragmentação. O segundo menor kernel apresenta tendência ao aumento de U com o aumento de 'p'. Com o gradual aumento dos valores de kernel, essa relação se amortiza e acaba por se reverter (figura 3, painel canto superior direito). Quando dividimos p em 10 classes, vemos que o efeito do kernel em U parece modificar ao longo das classes de p (figura 3, painel inferior), de maneira geral, parece que em baixos valores de 'p' incrementos de kernel implicam em incrementos de U. Como esperado, parece existir uma interação entre cobertura e kernel: o efeito do kernel em U depende da cobertura vegetal e vice e versa. Existe muita variação em U, que é muito sensível à S.obs, assim vou fazer alguns gráficos considerando S.obs como fator para investigar se parte 


```{r}
df_ae <- df_resultados[,c(1,18,2,17,3,22)] %>% arrange(p, kernel)
# df_ae$kernel %<>% factor
df_ae %<>% mutate(p_factor = cut(p,10),
                  S_factor = cut(S.obs,10))
names(df_ae)[6] <- "S"
lm_U.S <- lm(U ~ S, df_ae)
df_ae$fit <- lm_U.S$fitted.values
df_ae$res <- lm_U.S$residuals
p_S.p <- ggplot(df_ae, aes(x=p, y=S, group=S_factor)) + geom_smooth(method="lm", se=FALSE, aes(colour=S_factor)) +
          geom_point(aes(colour=S_factor ,shape = S_factor, size = 10)) +
          scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none")
p_U.p.S <- ggplot(df_ae, aes(x=p, y=U, group = S_factor)) + geom_smooth(method="lm", se=FALSE, aes(colour=S_factor)) +
            geom_point(aes(colour=S_factor, shape = S_factor, size = 10)) +
            scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none")
p_U.S_lm <- ggplot(df_ae, aes(x=S, y=U)) + geom_point() + geom_smooth(method="lm", se=FALSE) + theme_bw() + theme(legend.position="none")
p_J.p_lm.diag <- autoplot(lm_U.S) + theme_bw()
p_res.p <- ggplot(df_ae,aes(x=p,y=res)) + geom_smooth(method="lm", se= FALSE) +
                  geom_point() + theme_bw() + theme(legend.position="none")
p_fit.p <- ggplot(df_ae,aes(x=p,y=fit)) + geom_smooth(method="lm", se= FALSE, aes(colour=kernel)) +
                  geom_point() + theme_bw() + theme(legend.position="none")
lay <- rbind(c(1,1,2,2),
             c(1,1,2,2),
             c(3,3,4,5),
             c(3,3,6,7))
grid.arrange(p_S.p, p_U.p.S,
             p_U.S_lm,
             p_J.p_lm.diag[[1]], p_J.p_lm.diag[[2]],
             p_res.p, p_fit.p,
             ncol=4, layout_matrix=lay)
```
figura 4. Taxa de imigração, cobertura, riqueza e kernel. Porção superior, comparação entre os gráficos de dispersão de S~p e U~p. As letras representam as classes de riqueza, utilizadas anteriormente. R^2 = 0.3792, S = 7.190e-5, p-value = 2.2e-16.

  Parece haver uma tendência de que U diminua com o aumento de p. Essa tendência parece não ser válida para toda as classes de riqueza, quanto maior S.obs, maior a variação entre os valores (fig 4 paineis superiores). Além de aumentar a variância, os valores médios de U ao longo de p parecem ser influenciados pela correlação de U ~ S.obs (figura 4 paineis inferiores). Apesar de parecer que o modelo linear não é o melhor modelo para descrever a relação entre essas duas variáveis (figura 4 "Residuals vs Fitted" e "Normal Q-Q"). Por simplificade optei por realizar o gráfico dos resíduos e dos valores preditos pelo modelo linear contra p e parece que existia um efeito de S na relação observada de U e p (figura 4, os dois úlimos gráficos do canto inferior direito). A seguir reproduzo a figura 3, com os valores dos resíduos de U~p no lugar de U. 
  
```{r}
df_ae$kernel %<>% factor
p_res.p <- ggplot(df_ae, aes(x=p,y=res)) + geom_smooth(method="lm") + geom_point() + theme_bw()
p_res.p.kernel <- ggplot(df_ae, aes(x=p,y=res, group = kernel)) + geom_smooth(method="lm", se= FALSE, aes(colour=kernel)) +
                  geom_point(aes(colour=kernel)) + theme_bw()
p_res.kernel.p <- ggplot(df_ae, aes(y=res,x=kernel, group=SiteCode)) + geom_line(aes(colour=kernel)) + facet_grid(~p_factor)  + theme_bw()
lay <- rbind(rep(1:2,each=5),
             rep(3,10))
grid.arrange(p_res.p, p_res.p.kernel, p_res.kernel.p, ncol=8, layout_matrix=lay)
```
figura 3B - Resíduo de U~S, cobertura e kernel,

  Eu não sei se essa é a melhor abordagem para lidar com o caso, mas eu achei que facilitou para a visualização da questão. Então, 'descontado' o efeito de S em U, a relação U ~ p é negativa.

### KS ~ p * kernel * S ###


```{r}
df_ae <- df_resultados[,c(1,18,2,17,4)] %>% arrange(p, kernel)
df_ae$kernel %<>% factor
df_ae %<>% mutate(p_factor = cut(p,10))
p_KS.p <- ggplot(df_ae, aes(x=p,y=KS)) + geom_smooth(method="lm") + geom_point() + theme_bw()
p_KS.p.kernel <- ggplot(df_ae, aes(x=p,y=KS, group = kernel)) + geom_smooth(method="lm", se= FALSE, aes(colour=kernel)) +
                  geom_point(aes(colour=kernel)) + theme_bw()
p_KS.kernel.p <- ggplot(df_ae, aes(y=KS,x=kernel, group=SiteCode)) + geom_line(aes(colour=kernel)) + facet_grid(~p_factor)  + theme_bw()
lay <- rbind(rep(1:2,each=5),
             rep(3,10))
grid.arrange(p_KS.p, p_KS.p.kernel, p_KS.kernel.p, ncol=8, layout_matrix=lay)
```
figura 5. Estatística de Kolmogorov - Smirnov (KS), cobertura (p) e kernel de dispersão. No painel de baixo, cada linha representa um SiteCode, simulada com diferentes kerneis de dispersão (cores)


  KS e p parecem apresentar relação negativa, que quando ponderado pelo kernel se acentua mais: quanto maior o kernel maior o efeito de p (figura 5, paineis superiores). Contudo, não vemos um efeito claro de p na relação KS ~ p (figura 5, paineis inferiores). De maneira geral, quanto maior a cobertura vegeta e maior o kernel, menor KS. Mas parece haver muita variação nos dados. Vou avaliar a influência de S.


```{r}
df_ae <- df_resultados[,c(1,18,2,17,4,22)] %>% arrange(p, kernel)
# df_ae$kernel %<>% factor
df_ae %<>% mutate(p_factor = cut(p,10),
                  S_factor = cut(S.obs,10))
names(df_ae)[6] <- "S"
lm_KS.S <- lm(KS ~ S, df_ae)
df_ae$fit <- lm_KS.S$fitted.values
df_ae$res <- lm_KS.S$residuals
p_S.p <- ggplot(df_ae, aes(x=p, y=S, group=S_factor)) + geom_smooth(method="lm", se=FALSE, aes(colour=S_factor)) +
          geom_point(aes(colour=S_factor ,shape = S_factor, size = 10)) +
          scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none")
p_KS.p.S <- ggplot(df_ae, aes(x=p, y=KS, group = S_factor)) + geom_smooth(method="lm", se=FALSE, aes(colour=S_factor)) +
            geom_point(aes(colour=S_factor, shape = S_factor, size = 10)) +
            scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none")
p_KS.S_lm <- ggplot(df_ae, aes(x=S, y=KS)) + geom_point() + geom_smooth(method="lm", se=FALSE) + theme_bw() + theme(legend.position="none")
p_J.p_lm.diag <- autoplot(lm_KS.S) + theme_bw()
p_res.p <- ggplot(df_ae,aes(x=p,y=res)) + geom_smooth(method="lm", se= FALSE) +
                  geom_point() + theme_bw() + theme(legend.position="none")
p_fit.p <- ggplot(df_ae,aes(x=p,y=fit)) + geom_smooth(method="lm", se= FALSE, aes(colour=kernel)) +
                  geom_point() + theme_bw() + theme(legend.position="none")
lay <- rbind(c(1,1,2,2),
             c(1,1,2,2),
             c(3,3,4,5),
             c(3,3,6,7))
grid.arrange(p_S.p, p_KS.p.S,
             p_KS.S_lm,
             p_J.p_lm.diag[[1]], p_J.p_lm.diag[[2]],
             p_res.p, p_fit.p,
             ncol=4, layout_matrix=lay)
```
figura 6. KS, cobertura, riqueza e kernel. Porção superior, comparação entre os gráficos de dispersão de S~p e U~p. As letras representam as classes de riqueza, utilizadas anteriormente. R^2 = 0.3028, S = -6.897e-04, p-value < 2.2e-16.

  Apesar de existir uma correlação entre KS e S, visualizar a relação KS~p usando S como fator não ajudou para entender melhor o padrão observado. Nesse caso, a correlação entre VR ~ p e VC ~ possuem o mesmo sinal. Preciso refletir mais sobre essa questão.
  
```{r}
df_ae$kernel %<>% factor
p_res.p <- ggplot(df_ae, aes(x=p,y=res)) + geom_smooth(method="lm") + geom_point() + theme_bw()
p_res.p.kernel <- ggplot(df_ae, aes(x=p,y=res, group = kernel)) + geom_smooth(method="lm", se= FALSE, aes(colour=kernel)) +
                  geom_point(aes(colour=kernel)) + theme_bw()
p_res.kernel.p <- ggplot(df_ae, aes(y=res,x=kernel, group=SiteCode)) + geom_line(aes(colour=kernel)) + facet_grid(~p_factor)  + theme_bw()
lay <- rbind(rep(1:2,each=5),
             rep(3,10))
grid.arrange(p_res.p, p_res.p.kernel, p_res.kernel.p, ncol=8, layout_matrix=lay)
```
figura 5B - Resíduo de KS~S, cobertura e kernel,

  Parece que S.obs atenua o efeito de p em U.

### KS.p ~ p * kernel * S ###

```{r}
df_ae <- df_resultados[,c(1,18,2,17,5)] %>% arrange(p, kernel)
df_ae$kernel %<>% factor
df_ae %<>% mutate(p_factor = cut(p,10))
p_KS.p.p <- ggplot(df_ae, aes(x=p,y=KS.p)) + geom_smooth(method="lm") + geom_point() + theme_bw()
p_KS.p.p.kernel <- ggplot(df_ae, aes(x=p,y=KS.p, group = kernel)) + geom_smooth(method="lm", se= FALSE, aes(colour=kernel)) +
                  geom_point(aes(colour=kernel)) + theme_bw()
p_KS.p.kernel.p <- ggplot(df_ae, aes(y=KS.p,x=kernel, group=SiteCode)) + geom_line(aes(colour=kernel)) + facet_grid(~p_factor)  + theme_bw()
lay <- rbind(rep(1:2,each=5),
             rep(3,10))
grid.arrange(p_KS.p.p, p_KS.p.p.kernel, p_KS.p.kernel.p, ncol=8, layout_matrix=lay)
```
figura 7 KS.p, cobertura (p) e kernel de dispersão. No painel de baixo, cada linha representa um SiteCode, simulada com diferentes kerneis de dispersão (cores)

  KS.p tem muita variação nos dados, difícil dizer se existe uma relação mesmo. Ponderando pelo kernel, parece que com o aumento do kernel diminui o efeito da relação até que se reverte, mas muito diserpso.  

```{r}
df_ae <- df_resultados[,c(1,18,2,17,5,22)] %>% arrange(p, kernel)
# df_ae$kernel %<>% factor
df_ae %<>% mutate(p_factor = cut(p,10),
                  S_factor = cut(S.obs,10))
names(df_ae)[6] <- "S"
lm_KS.p.S <- lm(KS.p ~ S, df_ae)
df_ae$fit <- lm_KS.p.S$fitted.values
df_ae$res <- lm_KS.p.S$residuals
p_S.p <- ggplot(df_ae, aes(x=p, y=S, group=S_factor)) + geom_smooth(method="lm", se=FALSE, aes(colour=S_factor)) +
          geom_point(aes(colour=S_factor ,shape = S_factor, size = 10)) +
          scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none")
p_KS.p.p.S <- ggplot(df_ae, aes(x=p, y=KS.p, group = S_factor)) + geom_smooth(method="lm", se=FALSE, aes(colour=S_factor)) +
            geom_point(aes(colour=S_factor, shape = S_factor, size = 10)) +
            scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none")
p_KS.p.S_lm <- ggplot(df_ae, aes(x=S, y=KS.p)) + geom_point() + geom_smooth(method="lm", se=FALSE) + theme_bw() + theme(legend.position="none")
p_J.p_lm.diag <- autoplot(lm_KS.p.S) + theme_bw()
p_res.p <- ggplot(df_ae,aes(x=p,y=res)) + geom_smooth(method="lm", se= FALSE) +
                  geom_point() + theme_bw() + theme(legend.position="none")
p_fit.p <- ggplot(df_ae,aes(x=p,y=fit)) + geom_smooth(method="lm", se= FALSE, aes(colour=kernel)) +
                  geom_point() + theme_bw() + theme(legend.position="none")
lay <- rbind(c(1,1,2,2),
             c(1,1,2,2),
             c(3,3,4,5),
             c(3,3,6,7))
grid.arrange(p_S.p, p_KS.p.p.S,
             p_KS.p.S_lm,
             p_J.p_lm.diag[[1]], p_J.p_lm.diag[[2]],
             p_res.p, p_fit.p,
             ncol=4, layout_matrix=lay)
```
figura 8. KS.p, cobertura, riqueza e kernel. Porção superior, comparação entre os gráficos de dispersão de S~p e U~p. As letras representam as classes de riqueza, utilizadas anteriormente. R^2 = 1.022e-3, S = 1.83e-4, p-value = 0.384.

  Parece não haver relação entre as variáveis, não vou realizar os gráficos com os resíduos da regressão. 

### GOF ~ p * kernel * S ###

```{r}
df_ae <- df_resultados[,c(1,18,2,17,28)] %>% arrange(p, kernel)
df_ae$kernel %<>% factor
df_ae %<>% mutate(p_factor = cut(p,10))
p_GOF.p <- ggplot(df_ae, aes(x=p,y=GOF)) + geom_smooth(method="lm") + geom_point() + theme_bw()
p_GOF.p.kernel <- ggplot(df_ae, aes(x=p,y=GOF, group = kernel)) + geom_smooth(method="lm", se= FALSE, aes(colour=kernel)) +
                  geom_point(aes(colour=kernel)) + theme_bw()
p_GOF.kernel.p <- ggplot(df_ae, aes(y=GOF,x=kernel, group=SiteCode)) + geom_line(aes(colour=kernel)) + facet_grid(~p_factor)  + theme_bw()
lay <- rbind(rep(1:2,each=5),
             rep(3,10))
grid.arrange(p_GOF.p, p_GOF.p.kernel, p_GOF.kernel.p, ncol=8, layout_matrix=lay)
```
figura 9 GOF cobertura (p) e kernel de dispersão. No painel de baixo, cada linha representa um SiteCode, simulada com diferentes kerneis de dispersão (cores)

De maneira geral, a simulação parece criar SADs que são boas aproximações das curvas acumuladas para todo valore de p. A variação não parece estar associada com o gradiente de p. 

```{r}
df_ae <- df_resultados[,c(1,18,2,17,28,22)] %>% arrange(p, kernel)
# df_ae$kernel %<>% factor
df_ae %<>% mutate(p_factor = cut(p,10),
                  S_factor = cut(S.obs,10))
names(df_ae)[6] <- "S"
lm_GOF.S <- lm(GOF ~ S, df_ae)
df_ae$fit <- lm_GOF.S$fitted.values
df_ae$res <- lm_GOF.S$residuals
p_S.p <- ggplot(df_ae, aes(x=p, y=S, group=S_factor)) + geom_smooth(method="lm", se=FALSE, aes(colour=S_factor)) +
          geom_point(aes(colour=S_factor ,shape = S_factor, size = 10)) +
          scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none")
p_GOF.p.S <- ggplot(df_ae, aes(x=p, y=GOF, group = S_factor)) + geom_smooth(method="lm", se=FALSE, aes(colour=S_factor)) +
            geom_point(aes(colour=S_factor, shape = S_factor, size = 10)) +
            scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none")
p_GOF.S_lm <- ggplot(df_ae, aes(x=S, y=GOF)) + geom_point() + geom_smooth(method="lm", se=FALSE) + theme_bw() + theme(legend.position="none")
p_J.p_lm.diag <- autoplot(lm_GOF.S) + theme_bw()
p_res.p <- ggplot(df_ae,aes(x=p,y=res)) + geom_smooth(method="lm", se= FALSE) +
                  geom_point() + theme_bw() + theme(legend.position="none")
p_fit.p <- ggplot(df_ae,aes(x=p,y=fit)) + geom_smooth(method="lm", se= FALSE, aes(colour=kernel)) +
                  geom_point() + theme_bw() + theme(legend.position="none")
lay <- rbind(c(1,1,2,2),
             c(1,1,2,2),
             c(3,3,4,5),
             c(3,3,6,7))
grid.arrange(p_S.p, p_GOF.p.S,
             p_GOF.S_lm,
             p_J.p_lm.diag[[1]], p_J.p_lm.diag[[2]],
             p_res.p, p_fit.p,
             ncol=4, layout_matrix=lay)
```
figura 10. GOF, cobertura, riqueza e kernel. Porção superior, comparação entre os gráficos de dispersão de S~p e U~p. As letras representam as classes de riqueza, utilizadas anteriormente. R^2 = 1.435e-4, S = 6.280e-3, p-value = 0.744.

  Me parece que não há relaçã entre as variáveis, contudo, me parece que existe uma mudança da variância de GOF por classes de riqueza. 

  Similarmente ao conjunto de variáveis anteriores, KS._, também são medidas relacionadas entre si. KS.abund é o valor de abundância onde foi observado KS, pode ser entendido como a abundância acumulada que gerou a maior distância entre as SADs. KS.ac.obs é a média do valor da curva acumulada onde se observou KS; KS.ac.sim idem para a SAD simulada; KS.obs.sim mede a diferença média entre KS.ac.obs e KS.ac.sim. Espera-se que KS.obs.sim seja descrita por uma distribuição simétrica com média no zero, contudo, ela parece ser assimétrica para a direita, revelando que em média a maior distância entre as curvas acumuladas se deve ao modelo neutro subestimar a abundância onde KS foi observado (KS.abund). Não vou discutir essas variáveis nesse documento. Os gráficos para estas variáveis estão em anexo.

### Variáveis biogeográficas e históricas ###

Em anexo: tive problemas em coloca-la no markdown.

<!--
```{r}
#ggplot(df_va, aes(y = p, x = nivel)) + 
#  geom_boxplot(aes(fill=nivel)) + geom_jitter() +
#  facet_wrap(~var.aleatoria, scales = "free") + labs(x="") +
#  theme_bw() + theme(strip.background=element_rect(fill="black")) + theme(strip.text=element_text(color="white", face="bold")) + guides(fill =FALSE)
```
-->
Figura 11. Cobertura X Variáveis de efeito aleatório: 'estado', UC - unidade de conservação, succession = sucessão ecológica
f1.IM = Formacao pioneira sob influencia marinha, FG = Floresta de galeria, cer = Cerradão, PI = UC de proteção integral, US = UC de uso sustentável
  
  As variáveis 'forest disturbance' e 'forest age' apresentam muitos NAs (90 e 73 respectivamente), vou retira-las e considerar apenas as demais variáveis. As demais variáveis não apresentam NAs ou são poucos (UC: 6, succession: 1). Não acredito que vamos usar todas as vaiáveis de efeito aleatório, pois a amostra não está muito bem balanceada. Fundir níveis, quando pertinente, pode ser uma boa estratégia se houver problemas com a estimação.

## ANEXO ##
## Figuras de Resultados gerais ##

```{r}
# x11()
scatterplotMatrix(~ S.obs + J + Jl + Jl.p + U + S.medio + KS + KS.p + GOF, data = df_resultados)
```
Figura A1. Relação entre as variáveis de controle da simulação e e as variáveis respostas. S.obs = riqueza observada; S.medio = S médio das SADs réplicas de cada simulação; KS = média da maior distância entre a SAD observada e a SAD réplica; KS.p = média do p valor associado ao teste de Kolmogovor-Smirnov; GOF (Goodness of fit - adaptado de Etienne & Rosindell 2011) = número de réplicas que obtiveram um bom ajuste (critério de ajuste: p valor > 0.05). As três primeiras variáveis são variáveis de controle da simulação: S,.obs, J e Jp. U.medio é a media da taxa de imigração esimada para cada simulação. S.medio, pode ser entendido como uma avaliação da qualidade da simulação. KS, KS.p, GOF podem ser entendidos como métricas da congruência da SAD simulada com a SAD observada.-->



## Gráficos detalhados das variáveis de controle de e p ##

# J ~ p #
```{r}
df_ae <- df_resultados[,c(1,17,20)] %>% unique
df_ae %<>% mutate(.,J_factor = cut(J,10),
                    p_factor = cut(p,10))
lm_J.p <- lm(J ~ p, data = df_ae)
#df_ae$fit <- lm_S.p$fitted.values
#df_ae$res <- lm_S.p$residuals
# df_ae %>% mutate(S_true = S - (fit + res) ) %>% .$S_true %>% summary # OK
# summary(lm_S.p)
# plots #
p_J.p_bx <- ggplot(df_ae, aes(y=p, x=J)) +
              geom_boxplot(aes(colour=J_factor)) + 
              geom_jitter() +
              theme(plot.background=element_blank()) + 
              coord_flip()
p_p.J_bx <- ggplot(df_ae, aes(y = J, x=p, group = p_factor)) + geom_boxplot(aes(colour=p_factor)) + geom_jitter() +
              geom_jitter() +
              theme(plot.background=element_blank()) 
p_J.p_lm <- ggplot(df_ae, aes(x=p, y=J)) + geom_smooth(method="lm", se=FALSE, colour = "#003300") +
              geom_point(aes(colour=J_factor ,shape = J_factor, size = 10)) +
              scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none")
p_J.p_lm.diag <- autoplot(lm_J.p) + theme_bw()
lay <- rbind(c(1,1,3,3),
             c(1,1,3,3),
             c(2,2,4,5),
             c(2,2,6,7))
grid.arrange(p_J.p_bx,
             p_J.p_lm,
             p_p.J_bx,
             p_J.p_lm.diag[[1]], p_J.p_lm.diag[[2]], p_J.p_lm.diag[[3]], p_J.p_lm.diag[[4]],
             ncol = 4, nrow = 4, layout_matrix = lay)
```

## Jl ~ p ##
```{r}
df_ae <- df_resultados[,c(1,17,29)] %>% unique
df_ae %<>% mutate(.,Jl_factor = cut(Jl,10),
                    p_factor = cut(p,10))
lm_Jl.p <- lm(Jl ~ p, data = df_ae)
df_ae$fit <- lm_Jl.p$fitted.values
df_ae$res <- lm_Jl.p$residuals
# df_ae %>% mutate(Jl_true = Jl - (fit + res) ) %>% .$Jl_true %>% summary # OK
# summary(lm_Jl.p)
# plots #
p_Jl.p_bx <- ggplot(df_ae, aes(y=p, x=Jl)) +
              geom_boxplot(aes(colour=Jl_factor)) + 
              geom_jitter() +
              theme(legend.position="none",plot.background=element_blank()) + 
              coord_flip()
p_p.Jl_bx <- ggplot(df_ae, aes(y = Jl, x="")) + geom_boxplot() + geom_jitter(aes(colour=Jl_factor)) +
              theme(axis.ticks=element_blank(), legend.position="none", panel.background=element_blank(), panel.border=element_blank(),
                    panel.grid.major=element_blank(), panel.grid.minor=element_blank(),plot.background=element_blank())
p_Jl.p_lm <- ggplot(df_ae, aes(x=p, y=Jl)) + geom_smooth(method="lm", se=FALSE, colour = "#003300") +
              geom_point(aes(colour=Jl_factor ,shape = Jl_factor, size = 10)) +
              scale_shape_manual(values=LETTERS[1:10]) + theme_bw()
p_Jl.p_lm.diag <- autoplot(lm_Jl.p) + theme_bw()
lay <- rbind(c(1,1,1,3,4,4,5,5),
             c(2,2,2,2,6,6,7,7))
grid.arrange(p_Jl.p_bx,
             p_Jl.p_lm,
             p_p.Jl_bx,
             p_Jl.p_lm.diag@plots[[1]], p_Jl.p_lm.diag@plots[[2]],p_Jl.p_lm.diag@plots[[3]],p_Jl.p_lm.diag@plots[[4]], 
             ncol = 8, nrow = 2, layout_matrix = lay)
```


# Jlp ~ p #
```{r }
df_ae <- df_resultados[,c(1,17,30)] %>% unique
df_ae %<>% mutate(.,Jl.p_factor = cut(Jl.p,10),
                    p_factor = cut(p,10))
lm_Jl.p.p <- lm(Jl.p ~ p, data = df_ae)
df_ae$fit <- lm_Jl.p.p$fitted.values
df_ae$res <- lm_Jl.p.p$residuals
# df_ae %>% mutate(Jl.p_true = Jl.p - (fit + res) ) %>% .$Jl.p_true %>% summary # OK
# summary(lm_Jl.p.p)
# plots #
p_Jl.p.p_bx <- ggplot(df_ae, aes(y=p, x=Jl.p)) +
              geom_boxplot(aes(colour=Jl.p_factor)) + 
              geom_jitter() +
              theme(legend.position="none",plot.background=element_blank()) + 
              coord_flip()
p_p.Jl.p_bx <- ggplot(df_ae, aes(y = Jl.p, x="")) + geom_boxplot() + geom_jitter(aes(colour=Jl.p_factor)) +
              theme(axis.ticks=element_blank(), legend.position="none", panel.background=element_blank(), panel.border=element_blank(),
                    panel.grid.major=element_blank(), panel.grid.minor=element_blank(),plot.background=element_blank())
p_Jl.p.p_lm <- ggplot(df_ae, aes(x=p, y=Jl.p)) + geom_smooth(method="lm", se=FALSE, colour = "#003300") +
              geom_point(aes(colour=Jl.p_factor ,shape = Jl.p_factor, size = 10)) +
              scale_shape_manual(values=LETTERS[1:10]) + theme_bw()
p_Jl.p.p_lm.diag <- autoplot(lm_Jl.p.p) + theme_bw()
lay <- rbind(c(1,1,1,3,4,4,5,5),
             c(2,2,2,2,6,6,7,7))
grid.arrange(p_Jl.p.p_bx,
             p_Jl.p.p_lm,
             p_p.Jl.p_bx,
             p_Jl.p.p_lm.diag@plots[[1]], p_Jl.p.p_lm.diag@plots[[2]],p_Jl.p.p_lm.diag@plots[[3]],p_Jl.p.p_lm.diag@plots[[4]], 
             ncol = 8, nrow = 2, layout_matrix = lay)
```



## Gráficos das variáveis respostas pelas variáveis de interesse (fragmentação e kernel de dispersão), pelas variáveis de controle ##

Em ordem: S.obs, J, Jl, Jlp

VR ~ p * kernel * S.obs

```{r fig.width=15, fig.height=20}
# OBJETIVO: criar gráficos de todas as 8 VR por cobertura, separados pelo kernel de dispersão - 8 linhas (VR) X 8 colunas (kernel)
# x11()
# U #
df_ae <- df_resultados[,c(1,18,2,17,22,3:5,28,6:9)] %>% arrange(p, kernel)
df_ae %<>% mutate(.,S_factor = cut(S.obs, 10))
# df_ae %<>% filter(Sindrome == "wind")
p_U.p.kernel <- ggplot(df_ae, aes(x=p, y=U, group = S_factor)) + 
                  geom_point(aes(colour=S_factor, shape=S_factor),size=3) + geom_smooth(method="lm", se=FALSE, aes(colour=S_factor)) + 
                  scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none") + 
                  theme(strip.background=element_rect(fill="black")) + theme(strip.text=element_text(color="white", face="bold")) +
                  facet_wrap(~kernel,ncol=8) 
p_KS.p.kernel <- ggplot(df_ae, aes(x=p, y=KS, group = S_factor)) + 
                   geom_point(aes(colour=S_factor, shape=S_factor),size=3) + geom_smooth(method="lm", se=FALSE, aes(colour=S_factor)) + 
                   scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none") + 
                   theme(strip.background=element_rect(fill="black")) + theme(strip.text=element_text(color="white", face="bold")) +
                    facet_wrap(~kernel,ncol=8) 
p_KS.p.p.kernel <- ggplot(df_ae, aes(x=p, y=KS.p, group = S_factor)) + 
                     geom_point(aes(colour=S_factor, shape=S_factor),size=3) + geom_smooth(method="lm", se=FALSE, aes(colour=S_factor)) + 
                     scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none") + 
                     theme(strip.background=element_rect(fill="black")) + theme(strip.text=element_text(color="white", face="bold")) +
                     facet_wrap(~kernel,ncol=8) 
p_GOF.p.kernel <- ggplot(df_ae, aes(x=p, y=GOF, group = S_factor)) + 
                    geom_point(aes(colour=S_factor, shape=S_factor),size=3) + geom_smooth(method="lm", se=FALSE, aes(colour=S_factor)) + 
                    scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none") + 
                    theme(strip.background=element_rect(fill="black")) + theme(strip.text=element_text(color="white", face="bold")) +
                    facet_wrap(~kernel,ncol=8) 
p_KS.abund.p.kernel <- ggplot(df_ae, aes(x=p, y=log(KS.abund), group = S_factor)) + 
                         geom_point(aes(colour=S_factor, shape=S_factor),size=3) + geom_smooth(method="lm", se=FALSE, aes(colour=S_factor)) + 
                         scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none") + 
                         theme(strip.background=element_rect(fill="black")) + theme(strip.text=element_text(color="white", face="bold")) +
                         facet_wrap(~kernel,ncol=8) 
p_KS.ac.obs.p.kernel <- ggplot(df_ae, aes(x=p, y=KS.ac.obs, group = S_factor)) + 
                          geom_point(aes(colour=S_factor, shape=S_factor),size=3) + geom_smooth(method="lm", se=FALSE, aes(colour=S_factor)) + 
                          scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none") + 
                          theme(strip.background=element_rect(fill="black")) + theme(strip.text=element_text(color="white", face="bold")) +
                          facet_wrap(~kernel,ncol=8)  
p_KS.ac.sim.p.kernel <- ggplot(df_ae, aes(x=p, y=KS.ac.sim, group = S_factor)) + 
                          geom_point(aes(colour=S_factor, shape=S_factor),size=3) + geom_smooth(method="lm", se=FALSE, aes(colour=S_factor)) + 
                          scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none") + 
                          theme(strip.background=element_rect(fill="black")) + theme(strip.text=element_text(color="white", face="bold")) +
                          facet_wrap(~kernel,ncol=8) 
p_KS.obs.sim.p.kernel <- ggplot(df_ae, aes(x=p, y=KS.obs.sim, group = S_factor)) + 
                          geom_point(aes(colour=S_factor, shape=S_factor),size=3) + geom_smooth(method="lm", se=FALSE, aes(colour=S_factor)) + 
                          scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none") + 
                          theme(strip.background=element_rect(fill="black")) + theme(strip.text=element_text(color="white", face="bold")) +
                          facet_wrap(~kernel,ncol=8) 
# lay <- matrix(rep(1:8,8),ncol=8)
# grid.arrange(p_U.p.kernel,
#              p_KS.p.kernel,p_KS.p.p.kernel,p_GOF.p.kernel,
#              p_KS.abund.p.kernel,p_KS.ac.obs.p.kernel,p_KS.ac.sim.p.kernel,p_KS.obs.sim.p.kernel,
#              ncol = 8, nrow = 8, layout_matrix = lay)
# U, KS, KS.p, GOF #
lay <- matrix(rep(1:4,8),ncol=8)
grid.arrange(p_U.p.kernel,
             p_KS.p.kernel,p_KS.p.p.kernel,p_GOF.p.kernel,
             ncol = 8, nrow = 4, layout_matrix = lay)
```


VR ~ p * kernel * S.obs

```{r fig.width=15, fig.height=20}
# KS, KS._ #
lay <- matrix(rep(1:4,8),ncol=8)
grid.arrange(p_KS.abund.p.kernel,p_KS.ac.obs.p.kernel,p_KS.ac.sim.p.kernel,p_KS.obs.sim.p.kernel,
             ncol = 5, nrow = 8, layout_matrix = lay)
```


VR ~ p * kernel * J

```{r fig.width=15, fig.height=20}
# OBJETIVO: criar gráficos de todas as 8 VR por cobertura, separados pelo kernel de dispersão - 8 linhas (VR) X 8 colunas (kernel)
# x11()
df_ae <- df_resultados[,c(1,18,2,17,20,3:5,28,6:9)] %>% arrange(p, kernel)
df_ae %<>% mutate(.,J_factor = cut(J, 3))
# df_ae %<>% filter(Sindrome == "wind")
p_U.p.kernel <- ggplot(df_ae, aes(x=p, y=U, group = J_factor)) + 
                  geom_point(aes(colour=J_factor, shape=J_factor),size=3) + geom_smooth(method="lm", se=FALSE, aes(colour=J_factor)) + 
                  scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none") + 
                  theme(strip.background=element_rect(fill="black")) + theme(strip.text=element_text(color="white", face="bold")) +
                  facet_wrap(~kernel,ncol=8) 
p_KS.p.kernel <- ggplot(df_ae, aes(x=p, y=KS, group = J_factor)) + 
                   geom_point(aes(colour=J_factor, shape=J_factor),size=3) + geom_smooth(method="lm", se=FALSE, aes(colour=J_factor)) + 
                   scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none") + 
                   theme(strip.background=element_rect(fill="black")) + theme(strip.text=element_text(color="white", face="bold")) +
                    facet_wrap(~kernel,ncol=8) 
p_KS.p.p.kernel <- ggplot(df_ae, aes(x=p, y=KS.p, group = J_factor)) + 
                     geom_point(aes(colour=J_factor, shape=J_factor),size=3) + geom_smooth(method="lm", se=FALSE, aes(colour=J_factor)) + 
                     scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none") + 
                     theme(strip.background=element_rect(fill="black")) + theme(strip.text=element_text(color="white", face="bold")) +
                     facet_wrap(~kernel,ncol=8) 
p_GOF.p.kernel <- ggplot(df_ae, aes(x=p, y=GOF, group = J_factor)) + 
                    geom_point(aes(colour=J_factor, shape=J_factor),size=3) + geom_smooth(method="lm", se=FALSE, aes(colour=J_factor)) + 
                    scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none") + 
                    theme(strip.background=element_rect(fill="black")) + theme(strip.text=element_text(color="white", face="bold")) +
                    facet_wrap(~kernel,ncol=8) 
p_KS.abund.p.kernel <- ggplot(df_ae, aes(x=p, y=log(KS.abund), group = J_factor)) + 
                         geom_point(aes(colour=J_factor, shape=J_factor),size=3) + geom_smooth(method="lm", se=FALSE, aes(colour=J_factor)) + 
                         scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none") + 
                         theme(strip.background=element_rect(fill="black")) + theme(strip.text=element_text(color="white", face="bold")) +
                         facet_wrap(~kernel,ncol=8) 
p_KS.ac.obs.p.kernel <- ggplot(df_ae, aes(x=p, y=KS.ac.obs, group = J_factor)) + 
                          geom_point(aes(colour=J_factor, shape=J_factor),size=3) + geom_smooth(method="lm", se=FALSE, aes(colour=J_factor)) + 
                          scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none") + 
                          theme(strip.background=element_rect(fill="black")) + theme(strip.text=element_text(color="white", face="bold")) +
                          facet_wrap(~kernel,ncol=8)  
p_KS.ac.sim.p.kernel <- ggplot(df_ae, aes(x=p, y=KS.ac.sim, group = J_factor)) + 
                          geom_point(aes(colour=J_factor, shape=J_factor),size=3) + geom_smooth(method="lm", se=FALSE, aes(colour=J_factor)) + 
                          scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none") + 
                          theme(strip.background=element_rect(fill="black")) + theme(strip.text=element_text(color="white", face="bold")) +
                          facet_wrap(~kernel,ncol=8) 
p_KS.obs.sim.p.kernel <- ggplot(df_ae, aes(x=p, y=KS.obs.sim, group = J_factor)) + 
                          geom_point(aes(colour=J_factor, shape=J_factor),size=3) + geom_smooth(method="lm", se=FALSE, aes(colour=J_factor)) + 
                          scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none") + 
                          theme(strip.background=element_rect(fill="black")) + theme(strip.text=element_text(color="white", face="bold")) +
                          facet_wrap(~kernel,ncol=8) 
# lay <- matrix(rep(1:8,8),ncol=8)
# grid.arrange(p_U.p.kernel,
#              p_KS.p.kernel,p_KS.p.p.kernel,p_GOF.p.kernel,
#              p_KS.abund.p.kernel,p_KS.ac.obs.p.kernel,p_KS.ac.sim.p.kernel,p_KS.obs.sim.p.kernel,
#              ncol = 8, nrow = 8, layout_matrix = lay)
# U, KS, KS.p, GOF #
lay <- matrix(rep(1:4,8),ncol=8)
grid.arrange(p_U.p.kernel,
             p_KS.p.kernel,p_KS.p.p.kernel,p_GOF.p.kernel,
             ncol = 8, nrow = 4, layout_matrix = lay)
```

VR ~ p * kernel * J

```{r fig.width=15, fig.height=20}
# KS, KS._ #
lay <- matrix(rep(1:4,8),ncol=8)
grid.arrange(p_KS.abund.p.kernel,p_KS.ac.obs.p.kernel,p_KS.ac.sim.p.kernel,p_KS.obs.sim.p.kernel,
             ncol = 5, nrow = 8, layout_matrix = lay)
```


VR ~ p * kernel * Jl

```{r fig.width=15, fig.height=20}
# OBJETIVO: criar gráficos de todas as 8 VR por cobertura, separados pelo kernel de dispersão - 8 linhas (VR) X 8 colunas (kernel)
# x11()
# U #
df_ae <- df_resultados[,c(1,18,2,17,29,3:5,28,6:9)] %>% arrange(p, kernel)
df_ae %<>% mutate(.,Jl_factor = cut(Jl, 10))
# df_ae %<>% filter(Sindrome == "wind")
p_U.p.kernel <- ggplot(df_ae, aes(x=p, y=U, group = Jl_factor)) + 
                  geom_point(aes(colour=Jl_factor, shape=Jl_factor),size=3) + geom_smooth(method="lm", se=FALSE, aes(colour=Jl_factor)) + 
                  scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none") + 
                  theme(strip.background=element_rect(fill="black")) + theme(strip.text=element_text(color="white", face="bold")) +
                  facet_wrap(~kernel,ncol=8) 
p_KS.p.kernel <- ggplot(df_ae, aes(x=p, y=KS, group = Jl_factor)) + 
                   geom_point(aes(colour=Jl_factor, shape=Jl_factor),size=3) + geom_smooth(method="lm", se=FALSE, aes(colour=Jl_factor)) + 
                   scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none") + 
                   theme(strip.background=element_rect(fill="black")) + theme(strip.text=element_text(color="white", face="bold")) +
                    facet_wrap(~kernel,ncol=8) 
p_KS.p.p.kernel <- ggplot(df_ae, aes(x=p, y=KS.p, group = Jl_factor)) + 
                     geom_point(aes(colour=Jl_factor, shape=Jl_factor),size=3) + geom_smooth(method="lm", se=FALSE, aes(colour=Jl_factor)) + 
                     scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none") + 
                     theme(strip.background=element_rect(fill="black")) + theme(strip.text=element_text(color="white", face="bold")) +
                     facet_wrap(~kernel,ncol=8) 
p_GOF.p.kernel <- ggplot(df_ae, aes(x=p, y=GOF, group = Jl_factor)) + 
                    geom_point(aes(colour=Jl_factor, shape=Jl_factor),size=3) + geom_smooth(method="lm", se=FALSE, aes(colour=Jl_factor)) + 
                    scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none") + 
                    theme(strip.background=element_rect(fill="black")) + theme(strip.text=element_text(color="white", face="bold")) +
                    facet_wrap(~kernel,ncol=8) 
p_KS.abund.p.kernel <- ggplot(df_ae, aes(x=p, y=log(KS.abund), group = Jl_factor)) + 
                         geom_point(aes(colour=Jl_factor, shape=Jl_factor),size=3) + geom_smooth(method="lm", se=FALSE, aes(colour=Jl_factor)) + 
                         scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none") + 
                         theme(strip.background=element_rect(fill="black")) + theme(strip.text=element_text(color="white", face="bold")) +
                         facet_wrap(~kernel,ncol=8) 
p_KS.ac.obs.p.kernel <- ggplot(df_ae, aes(x=p, y=KS.ac.obs, group = Jl_factor)) + 
                          geom_point(aes(colour=Jl_factor, shape=Jl_factor),size=3) + geom_smooth(method="lm", se=FALSE, aes(colour=Jl_factor)) + 
                          scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none") + 
                          theme(strip.background=element_rect(fill="black")) + theme(strip.text=element_text(color="white", face="bold")) +
                          facet_wrap(~kernel,ncol=8)  
p_KS.ac.sim.p.kernel <- ggplot(df_ae, aes(x=p, y=KS.ac.sim, group = Jl_factor)) + 
                          geom_point(aes(colour=Jl_factor, shape=Jl_factor),size=3) + geom_smooth(method="lm", se=FALSE, aes(colour=Jl_factor)) + 
                          scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none") + 
                          theme(strip.background=element_rect(fill="black")) + theme(strip.text=element_text(color="white", face="bold")) +
                          facet_wrap(~kernel,ncol=8) 
p_KS.obs.sim.p.kernel <- ggplot(df_ae, aes(x=p, y=KS.obs.sim, group = Jl_factor)) + 
                          geom_point(aes(colour=Jl_factor, shape=Jl_factor),size=3) + geom_smooth(method="lm", se=FALSE, aes(colour=Jl_factor)) + 
                          scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none") + 
                          theme(strip.background=element_rect(fill="black")) + theme(strip.text=element_text(color="white", face="bold")) +
                          facet_wrap(~kernel,ncol=8) 
lay <- matrix(rep(1:4,8),ncol=8)
grid.arrange(p_U.p.kernel,
             p_KS.p.kernel,p_KS.p.p.kernel,p_GOF.p.kernel,
             ncol = 8, nrow = 4, layout_matrix = lay)
```


VR ~ p * kernel * Jl

```{r fig.width=15, fig.height=20}
# KS, KS._ #
lay <- matrix(rep(1:4,8),ncol=8)
grid.arrange(p_KS.abund.p.kernel,p_KS.ac.obs.p.kernel,p_KS.ac.sim.p.kernel,p_KS.obs.sim.p.kernel,
             ncol = 5, nrow = 8, layout_matrix = lay)
```


VR ~ p * kernel * Jl.p

```{r fig.width=15, fig.height=20}
# OBJETIVO: criar gráficos de todas as 8 VR por cobertura, separados pelo kernel de dispersão - 8 linhas (VR) X 8 colunas (kernel)
# x11()
# U #
df_ae <- df_resultados[,c(1,18,2,17,30,3:5,28,6:9)] %>% arrange(p, kernel)
df_ae %<>% mutate(.,Jl.p_factor = cut(Jl.p, 10))
p_U.p.kernel <- ggplot(df_ae, aes(x=p, y=U, group = Jl.p_factor)) + 
                  geom_point(aes(colour=Jl.p_factor, shape=Jl.p_factor),size=3) + geom_smooth(method="lm", se=FALSE, aes(colour=Jl.p_factor)) + 
                  scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none") + 
                  theme(strip.background=element_rect(fill="black")) + theme(strip.text=element_text(color="white", face="bold")) +
                  facet_wrap(~kernel,ncol=8) 
p_KS.p.kernel <- ggplot(df_ae, aes(x=p, y=KS, group = Jl.p_factor)) + 
                   geom_point(aes(colour=Jl.p_factor, shape=Jl.p_factor),size=3) + geom_smooth(method="lm", se=FALSE, aes(colour=Jl.p_factor)) + 
                   scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none") + 
                   theme(strip.background=element_rect(fill="black")) + theme(strip.text=element_text(color="white", face="bold")) +
                    facet_wrap(~kernel,ncol=8) 
p_KS.p.p.kernel <- ggplot(df_ae, aes(x=p, y=KS.p, group = Jl.p_factor)) + 
                     geom_point(aes(colour=Jl.p_factor, shape=Jl.p_factor),size=3) + geom_smooth(method="lm", se=FALSE, aes(colour=Jl.p_factor)) + 
                     scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none") + 
                     theme(strip.background=element_rect(fill="black")) + theme(strip.text=element_text(color="white", face="bold")) +
                     facet_wrap(~kernel,ncol=8) 
p_GOF.p.kernel <- ggplot(df_ae, aes(x=p, y=GOF, group = Jl.p_factor)) + 
                    geom_point(aes(colour=Jl.p_factor, shape=Jl.p_factor),size=3) + geom_smooth(method="lm", se=FALSE, aes(colour=Jl.p_factor)) + 
                    scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none") + 
                    theme(strip.background=element_rect(fill="black")) + theme(strip.text=element_text(color="white", face="bold")) +
                    facet_wrap(~kernel,ncol=8) 
p_KS.abund.p.kernel <- ggplot(df_ae, aes(x=p, y=log(KS.abund), group = Jl.p_factor)) + 
                         geom_point(aes(colour=Jl.p_factor, shape=Jl.p_factor),size=3) + geom_smooth(method="lm", se=FALSE, aes(colour=Jl.p_factor)) + 
                         scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none") + 
                         theme(strip.background=element_rect(fill="black")) + theme(strip.text=element_text(color="white", face="bold")) +
                         facet_wrap(~kernel,ncol=8) 
p_KS.ac.obs.p.kernel <- ggplot(df_ae, aes(x=p, y=KS.ac.obs, group = Jl.p_factor)) + 
                          geom_point(aes(colour=Jl.p_factor, shape=Jl.p_factor),size=3) + geom_smooth(method="lm", se=FALSE, aes(colour=Jl.p_factor)) + 
                          scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none") + 
                          theme(strip.background=element_rect(fill="black")) + theme(strip.text=element_text(color="white", face="bold")) +
                          facet_wrap(~kernel,ncol=8)  
p_KS.ac.sim.p.kernel <- ggplot(df_ae, aes(x=p, y=KS.ac.sim, group = Jl.p_factor)) + 
                          geom_point(aes(colour=Jl.p_factor, shape=Jl.p_factor),size=3) + geom_smooth(method="lm", se=FALSE, aes(colour=Jl.p_factor)) + 
                          scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none") + 
                          theme(strip.background=element_rect(fill="black")) + theme(strip.text=element_text(color="white", face="bold")) +
                          facet_wrap(~kernel,ncol=8) 
p_KS.obs.sim.p.kernel <- ggplot(df_ae, aes(x=p, y=KS.obs.sim, group = Jl.p_factor)) + 
                          geom_point(aes(colour=Jl.p_factor, shape=Jl.p_factor),size=3) + geom_smooth(method="lm", se=FALSE, aes(colour=Jl.p_factor)) + 
                          scale_shape_manual(values=LETTERS[1:10]) + theme_bw() + theme(legend.position="none") + 
                          theme(strip.background=element_rect(fill="black")) + theme(strip.text=element_text(color="white", face="bold")) +
                          facet_wrap(~kernel,ncol=8) 
# lay <- matrix(rep(1:8,8),ncol=8)
# grid.arrange(p_U.p.kernel,
#              p_KS.p.kernel,p_KS.p.p.kernel,p_GOF.p.kernel,
#              p_KS.abund.p.kernel,p_KS.ac.obs.p.kernel,p_KS.ac.sim.p.kernel,p_KS.obs.sim.p.kernel,
#              ncol = 8, nrow = 8, layout_matrix = lay)
# U, KS, KS.p, GOF #
lay <- matrix(rep(1:4,8),ncol=8)
grid.arrange(p_U.p.kernel,
             p_KS.p.kernel,p_KS.p.p.kernel,p_GOF.p.kernel,
             ncol = 8, nrow = 4, layout_matrix = lay)
```

```{r fig.width=15, fig.height=20}
# KS, KS._ #
lay <- matrix(rep(1:4,8),ncol=8)
grid.arrange(p_KS.abund.p.kernel,p_KS.ac.obs.p.kernel,p_KS.ac.sim.p.kernel,p_KS.obs.sim.p.kernel,
             ncol = 5, nrow = 8, layout_matrix = lay)
```




#
```{r}
plot(S.obs ~ fitofisio, df_md)
```
