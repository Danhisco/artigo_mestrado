---
title: "Relatorio de obtenção dos resultados"
author: "Mori, Danilo"
date: "29/10/2019"
output: 
  html_document:
    toc: true
    toc_depth: 5
---

<style>
body {
text-align: justify}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, tidy = FALSE, include = TRUE, warning = FALSE,cache = FALSE,message=FALSE,eval=FALSE)
knitr::opts_knit$set(root.dir = "~/Documentos/Doutorado/artigo_mestrado/1A.P_MOVER/simulacao/")
setwd("~/Documentos/Doutorado/artigo_mestrado/1A.P_MOVER/simulacao/")
```

```{r pacotes,eval=TRUE}
library(doMC)
library(GUILDS)
library(lme4)
library(merTools)
library(magrittr)
library(gridExtra)
library(ggplot2)
library(stringr)
library(tidyr)
library(plyr)
library(purrr)
library(dplyr)
```


# Seleção e Preparo dos Sítios de Amostragem

## Dados Disponíveis

### Seleção dos trabalhos fitossociológicos

__Filtros gerais:__  
i) effort >= 1ha; ii) DBH>=5cm; iii) ano dos dados >= 2000;

__Filtros condicionais:__  
i) state %in% Rio de Janeira, Rio Grande do Sul -> ano dos dados >= 1990  
ii) state %in% Bahia, Goiás, Mato Grosso do Sul -> ano dos dados >= 2000  
iii) para as demais regiões ->  ano dos dados>= 1995  
iv) Exceções a esse esquema ocorreram quando trabalhos foram feitos antes do ano de 2000 em grandes áreas de regiões protegidas (>1000ha) ou em antigos campi universitários.  

```{r filtros references}
### dados
df_references <- read.csv(file="/home/danilo/Documentos/Doutorado/artigo_mestrado/1A.P_MOVER/dados_brutos/references - TreeCo.csv",
                          as.is = TRUE,header =T, na.strings = c("","NA"))
### filtro geral
df_1ofiltro <- df_references %>% filter(method=="parcelas" &
                                         grepl("*contiguous*",arrangement) & 
                                        effort_ha>=1 &
                                         grepl("*yes*",status) & 
                                         grepl("ok*",status_diagnostico) &
                                         grepl("Atlantic_Forest*",domain) &
                                        dbh_cutoff %in% c("PBH>=15.0cm","PBH>=15.7cm",
                                                          "DBH>=5.0cm","DGH>=5.0cm",
                                                          "DBH>=4.8cm",
                                                          "DBH>=5.0cm&H>300cm","DBH>=5.0cm&H>500cm", 
                                                          "DGH30>=5.0cm") )
### filtro universidades e campi
df_simulacao_s_UCprotecao.integral <- df_1ofiltro %>% 
  filter(UC_area_ha >= 1000 & 
         Unidade_de_conservacao == "universities and research centers")
### filtro estados
df_simulacao_filtro.estate <- filter(df_1ofiltro,state %in% c("RJ","RS") & year >= 1990)
df_simulacao_filtro.estate %<>% rbind(.,filter(df_1ofiltro,state %in% c("BA","GO","MS") & year >= 2000)) %>% 
  unique
df_simulacao_filtro.estate %<>% rbind(.,filter(df_1ofiltro,!(state %in% c("BA","GO","MS","RJ","RS")) & year >= 1995)) %>% 
  unique
### unindo e salvando
df_ref.S_UCprotecaoIntegral <- rbind(df_simulacao_s_UCprotecao.integral,df_simulacao_filtro.estate) %>% 
  distinct()
```


### SADs obs

- A SAD obs conta com a abundância dos indivíduos mortos em pé, que foram desconsiderados para a parametrização das simulações.  

```{r tratamento}
# SAD obs
df_SAD.obs <- read.csv(file="/home/danilo/Documentos/Doutorado/artigo_mestrado/1A.P_MOVER/dados_brutos/abundances.csv",header = TRUE,as.is = TRUE)
df_SAD.obs$SiteCode %<>% as.factor()
df_SAD.obs %<>% filter(species.correct != "Mortas") %>% select(SiteCode,RefID,ordem,species.correct,N) #%>% group_by(SiteCode,RefID,ordem) %>% nest
names(df_SAD.obs)[2] <- "refID"
# merge
df_dados.disponiveis %<>% inner_join(x=.,
                                     y=ddply(df_SAD.obs,"SiteCode",summarise,
                                            Ntotal=sum(N), Stotal=length(species.correct)),
                                     by="SiteCode")

```


### Raster de Paisagem

- Os rasters de paisagem atualizados são para áreas > 5km2.  
- A resolução dos arquivos é de 30x30m e o lado da paisagem é de 800 pixels.  
- Selecionei os 200 pixels centrais, assim obtive paisagens de 6x6km.  

```{r png to tif}
func_tif.png <- function(file){
  raster <- raster(file) #leitura do raster
  # raster <- raster(df_dados.disponiveis$tif.name[df_dados.disponiveis$SiteCode=="MGuberl3"])
  mat_raster <- matrix(data = getValues(raster)/100) #convertendo para matrix
  dim(mat_raster) <- dim(raster)[1:2]
  #recorte de 6x6km: os 200x200 pixeis centrais
  mat_raster <- mat_raster[301:500,301:500]
  squash::savemat(x = mat_raster, filename = gsub(".tif",".png", file)) #salvando como png
}
registerDoMC(3)
# df_dados.disponiveis %>% filter(is.na(tif.name))
a_ply(df_dados.disponiveis$tif.name,1,func_tif.png,.parallel = TRUE) #gera 113 .png, oriundos dos .tif
```

- Ajustei a resolução das imagens de tal modo que o total de pixels na paisagem = DA_{obs} * Area_{paisagem}

```{r ajuste resolucao}
func_png.ajust <- function(file, densidade, A_landscape=600){ # atualizar para o pacote 'magick'
  system(paste(
    "convert ",file, " -resize ", densidade*A_landscape,"@ ", file,  
    sep = ""
  ))
}
df_dados.disponiveis %<>% mutate(DA=Ntotal/effort_ha) # portanto exclui os indivíduos mortos
registerDoMC(3)
a_ply(df_dados.disponiveis,1,function(x) func_png.ajust(file = x$png.name, densidade = x$DA), .parallel = TRUE) # ajuste da resolucao em funcao da densidade

```

- então aplico o seguinte tratamento nas imagens:

i) pixels com cobertura vegetal >= 70% em unidades de habitat e abaixo unidades de não-habitat  
ii) função focal para tapar buracos e apagar fragmentos com apenas 1 unidade de habitat   
iii) função 'area simulada', que marca unidades de habitat que serão seguidas na simulação coalescente:  
  a) define-se uma janela de observação; A_{janela de observação} ~ 2.25 A_{sitio de amostragem} ;  
  b) esta janela é posicionada na região central da paisagem ;  
  c) a função marca as unidades de habitat pressupondo uma espiral quadrada divergente que se inicia no pixel central da paisagem ;  
  d) unidades de não-habitat não são marcadas.  

```{r f_mat_tri}
f_area.simulada <- function(matriz, N){
#@ matriz :: objeto matriz que representa
#@ N:: tamanho da amostra de indivíduos
  # Janela de observação
  d <- ceiling(sqrt(N)*(3/4)) # metade do lado do janela de observação
  l <- ceiling(dim(matriz)[1]/2) # linha central da paisagem
  c <- ceiling(dim(matriz)[2]/2) # coluna central da paisagem
  # define uma janela central na paisagem onde o for sera aplicado
  m_temp <- matriz[(l-d):(l+d),(c-d):(c+d)]
  if(length(m_temp[m_temp==1]) < N) { 
    stop("habitat insuficiente na janela de observação")
  # tambem deve estar errado, pois janela de observacao ~ 2.25A_sitio
  } else if (length(m_temp[m_temp==1]) == N) { 
    stop("area amostral igual janela de observacao")
  # paisagens que devem estar adequadas para os métodos:
  } else { 
    # posição de cada elemento da janela de observação, por coluna em ordem crescente
    col_cresc <- which(m_temp==m_temp, arr.ind = T)
    # idem na ordem contrária
    col_decre <- col_cresc[dim(col_cresc)[1]:1,]
    # posicao de cada elemento, por linha em ordem crescente
    row_cresc <- col_cresc[order(col_cresc[,1],decreasing = FALSE),] 
    # idem ao controario
    row_decre <- row_cresc[dim(col_cresc)[1]:1,] 
    # (nrow - 1)/2; exclui a posição dos elementos da coluna central da janela de observação
    ciclo <- (dim(m_temp)[1]-1)/2 # 
    l_mat_index <- list() #lista que vou usar dentro do for
    dim_temp <- dim(m_temp)[1]
    for(i in 1:ciclo){
      a1 <- col_cresc[col_cresc[,"col"]==i,] #considerando o primeiro ciclo: 1a coluna em ordem crescente
      b1 <- row_cresc[row_cresc[,"row"]==dim_temp+1-i,] #última linha em ordem crescente 
      c1 <- col_decre[col_decre[,"col"]==dim_temp+1-i,] #última coluna em ordem reversa
      d1 <- row_decre[row_decre[,"row"]==i,] #primeira linha em ordem reversa; os demais ciclos são com a segunda coluna, penúltima linha, penúltima coluna e segunda linha, etc  
      l_mat_index[[i]] <- do.call(rbind,list(a1,b1,c1,d1)) #ao final de cada ciclo eu concateno tudo em uma única matriz
    }
    l_mat_index[[(dim_temp+1)/2]] <- col_cresc[col_cresc[,"col"]==(dim_temp+1)/2,] #a coluna central deve ser a última
    mat_ref <- unique(do.call(rbind, l_mat_index)) #remocao de repeticao. Obtenho uma sequência de elementos que descreve uma espiral quadrada convergente
    length_ref <- length(m_temp[mat_ref][m_temp[mat_ref]==1]) #variável para indexação:
    m_temp[mat_ref][m_temp[mat_ref]==1][(1+length_ref-N):length_ref] <- 2 #os N últimos elementos que são iguais a 1 e troco por 2
    matriz[(l-d):(l+d),(c-d):(c+d)] <- m_temp #substituo a matriz de volta
    return(matriz)
  }
}

f_mat.tri <- function(png, abund){ #png.file, número de indivíduos presente 
  janela <- matrix(1,3,3) 
  raster <- raster(png)
  mat <- matrix(getValues(raster)/255, ncol = ncol(raster), nrow = nrow(raster))
  raster_binario <- raster( matrix(nrow = nrow(mat), ncol = ncol(mat), sapply(mat, function(x) ifelse(x >= 0.7, 1, 0)) ) ) 
  func_focal <- function(x) ifelse(sum(x[x==1]) >= 5, 1, x[5])
  binario.focal <- as.matrix( focal(raster_binario, janela, func_focal, pad=TRUE, padvalues = 0))
  mat_tri <- try(f_area.simulada(matriz = binario.focal, N = abund))
  if(class(mat_tri) == "matrix"){ 
    try(write.table(x = mat_tri, 
                    file = gsub(".png",".txt", png),
                    sep = " ", row.names = FALSE, col.names = FALSE))
  }
}
df_dados.disponiveis$png.name %<>% as.character
registerDoMC(3)
a_ply(df_dados.disponiveis,1,function(X) f_mat.tri(png = X$png.name,abund = X$Ntotal),.parallel = TRUE)
```


- Essa rotina gera paisagens onde a comunidade local é representada exatamente por um quadrado (figura 1).  
- Em outros casos a particular configuração espacial não permite construir a comunidade local como uma região quadrada (figura 1).

![fig1 A](/home/danilo/Documentos/Doutorado/artigo_mestrado/1A.P_MOVER/figuras/conserto_paisagens/comunidade_local_quadrada.png){ width=37.5% }
![fig1 B](/home/danilo/Documentos/Doutorado/artigo_mestrado/1A.P_MOVER/figuras/conserto_paisagens/comunidade_loca_aproximada_ok.png){ width=37.5% }

__Figura 1__ Na esquerda consideramos a comunidade local como quadrada; na direita consideramos a comunidade local aproximadamente como um quadrado 

- Consideramos que os métodos são uma boa aproximação quando todo o habitat da comunidade local esta conectado.
- Para as paisagens onde o habitat da comunidade local esta fragmentado em fragmentos florestais vizinhos, eu removi o habitat isolado e marquei quantidade equivalante de habitat adjacente à comunidade local:

```{r rotina de conserto das paisagens}
par(mar=c(0.2,0.2,1.2,0.2))
i <- 1 #nrow = 9
N <- df_conserto.land$N[i]
paisagem <- as.matrix(read.table(df_conserto.land$txt.name[i],header = TRUE,sep = " ",as.is = FALSE))
# janela de observação:
d <- ceiling(sqrt(N)*(3/4))  # metade do lado do janela de observação
l <- ceiling(dim(paisagem)[1]/2) # linha central da paisagem
c <- ceiling(dim(paisagem)[2]/2) # coluna central da paisagem
# janela de observação:
janela_observao <- paisagem[(l-d):(l+d),(c-d):(c+d)]
###############################
########### região para remover
###############################
## objetos
#visualização
image(janela_observao,main=df_conserto.land$SiteCode[i],col=terrain.colors(12,rev = TRUE))
coordenada_ <- locator(1) %>% unlist()
l_ <- round(coordenada_[1]*nrow(janela_observao))
c_ <- round(coordenada_[2]*ncol(janela_observao))
n_ <- 5
## auditoria visual
image(janela_observao[(l_-n_):(l_+n_),(c_-n_):(c_+n_)],
      main=df_conserto.land$SiteCode[i],col=terrain.colors(12,rev = TRUE))
## para aqueles sem o habitat central como 1:
# janela_observao[(l_-n_):(l_+n_),(c_-n_):(c_+n_)] <- 2
## janela de conversao de 2->1
#1
p_arrumar <- janela_observao[(l_-n_):(l_+n_),(c_-n_):(c_+n_)]
rm_ <- p_arrumar[p_arrumar==2] %>% length()
p_arrumar[p_arrumar==2] <- 1
janela_observao[(l_-n_):(l_+n_),(c_-n_):(c_+n_)] <- p_arrumar
#2
# p_arrumar <- janela_observao[(l_-n_):(l_+n_+2),(c_-n_):(c_+n_)]
# rm_ <- length(p_arrumar[p_arrumar==2]) + rm_
# p_arrumar[p_arrumar==2] <- 1
# janela_observao[(l_-n_):(l_+n_+2),(c_-n_):(c_+n_)] <- p_arrumar
######################################
########### região para incluir 1 -> 2
######################################
# length(rm_)
## 
image(janela_observao)
coordenada_ <- locator(1) %>% unlist()
l_ <- round(coordenada_[1]*nrow(janela_observao))
c_ <- round(coordenada_[2]*ncol(janela_observao))
n_ <- 2
janela_observao[(l_-n_):(l_+n_),(c_-n_):(c_+n_)] # %>% image
# para aqules com ponto central = 1
# janela_observao[l_+1,c_+1] <- 1
# exemplo: o ponto de inicío é [4,3] e o ponto l_,c_ é [3,3] portanto em termos de l_,c_: 
p_inicio <- c(l_+1,c_+1)
# correr pela ___ até o ponto:
image(janela_observao)
coordenada_ <- locator(1) %>% unlist()
l_ <- round(coordenada_[1]*nrow(janela_observao))
c_ <- round(coordenada_[2]*ncol(janela_observao))
n_ <- 2
janela_observao[(l_-n_):(l_+n_),(c_-n_):(c_+n_)] # %>% image
p_final <- c(l_+1,c_)
# trocando 1 -> 2
p_rm_ <- janela_observao[p_inicio[1]:p_final[1],p_inicio[2]:p_final[2]] %>% length()
# if
p_rm_ < rm_
 janela_observao[p_inicio[1]:p_final[1],p_inicio[2]:p_final[2]] <- 2
 rm_ <- rm_ - p_rm_
# else 
 janela_observao[p_inicio[1]:p_final[1],p_inicio[2]:p_final[2]][1:rm_] <- 2

## outro
# pontos_p_marcar <- janela_observao[p_inicio[1]:p_final[1],p_inicio[2]:p_final[2]]
# pontos_p_marcar[pontos_p_marcar==1][1:length(rm_)] <- 2
# janela_observao[p_inicio[1]:p_final[1],p_inicio[2]:p_final[2]] <- pontos_p_marcar 
# image(janela_observao)
# auditoria e gravar
image(paisagem[(l-d):(l+d),(c-d):(c+d)],
      main=paste(df_conserto.land$SiteCode[i], "antes"),
      col=terrain.colors(12,rev = TRUE))
image(janela_observao,
      main=paste(df_conserto.land$SiteCode[i], "consertada"),
      col=terrain.colors(12,rev = TRUE))
paisagem[(l-d):(l+d),(c-d):(c+d)] <- janela_observao
image(paisagem,main=df_conserto.land$SiteCode[i],col=terrain.colors(12,rev = TRUE))
write.table(paisagem,
            file=df_conserto.land$txt.name[i],
            row.names = FALSE,col.names = FALSE)

```

Um exemplo de paisagem modificada esta na figura 2.

![](/home/danilo/Documentos/Doutorado/artigo_mestrado/1A.P_MOVER/figuras/conserto_paisagens/MGuberl7_antes.png){ width=37.5% }
![](/home/danilo/Documentos/Doutorado/artigo_mestrado/1A.P_MOVER/figuras/conserto_paisagens/MGuberl7_consertada.png){ width=37.5% }

__Figura 2__ Exemplo de modificação realizada para poder aproximar a paisagem pelos métodos utilizados.

Por conta da função focal a paisagem esta cercada por NAs (linhas e colunas marginais), então removo-as utilizando:

```{r remocao de NAs}
f_NA_zero <- function(path_){
  mat_paisagem <- read.table(file=path_,header = FALSE)
  mat_paisagem[is.na(mat_paisagem)] <- 0
  write.table(x = mat_paisagem,file = path_,sep = " ", row.names = FALSE, col.names = FALSE)
}
```


## Parametrização 

A relação entre os parâmetros de diversidade pode ser obtida a partir da igualdade proposta por por Vallade & Houchmandzadeh (2003) $\theta = \frac{U  (J_M - 1)}{1-U}$. Para isso aproximamos o número de indivíduos na metacomunidade como $J_M = A_{landscape}  DA_{obs} p$.  
  
  
  O parâmetro m é a probabilidade de um evento de colonização na comunidade local ser por um propágulo da metacomunidade (Hubbel 2001). Uma vez que toda unidade de habitat apresenta igual probabilidade de colonização, podemos definir m como a média das probabilidades de cada sítio na comunidade local ser colonizada por um imigrante (eq 1; Chisholm & Lichstein 2009).

$$ eq 1: m = \frac{1}{A} \int \int_A m_{x,y} dxdy $$  

 Aproximamos as comunidades locais como áreas quadradas com lado L, que pode ser obtido por $L = \sqrt{10000\frac{J}{DA}}$. Assim podemos reescrever a equação 1 como:

$$ eq 2.a :   m = \left(\frac{1}{L} \int\limits_{-L/2}^{L/2} m_{x}(x)\mathrm{d}x \right)^2 $$

$$ eq 2.b :m_{x} = 1 - \int\limits_{-L/2}^{L/2} K(x-y) \mathrm{d}y $$ 

  Onde K é a função de dispersão. Na simulação coalescente a dispersão resulta do sorteio indepentende de duas distribuições de Laplace em eixos ortogonais centradas no sítio vago (figura X). Se consideramos a distribuição de Laplace como $K(x) = \frac{\alpha}{2} e^{-|\alpha x|}$ (idem para o eixo y), então:

$$eq3:m = (\frac{1-e^{-\alpha L}}{\alpha L})^2$$ 

Onde $\alpha = 1/b$, b é o parâmetro escalar da distribuição de Laplace que pode ser escrito em função do desvio-padrão da distribuição de Laplace (d) $b = d/ \sqrt{2}$. O desvio padrão corresponden à distância média de dispersão (Clark et al. 1999). Podemos reescrever a equação de m em funçao de d:

$$ eq4: m = d \frac{1 - e^{-\frac{\sqrt{2} L}{d}} }{\sqrt{2} L} $$ 

Com a equação 4 podemos calcular m a partir do desvio padrão da função de dispersão. Essa equação é válida para o processo de dispersão em paisagens homogêneas. Na simulação coalescente, uma vez que sorteamos um progenitor e este estaria presente em uma unidade de não habitat, o sorteio é refeito até que o progenitor esteja em uma unidade de habitat. Uma aproximação do efeito da fragmentação na simulação no m calculado a partir da equação 4 pode ser obtido por:

$$eq.5: m' = \frac{mp}{1 - (1-p)m} $$

Onde _p_ é a porcentagem de cobertura vegetal na paisagem. Caso seja necessário calcular d a partir de m, utilizamos o ramo principal da função W de Lambert ($W_{0}$):

$$ eq6 : d = \frac{\sqrt{2} L m}{m W_{0}(- \frac{e^{-1/m}}{m} ) + 1} $$ 


### Proporção de cobertura vegetal 

Para calcular a proporção de cobertura vegetal utilizei a função:

```{r tree cover}
f_tree.cover <- function(file_path){
  mat_paisagem <- read.table(file=file_path,sep=" ",header=TRUE)
  tree.cover <- as.vector(mat_paisagem)
  tree.cover <- tree.cover[!is.na(tree.cover)]
  p <- 1 - length(tree.cover[tree.cover==0])/length(tree.cover)
  return(p)
}
registerDoMC(4)
df_simulacao$p <- aaply(df_simulacao$txt.name,1,f_tree.cover,.parallel = TRUE)
# 
```


A relação entre proporção de habitat (p) e riqueza observada (S) esta na figura 3.

```{r relacao p e S,eval=TRUE,echo=FALSE,fig.width=8,fig.height=3}
### dados
df_resultados <- read.table(file="./resultados/df_resultados.csv",header = TRUE,sep = ";",dec = ".",as.is=FALSE)
level_k <- unique(as.character(df_resultados$k))
df_resultados$k <- factor(as.character(df_resultados$k),levels = level_k)
levels(df_resultados$k)[19] <- "0.1"
### graficos
df_plot <- df_resultados %>% dplyr::filter(k=="0.99" & MN=="EE") %>% dplyr::select(SiteCode, p, Stotal) %>% unique
l_p <- vector("list",3)
l_p[[1]] <- ggplot(df_plot, aes(x=p)) +
  geom_histogram(bins=30) +
  geom_vline(xintercept = c(quantile(df_plot$p,probs = c(0.25,0.50,0.75))),color="red")
l_p[[2]] <- ggplot(df_plot, aes(x=Stotal)) +
  geom_histogram(bins=30) +
  geom_vline(xintercept = quantile(df_plot$Stotal,probs = c(0.25,0.50,0.75)),color="red")
l_p[[3]] <- ggplot(df_plot, aes(x=p,y=Stotal)) +
  # geom_hline(yintercept = quantile(df_plot$Stotal,probs = c(0.25,0.50,0.75)),color="red") +
  # geom_vline(xintercept = quantile(df_plot$p,probs = c(0.25,0.50,0.75)),color="red") +
  geom_point() # + 
  # geom_smooth(method="lm")
do.call("grid.arrange",c(l_p,ncol=3))
```

__Figura 3__ Distribuição de p, s e relação entre as duas variáveis. As linhas verticais em vermelho marcam respectivamente o quantil de 25, 50 e 75% da distribuição.

### Parâmetro de dispersão

Parametrizamos por k, a proporção de propágulos que permanecem até a vizinhança imediata da planta progenitora. A estimativa da distância média de dispersão para o respectivo k para cada paisagem foi obtida pelas funções:

```{r funcoes para estimar d necessario para respectivo k}
library(rmutil)
library(lamW)
qkernel<- function(sigma, kernel, p, density=20852/50, npoints = 1e5){
    kernel <- match.arg(kernel, choices=c("normal","gaussian","laplace","uniform"))
    d_ind_MA  <- 100/sqrt(density)
    if(kernel=="laplace"){
        b_laplace <- sigma / sqrt(2)
        X_laplace <- d_ind_MA * round(rlaplace(npoints, s=b_laplace) / d_ind_MA) 
        Y_laplace <- d_ind_MA * round(rlaplace(npoints, s=b_laplace) / d_ind_MA)
        dist_laplace <- sqrt(X_laplace^2+Y_laplace^2)
        result <- quantile(dist_laplace, p)
    }
    if(kernel=="normal"|kernel=="gaussian"){
        b_norm <- sigma 
        X_norm <- d_ind_MA * round(rnorm(npoints, sd=b_norm) / d_ind_MA)
        Y_norm <- d_ind_MA * round(rnorm(npoints, sd=b_norm) / d_ind_MA)
        dist_norm <- sqrt(X_norm^2+Y_norm^2)
        result <- quantile(dist_norm, p)
    }
    if(kernel=="uniform"){
        b_unif <- sigma/2
        X_unif <- d_ind_MA * round(runif(npoints, min = -b_unif, max = b_unif) / d_ind_MA)
        Y_unif <- d_ind_MA * round(runif(npoints, min = -b_unif, max = b_unif) / d_ind_MA)
        dist_unif <- sqrt(X_unif^2+Y_unif^2)
        result <- quantile(dist_unif, p)
    }
    return(unname(result))
}

sigkernel <- function(kernel, p, distance, density=20852/50,
                      npoints =1e5, sigma.min = 1, sigma.max= 100){
    f1 <- function(x) distance - qkernel(x, kernel, p, density, npoints)
    uniroot( f1 , lower = sigma.min, upper = sigma.max)
}
```

Utilizamos os percentis: c(0.99,seq(0.95,0.05,-0.05)) (figura 4)

```{r figura 4 relacao k e d, fig.width=5,fig.height=4,eval=TRUE,echo=FALSE}
df_resultados %>% ggplot(aes(x=k,y=d)) +
  geom_jitter() +
  geom_boxplot() +
  labs(x="% de propágulos na vizinhança imediata",y="Distância média de dispersão (metros)")
```

__Figura 4__ Distância média de dispersão em metros (d) ~ porcentagem de propagulos até a vizinhança imediata (k)


# Simulação

A simulação coalescente foi construida em C++ e uma função em R foi utilizada para alimentar a simulação:

```{r dinamica coalescente beta}
dinamica_coalescente <- function(U, S=0, N_simul, seed, disp_range, disp_kernel, landscape){
  # Runs coalescent simulations for a given heterogeneous landscape
  #
  # Parameters:
  # U: speciation rate
  # S: observed richness (integer) - used to fit the value of U, or set to
  #       0 (default) if that is not desired
  # N_simul: number of simulations
  # seed: seed of the RNG (an integer)
  # disp_range: width of the dispersal kernel
  # disp_kernel: an integer corresponding to the type of dispersal kernel. One of
  #               0: uniform
  #               1: normal
  #               2: Laplacian
  # landscape: either a filename containing the landscape data, or a
  #   bidimensional R array or matrix.
  #   TODO: describe the format of the input - trinary matrix)
  #
  # Returns:
  # r: an array of dimension N_simul x landscape dimensions, that is, each
  #   r[i.,] is a bidimensional array of the same shape as the landscape.
  #   Each site is labeled according to the identity of the species occupying
  #   that site.
  # U_est: estimated speciation rate. This is returned only if input parameter S > 0
  if (is.character(landscape)){
    l <- as.matrix(read.table(landscape))
    infile <- landscape
    land_dims <- dim(l)
  } else {
    land_dims <- dim(landscape)
    infile <- tempfile()
    # input file *must* be clean: no comments, headers or anything
    write.table(landscape, infile, col.names=F, row.names=F)
  }
  outfile <- tempfile()
  repeat {
    system(paste('./dinamica_coalescente', land_dims[1], land_dims[2], U, S, N_simul,
                 seed, disp_range, disp_kernel, infile, outfile))
    if (file.exists(outfile) || S == 0)
      break
    U <- U/10.
    print(paste("Decreasing value of U to", U))
    # set some lowest boundary here so simulations don't take forever
    if (U < 1e-20){
      print("Richness value too low, giving up...")
      return(NULL)
    }
  }
  r <- as.matrix(read.table(outfile))
  # transpose each grid, as output is written along lines but R reads it along columns
  # TODO: I thought I got it right, but it was wrong... please DO re-check
  #r <- aperm(r, c(1,3,2))
  
  # recover estimated speciation rate
  if (S > 0){
    out_con <- file(outfile)
    U_line <- strsplit(readLines(out_con, 2)[2], ' ')[[1]]
    close(out_con)
    U_est <- as.double(U_line[length(U_line)])
    return(list(r = r, U_est = U_est))
  }
  return(r)
}

```



## Estimativa de U

Foram utilizadas 10 réplicas para estimar U:

```{r estimativa de U}
# replicas
n_rep.U <- 10
func1 <- function(x,replicas=n_rep.U) {
  x$U <- NA
  x <- x[rep(1:dim(x)[1],each=replicas),]
}
df_referencia %<>% func1()
# simulacao
# valores de k
k_factor <- unique(df_referencia$k)
registerDoMC(n_cores)
for(a in 1:length(k_factor)){
  df_simU <- df_referencia %>% dplyr::filter(k == k_factor[a])
  op <- options(digits.secs=6)
  funcao_imigracao <- function(i,df_temp=df_simU){
    aviao <- list()
    aviao <- dinamica_coalescente(U = 1.25e-06, 
                                  S = df_temp[i,"Stotal"], 
                                  N_simul = 1, 
                                  seed = as.numeric(Sys.time()), 
                                  disp_range = df_temp[i,"d"], 
                                  disp_kernel = df_temp[i,"kernel_code"], 
                                  landscape = df_temp[i,"txt.name"])
    return(aviao$U_est)
  }
  replica.sim <- as.list(1:dim(df_simU)[1])
  sim.coal_U <- llply(.data = replica.sim, .fun = funcao_imigracao, .parallel = TRUE)
  df_simU[,"U"] <- unlist(sim.coal_U)
  write.csv(df_simU, 
            file=paste0("./U/","df_simU__k",k_factor[a],".csv"),row.names = FALSE)
}
```

Então calculou-se a média e variância por SiteCode e k (a maior variância foi na casa dos e-06). O U médio foi utilizado para parametrizar as predições de MNEE e MNEI (figura 6).

```{r U padroes gerais, eval=TRUE,echo=FALSE,fig.height=10}
# dados
df_resultados <- read.table(file="./resultados/df_resultados.csv",header = TRUE,sep = ";",dec = ".",as.is=FALSE)
level_k <- unique(as.character(df_resultados$k))
df_resultados$k <- factor(as.character(df_resultados$k),levels = level_k)
levels(df_resultados$k)[19] <- "0.1"
# graficos
l_p <- vector("list",3)
l_p[[1]] <- ggplot(df_resultados,aes(x=log(Stotal),y=U_med)) + 
  geom_point() +
  geom_smooth() +
  theme(axis.title.y = element_blank(),
        axis.ticks.y = element_blank())
l_p[[2]] <- ggplot(df_resultados,aes(x=k,y=U_med,group=k)) + 
  geom_jitter() + 
  geom_boxplot()
l_p[[3]] <- ggplot(df_resultados,aes(x=p,y=U_med)) + 
  geom_point() + 
  geom_smooth() +
  facet_wrap(~k,ncol=4,scales="free")
grid.arrange(l_p[[1]],l_p[[2]],l_p[[3]],
             layout_matrix = rbind(c(2,2,2,1),
                                   c(3,3,3,3),
                                   c(3,3,3,3))
             )

```

__Figura 5__ Padrões gerais de U.  


## SAD predita

### MNEE  

Para obter as SADs preditas por MNEE utilizei o seguinte código

```{r SADs MNEE}
f_simulacao <- function(i,df_=df_simulacao){
  X <- df_[i,]
  mat_sim <- dinamica_coalescente(U = X[,"U_med"], 
                                  S = 0, 
                                  N_simul = n_rep.SAD, 
                                  seed = as.numeric(Sys.time()), 
                                  disp_range = X[,"d"], 
                                  disp_kernel = X[,"kernel_code"], 
                                  landscape = X[,"txt.name"])
  l_SADs.preditas <- alply(mat_sim,1,function(Y) sort(as.integer(table(Y))) )
  file_name <- gsub("/home/danilo/Documentos/Doutorado/artigo_mestrado/1A.P_MOVER/simulacao/","",
                    X[,"txt.name"])
  file_name <- gsub(".txt","",file_name)
  path.file <- paste0(getwd(),"/SADs_preditas/",file_name,"__k",X[,"k"],".EE.", "rep_",1:length(l_SADs.preditas),".csv")
  for(j in 1:length(l_SADs.preditas)){
    write.csv(data.frame(SAD_predita = l_SADs.preditas[[j]]),
              file=path.file[j],
              row.names = FALSE)
  }
}
registerDoMC(4)
simulacao <- as.list(1:dim(df_simulacao)[1])
l_ply(simulacao,f_simulacao,.parallel = TRUE)
```

### MNEI  

Para MNEI:

```{r SADs MNEI}
# preparação dos dados
df_simulacao %<>% mutate(L_plot = 100*sqrt(Ntotal/DA),
                         m = d * ( 1 - exp(-L_plot*sqrt(2)/d) ) / (L_plot*sqrt(2)), 
                         m_ = m * p / (1 - (1-p) * m),
                         I = m_ * (Ntotal-1)/(1-m_),
                         J_M=p*DA*3600,
                         theta=(U_med*(J_M-1))/(1-U_med))
# simulação
f_simulacaoEI <- function(i,df_=df_simulacao){
  # i <- 1
  # n_rep.SAD <- 100
  df_name <- df_[i,]
  l_SADs <- replicate(n_rep.SAD,generate.ESF(theta = df_name$theta, I = df_name$I, J = df_name$Ntotal))
  file_name <- gsub("/home/danilo/Documentos/Doutorado/artigo_mestrado/1A.P_MOVER/simulacao/","",
                    df_name[,"txt.name"])
  file_name <- gsub(".txt","",file_name)
  path.file <- paste0(getwd(),"/SADs_preditas/",file_name,"__k",df_name[,"k"],".EI.", "rep_",1:length(l_SADs),".csv")
  for(j in 1:length(l_SADs)){
    write.csv(data.frame(SAD_predita = l_SADs[[j]]),
              file=path.file[j],
              row.names = FALSE)
  }
}
registerDoMC(4)
simulacao <- as.list(1:dim(df_simulacao)[1])
l_ply(simulacao,f_simulacaoEI,.parallel = TRUE)
```

# Prévia Resultados

## Auditoria 1: auto coerrência dos dados

```{r avaliacao da auto coerrencia,, eval=TRUE,echo=FALSE}
df_resultados <- read.table(file="./resultados/df_resultados.csv",header = TRUE,sep = ";",dec = ".",as.is=FALSE)
level_k <- unique(as.character(df_resultados$k))
df_resultados$k <- factor(as.character(df_resultados$k),levels = level_k)
levels(df_resultados$k)[19] <- "0.1"
# contrasts(df_resultados$k)
# graficos
l_p <- vector("list",4)
l_p[[1]] <- ggplot(df_resultados,aes(x=p.value_mean,y=n_SAD.N.ref)) + geom_point() + geom_smooth(stat="loess") + labs(y="número de SADs não refutadas",x="p-valor médio")
l_p[[2]] <- ggplot(df_resultados,aes(x=D_mean,y=p.value_mean)) + geom_point() + geom_smooth(stat="loess") + labs(x="estatística D média",y="p-valor médio")
l_p[[3]] <- ggplot(df_resultados,aes(x=p.value_mean,y=p.value_var)) + geom_point() + geom_smooth(stat="loess") + labs(y="variância p-valor",x="p-valor médio")
l_p[[4]] <- ggplot(df_resultados,aes(x=D_mean,y=D_var)) + geom_point() + geom_smooth(stat="loess") +
   labs(x="estatística D média",y="variância estatística D")
# l_p[[5]] <- ggplot(df_resultados,aes(x=Stotal,y=S.obs_mean)) + geom_point() + geom_abline(intercept = 0,slope = 1,color="red")
# df_resultados %<>% mutate(diff_S.obs = Stotal-S.obs_mean)
# l_p[[6]] <- ggplot(df_resultados, aes(x=df_resultados$diff_S.obs)) + 
#   geom_histogram(breaks=seq(0, max(df_resultados$diff_S.obs), length.out = 40)) + 
#   labs(title="", x="S_{parametro U} - S_{do vetor KS}", y="Count")
grid.arrange(l_p[[1]], l_p[[2]], l_p[[3]], l_p[[4]], # l_p[[5]],# l_p[[6]],
             layout_matrix = rbind(c(rep(1,3),rep(2,3)),
                                   c(rep(3,3),rep(4,3))) #,
                                   # c(rep(5,3),rep(NA,3)))
             )
```

__Figura 6__ Avaliação da autocoerrência dos métodos. geom_smooth(method="loess") 

## Padrões Gerais da congruência entre predito e observado

```{r SAD preditas padroes gerais, eval=TRUE,echo=FALSE,fig.height=10}
# dados
df_resultados <- read.table(file="./resultados/df_resultados.csv",header = TRUE,sep = ";",dec = ".",as.is=FALSE)
level_k <- unique(as.character(df_resultados$k))
df_resultados$k <- factor(as.character(df_resultados$k),levels = level_k)
levels(df_resultados$k)[19] <- "0.1"
# graficos
l_p <- vector("list",4)
l_p[[1]] <- ggplot(df_resultados,aes(x=MN,y=n_SAD.N.ref)) +
  geom_jitter() +
  geom_boxplot()
l_p[[2]] <- ggplot(df_resultados,aes(x=k,y=n_SAD.N.ref,group=k)) +
  geom_jitter() +
  geom_boxplot()
l_p[[3]] <- ggplot(filter(df_resultados,
                          k %in% levels(df_resultados$k)[1:10]),
                   aes(x=p,y=n_SAD.N.ref)) +
  geom_point() + 
  geom_smooth(method="loess") + 
  facet_grid(k~MN)
l_p[[4]] <- ggplot(filter(df_resultados,
                          k %in% levels(df_resultados$k)[11:20]),
                   aes(x=p,y=n_SAD.N.ref)) +
  geom_point() + 
  geom_smooth(method="loess") + 
  facet_grid(k~MN)
grid.arrange(l_p[[1]],l_p[[2]],l_p[[3]],l_p[[4]],
             layout_matrix = rbind(c(1,2,2,2),
                                   c(3,3,4,4),
                                   c(3,3,4,4),
                                   c(3,3,4,4))
             )

```

__Figura 7__ Padrões gerais para o número de SADs não refutadas (n_SAD.N.ref). geom_smooth(method="loess")


```{r S predita e obs, eval=TRUE,echo=FALSE}
# dados
df_resultados <- read.table(file="./resultados/df_resultados.csv",header = TRUE,sep = ";",dec = ".",as.is=FALSE)
level_k <- unique(as.character(df_resultados$k))
df_resultados$k <- factor(as.character(df_resultados$k),levels = level_k)
levels(df_resultados$k)[19] <- "0.1"
# graficos
ggplot(df_resultados,aes(x=S.obs_mean,y=S.MN_mean,color=MN)) +
  geom_abline(intercept = 0,slope = 1,color="red") +
  geom_point() +
  facet_wrap(~k,ncol=4,scales="free")
```

__Figura 8__ S_predita ~ S_obs. Linha vermelha: slope=1,intercept=0


## Auditoria 2: Comparação com o conjunto de dados antigos

```{r diff resultados antigos, eval=TRUE,echo=FALSE}
# dados antigos
df_resultados.antigos <- read.csv("/home/danilo/Documentos/Doutorado/artigo_mestrado/Rmd_e_dados/df_resultados.csv",header = TRUE,as.is = TRUE)
# dados novos
df_resultados <- read.table(file="./resultados/df_resultados.csv",header = TRUE,sep = ";",dec = ".",as.is=TRUE)
# merge
# df_resultados %>% str
# df_resultados.antigos %>% str
df_auditoria <- inner_join(x=df_resultados.antigos,y=df_resultados,
                           by=c("SiteCode","MN","k"))
# df_auditoria %>% names
# padronizacao
level_k <- unique(as.character(df_auditoria$k))
df_auditoria$k <- factor(as.character(df_auditoria$k),levels = level_k)
# df_auditoria %>% str
# variáveis de auditoria
## diff = novo - antigo
df_auditoria %<>% mutate(diff_GOF = n_SAD.N.ref - GOF,
                         diff_S.mean = S.MN_mean - S_m,
                         diff_U = U_med - U,
                         diff_p = p.y-p.x,
                         diff_Ntotal = Ntotal - J,
                         diff_Stotal = Stotal - S,
                         diff_d = d.y - d.x,
                         diff_m_ = m_.y - m_.x,
                         J_M.x = DA.x * p.x * 600,
                         theta.x = (U*(J_M.x-1))/(1-U),
                         diff_theta = theta - theta.x) 
## Graficos
df_plot <- df_auditoria %>% select(SiteCode, MN, k,
                                   diff_GOF, diff_S.mean,
                                   diff_d, diff_m_, diff_U, diff_theta,
                                   diff_p, diff_Ntotal, diff_Stotal)
l_p <- vector("list",9)
## parâmetros comuns
l_p[[1]] <- ggplot(df_plot, aes(x=diff_p)) + geom_histogram(bins=40) + labs(y="contagem")
l_p[[2]] <- ggplot(df_plot, aes(x=diff_Ntotal)) + geom_histogram(bins=40) + theme(axis.title.y = element_blank())
l_p[[3]] <- ggplot(df_plot, aes(x=diff_Ntotal)) + geom_histogram(bins=40) + theme(axis.title.y = element_blank())
# do.call("grid.arrange",c(l_p,ncol=3,top="diff_ = novo - antigo"))
## parametros de cada MN 
l_p[[4]] <- ggplot(df_plot, aes(x=diff_d)) + geom_histogram(bins=40) + labs(y="contagem")
l_p[[5]] <- ggplot(df_plot, aes(x=diff_m_)) + geom_histogram(bins=40) + theme(axis.title.y = element_blank())
l_p[[6]] <- ggplot(df_plot, aes(x=diff_U)) + geom_histogram(bins=40) + theme(axis.title.y = element_blank())
l_p[[7]] <- ggplot(df_plot, aes(x=diff_theta)) + geom_histogram(bins=40) + theme(axis.title.y = element_blank())
## variávis resposta da congruência com o observado
l_p[[8]] <- ggplot(df_plot,aes(x=MN,y=diff_GOF,group=MN)) + geom_jitter() + geom_boxplot()
l_p[[9]] <- ggplot(df_plot,aes(x=MN,y=diff_S.mean,group=MN)) + geom_jitter() + geom_boxplot()
# arranjo dos plots
mat_lay <- rbind(c(1,2,3,NA),
                 c(4,5,6,7),
                 c(8,8,9,9))
grid.arrange(l_p[[1]],l_p[[2]],l_p[[3]],l_p[[4]],l_p[[5]],l_p[[6]],l_p[[7]],l_p[[8]],l_p[[9]],
             layout_matrix=mat_lay,top="diff_ = novo - antigo")
do.call("grid.arrange",c(l_p,layout_matrix=mat_lay,top="diff_ = novo - antigo"))
```

__Figura 8__ Diferença entre os parâmetros do novo conjunto de dados e do antigo.

```{r}

```

