---
title: "Relatório de Achados Gerais"
author: "Mori, Danilo Pereira"
date: "9 de setembro de 2018"
output: 
  html_document:
    toc: true
    toc_depth: 5
---

```{r setup, include=FALSE} 
knitr::opts_chunk$set(echo = FALSE, tidy = TRUE, include = TRUE, warning = FALSE,cache = TRUE)
```

```{r dados e pacotes,warning=FALSE,message=FALSE,echo=FALSE}
library(gridExtra)
library(MuMIn) # para R^2
library(sads)
library(lme4) # pacote de criação dos modelos estatísticos
library(merTools) # para intervalos de previsao
library(tidyverse)
library(broom) # para manipular os modelos
library(magrittr) # p escrita
library(DHARMa)
library(merTools)
library(plyr)
df_resultados <- read_csv("/home/danilo/Documentos/Doutorado/artigo_mestrado/Rmd_e_dados/df_resultados.csv")
# df_resultados %>% str
df_resultados$MN <- factor(df_resultados$MN,levels = c("EI","EE"))
df_resultados$SiteCode <- factor(df_resultados$SiteCode)
df_resultados$k <- factor(df_resultados$k,levels=unique(df_resultados$k))
# df_resultados$k %>% contrasts()
# df_resultados$MN %>% contrasts()

#### z score ###

f_z <- function(x){
  m <- base::mean(x,na.rm=TRUE)
  sd <- sd(x,na.rm=TRUE)
  output <- (x-m)/sd
  return(output)
} 

df_resultados %<>% mutate(GOF.z = f_z(GOF),
                          DA.z = f_z(DA),
                          p.z = f_z(p),
                          S.z = f_z(S),
                          U.z = f_z(U),
                          m_.z = f_z(m_),
                          I.z = f_z(I),
                          d.z = f_z(d),
                          k.z0 = as.numeric(as.character(k)),
                          k.z = f_z(k.z0))

names(df_resultados)[1] <- "Site"

```

## Esquema Dos Métodos

### Desenho Experimental

__i) Sítios de amostragem__

80 sítios de amostragem; amostragem de indivíduos arbóreos com DBH >= 5cm em bloco único; coordenada central do sítio de amostragem

__ii) Predições__

_Modelo Neutro Espacialmente Explícito (EE)_

Para cada combinação de parâmetros U e d, a respectiva matriz de paisagem e o modelo descrito por Rosindell et al. (2008) geramos 100 SADs réplicas

_Modelo Neutro Espacialmente Implícito (EI)_

Para cada combinação de parâmetros $\theta$ e I e a formula de amostragem desenvolvida por Etienne (2005) geramos 100 SADs réplicas

__iii) Comparação com o observado__

Cada SAD réplica foi comparada com a respectiva SAD observada no teste de Kolmogorov-Smirnov (KS). O teste KS é um teste estatístico não paramétrico da hipótese nula de que dois vetores de abundância são amostras de uma mesma distribuição teórica. Contabilizamos o número de SADs réplicas em que não foi possível refutar a hipótese nula com alfa crítico de 0.05 na variável (GOF).

### Matriz de Paisagem

i) landsat 8 => recorte de paisagem de 5 km^2 concêntrico ao sítio de amostragem (Site)
ii) ajuste de resolução da imagem tal que: densidade de pixels = densidade de indivíduos na área amostrada (DA)  
  ii.a) portanto o lado da célula (l_cel) = 100/sqrt(DA) metros
iii) se a porcentagem de cobertura vegetal do pixel for >= 70% então é unidade de habitat; caso contrário é unidade de não habitat
iv) a comunidade local é composta de J (número de indivíduos amostrados) unidades de habitat na região central do recorte de paisagem

### Função de Dispersão

i) partimos de uma distribuição de Laplace para simular a função de dispersão
ii) determinamos 12 valores de proporção de propágulos que se mantêm até l_cel metros da árvore progenitora (k): 0.99,0.95:0.50,0.25
iii) então calculou-se a distância média de dispersão (d) que gerava o correspondente percentil

### Taxa de Especiação - U

Dado matriz de paisagem e riqueza observada (S) no respectivo Site, estimamos um valor médio de taxa de especiação (U) para cada nível de k. Para está estimativa utilizamos um método semi-analítico derivado do modelo neutro de espaço explícito descrito em Rosindell et al. 2008 e estimamos 20 réplicas para cada cenário neutro. 

### Equivalência entre grandezas

__i) Parâmetros de dispersão __

Desenvolvemos uma equação que relaciona d com a probabilidade de uma unidade de habitat ser colonizada pela prole de um indivíduo de fora da comunidade local (m) e então calculamos I o número de imigrantes que competem com os indivíduos locais pelas unidades de habitat disponível (Etienne 2005).

Para calcular m a partir do desvio padrão (sd) da função de dispersão, assumimos que as áreas de amostragem são quadradas e distribuição de Laplace:

$$m = sd \frac{1 - e^{-\frac{\sqrt{2} L}{sd}} }{\sqrt{2} L}$$

Onde L = lado da área amostrada. Para corrigir essa equação para paisagens não homogêneas (fragmentadas) utilizamos uma correção de valor:

$$m' = \frac{mp}{1 - (1-p)m} $$

Para criar as predições do modelo EI utilizamos a formula de amostragem de Etienne (2005) que utiliza o parâmetro I ao invés de m. I se relaciona com m por:

$$ I = m (J - 1) / (1 - m)$$

__ii) Parâmetros de Diversidade__

Para cada U calculamos o respectivo theta por:

$$ \theta = U  (J_M - 1) / (1 - U) $$
Onde $J_M$ é o número de indivíduos na paisagem:

$$ J_M = 500 p DA $$
500 é área do recorte de paisagem em hectares


## Parâmetros de Dispersão

### d - distância média de dispersão

Perguntas: Quais as situações biológicas que estamos simulando? Em relação às médias de síndromes de dispersão em floresta intacta? E em floresta fragmentada?

#### Gráficos Exploratórios

```{r graf exp d, fig.width=10}
l_p <- vector("list",2)
l_p[[1]] <- ggplot(df_resultados,aes(x=k,y=d)) + 
  geom_jitter() +
  geom_boxplot()
l_p[[2]] <- ggplot(df_resultados,aes(x=DA,y=d)) + 
  geom_point() +
  geom_smooth(method = "loess",se=FALSE) +
  labs(y="")
do.call("grid.arrange",c(l_p,ncol=2))
```

__Figura 1__ Distância média de dispersão, k (proporção de propágulos até l_cel metros da planta progenitora) e DA (densidade observada)

#### Tabela de Seleção de Modelos

- distribuição Gamma com função de ligação 'log'

```{r selecao d}
l_md <- vector("list",length = 4)
names(l_md) <- c("k+DA","DA","k","1")
l_md[[1]] <-  glmer(d ~ k + DA.z + (1|Site),family = "Gamma"(link=log),data = df_resultados)
l_md[[2]] <-  glmer(d ~ DA.z + (1|Site),family = "Gamma"(link=log),data = df_resultados)
l_md[[3]] <-  glmer(d ~ k + (1|Site),family = "Gamma"(link=log),data = df_resultados)
l_md[[4]] <-  glmer(d ~ 1 + (1|Site),family = "Gamma"(link=log),data = df_resultados)
AICctab(l_md)
```

#### Observado e predito

```{r predito e observado d}
df_reg <- broom::augment(l_md[[1]])
df_reg %<>% mutate(predito = exp(.fitted),
                   std.resid = .resid/sd(.resid),
                   sqrt.std.resid = sqrt(std.resid))
## observado e predito ##
df_reg %>%  ggplot(aes(x=DA.z,y=d)) + geom_point() +
  geom_line(aes(y=predito),color="red") + facet_wrap(~k,ncol=3,scales="free")
```

__Figura 2__ Distância média de dispersão (d) e o predito segundo d ~ DA.z + k + (1 | Sítio), family=Gamma(log). Os pontos são as distâncias médias estimados para o determinado percentil (k) de propágulos que permanecem até l_cel metros da planta progenitora; em vermelho o predito.

#### Tabela de efeitos na escala padrão

```{r effects glmm d}
(df_effect <- data.frame(par.class = c("beta",rep("alfa",length(levels(df_resultados$k)) ) ),
                        par.VE = c("DA.z",
                                   paste("k=",levels(df_resultados$k),sep="")),
                        par.value = c(exp(fixef(l_md[[1]])[13]),
                                      exp(fixef(l_md[[1]])[1]),
                                      exp(fixef(l_md[[1]])[2:12]-fixef(l_md[[1]])[1]))
                        ))
```


#### Status

Análise da variável quase completa. Problemas de convergência não permitiram estimar os intervalos de confiança das estimativas e nem o R^2 do modelo mais plausível.

__Questões__
Qual seria k dado d, ou seja, extrapolar a relação para poder inferir qual seria k para determinadas médias de síndrome de dispersão sem precisar simular as funções de dispersão.   

Utilizando a equação matemática estimada seria necessário utilizar k enquanto variável contínua.

### I 

Perguntas: Quais são as estimativas do parâmetro de dispersão de EI obtido em campos? Quais são os valores que simulamos?

#### Gráficos Exploratórios

```{r graf exp I,fig.height=10,fig.width=10}
l_p <- vector("list",3)
l_p[[1]] <- ggplot(df_resultados,aes(x=k,y=I)) + 
  geom_jitter() +
  geom_boxplot()
l_p[[2]] <- ggplot(df_resultados,aes(x=J,y=I)) + 
  geom_point() +
  geom_smooth(method = "loess",se=FALSE) +
  labs(y="")
l_p[[3]] <- ggplot(df_resultados,aes(x=log(J),y=I)) +
  geom_point() +
  geom_smooth(method = "loess",se=FALSE) +
  facet_wrap(~k,ncol = 3,scales="free")
grid.arrange(l_p[[1]],l_p[[2]],l_p[[3]],
             layout_matrix = rbind(c(1,1,2,2),
                                   rep(3,4),
                                   rep(3,4)
                                   )
             )
```

__Figura 3__ Gráficos Exploratórios de I, k e J (número de indivíduos amostrado)

#### Status

Não iniciei a análise da variável.

## Parâmetros de Diversidade

### U - taxa de especiação

#### Gráficos Exploratórios 

##### Efeitos fixos indivíduais


```{r graf exp U 1,fig.width=12,fig.height=5}
l_p <- vector("list",3)
l_p[[1]] <- ggplot(df_resultados,aes(x=k,y=U)) +
  geom_jitter() +
  geom_boxplot()
l_p[[2]] <- ggplot(df_resultados,aes(x=p,y=U)) +
  geom_point() +
  geom_smooth(method = "loess",se=FALSE) +
  labs(y="")
l_p[[3]] <- ggplot(df_resultados,aes(x=S,y=U)) +
  geom_point() +
  geom_smooth(method = "loess",se=FALSE) +
  labs(y="")
do.call("grid.arrange",c(l_p,ncol=3))
```

__Figura 4__ Taxa de especiação, k, p e S

##### Interações efeitos fixos


```{r graf exp U 21}
ggplot(df_resultados,aes(x=p,y=U)) +
  geom_point() +
  geom_smooth(method = "loess",se=FALSE) +
  facet_wrap(~k,ncol = 3) +
  labs(title=" ~ k * p")
```

__Figura 5.1__ U ~ k * p

```{r graf exp U 22}
ggplot(df_resultados,aes(x=S,y=U)) +
  geom_point() +
  geom_smooth(method = "loess",se=FALSE) +
  facet_wrap(~k,ncol = 3) +
  labs(title=" ~ k * S")
```

__Figura 5.2__ U ~ k * S


```{r graf exp 23}
ggplot(df_resultados,aes(x=p,y=U)) +
  geom_point(aes(color=S.z)) +
  scale_color_gradient2() +
  facet_wrap(~k,ncol=3) +
  labs(title="~ k * p + S")
```

__Figura 5.3__ U ~ k * p + S

- Achei estranho que há valores de U baixos para altos valores de S
- Então pensei em um possível efeito do tamanho amostral: quanto maior J maior a árvore genealógica da comunidade [sob hipótese de monodominância] e assim menor a probabilidade média de imigração necessária para gerar uma mesma riqueza observada
- O tamanho da metacomunidade ao redor pode ter o mesmo efeito, esse efeito pode ser expresso em termos de relação de J/J_M pois considera-se a coalescência apenas da área amostral e não da paisagem


```{r graf exp U 24}
df_resultados %<>% mutate(J_M = p * DA * 500)
l_p <- vector("list",4)
l_p[[1]] <- ggplot(df_resultados,aes(x=J,y=U)) +
  geom_point()
l_p[[2]] <- ggplot(df_resultados,aes(x=log(J),y=U)) +
  geom_point() +
  labs(y="")
l_p[[3]] <- ggplot(df_resultados,aes(x=J/J_M,y=U)) +
  geom_point()
l_p[[4]] <- ggplot(df_resultados,aes(x=log(J/J_M),y=U)) +
  geom_point() + 
  labs(y="")
do.call("grid.arrange",c(l_p,ncol=2))
```

__Figura 5.4__ U, J e J/J_M em escala padrão e log

-Parece que há um efeito de log(J), contudo, há correlação entre as variáveis empíricas p, S e J:

```{r graf exp 25,fig.width=10,fig.height=4}
l_p <- vector("list",3)
l_p[[1]] <- ggplot(df_resultados,aes(x=p,y=S)) + geom_point()
l_p[[2]] <- ggplot(df_resultados,aes(x=p,y=J)) + geom_point()
l_p[[3]] <- ggplot(df_resultados,aes(x=J,y=S)) + geom_point()
do.call("grid.arrange",c(l_p,ncol=3))
```

__Figura 5.5__ Relação entre co-variáveis empíricas S, J e p

- Na análise de U consideramos o efeito de S, mas não de J. Eu acredito que vale a investigação se os dois outliers de J (J>5000) não podem estar influênciando muito as estimativas


##### Efeitos aleatórios


```{r graf exp 31, fig.height=5.75}
df_resultados %>% mutate(p_class = cut(p,12)) %>% ggplot(aes(x=k,y=U,group=Site)) +
  geom_line(aes(color=Site)) +
  # scale_colour_gradient2() +
  theme(legend.position = "none") +
  labs(title="~p_class") +
  facet_wrap(~p_class,ncol=3,scales="free")
```

__Figura 6.1__ U ~ k * p_class (group=Site)

```{r graf exp 32, fig.height=5.75}
df_resultados %>% mutate(S_class = cut(S,9)) %>% ggplot(aes(x=k,y=U,group=Site)) +
  geom_line(aes(color=Site)) +
  facet_wrap(~S_class,ncol=3,scales="free") +
  theme(legend.position = "none") +
  labs(title="~S_class")
```


__Figura 6.2__ U ~ k * S_class (group=Site)

#### Resultados da dissertação

- Para modelar U aplicamos a transformação logito
- Utilizamos então a distribuição normal e a função de ligação identidade para a seleção dos modelos

```{r graf exp logit U}
df_resultados %<>% mutate(lU = log(U/(1-U)),
                          lS.z = (log(S) - mean(log(S)))/sd(log(S)))

# não estou conseguindo organizar os Sites por cobertura vegetal no plot, apenas na tabela

# arrange(df_resultados,p) %>%
#   ggplot(aes(x=Site,y=logit_U)) +
#   geom_boxplot() +
#   geom_point() +
#   coord_flip() +
#   labs(x="Fragmento Florestal", y="Logito taxa de especiação necessária para manter a riqueza observada")
```
<!--
__Figura 1__ Logito de U para cada sítio de amostragem ordenado da maior cobertura para a menor
-->

##### Tabela de Seleção e R2

_Tabela de Seleção de Variáveis para descrever logito de U_

```{r tabela de selecao logito U}
l_md <- vector("list",length=10)
names(l_md) <- c("p * k + S", "p + k + S", "p + S", "k + S", "S", "p * k", "p + k", "p", "k", "1")
l_md[[1]] <- lmer(lU ~ p.z * k + lS.z + (1 | Site), data = df_resultados)
l_md[[2]] <- lmer(lU ~ p.z + k + lS.z + (1 | Site), data = df_resultados)
l_md[[3]] <- lmer(lU ~ p.z + lS.z + (1 | Site), data = df_resultados)
l_md[[4]] <- lmer(lU ~ k + lS.z + (1 | Site), data = df_resultados)
l_md[[5]] <- lmer(lU ~ lS.z + (1 | Site), data = df_resultados)
l_md[[6]] <- lmer(lU ~ p.z * k + (1 | Site), data = df_resultados)
l_md[[7]] <- lmer(lU ~ p.z + k + (1 | Site), data = df_resultados)
l_md[[8]] <- lmer(lU ~ p.z + (1 | Site), data = df_resultados)
l_md[[9]] <- lmer(lU ~ k + (1 | Site), data = df_resultados)
l_md[[10]] <- lmer(lU ~ 1 + (1 | Site), data = df_resultados)
# selecao #
AICctab(l_md, weights = TRUE)
```

_R2 marginal e condicional da seleção de modelos_

- pelo método de Nakagawa & Schielzeth (2013)

```{r R2 logito U}
# R2 marginal e condicional #
(r2_U <- sapply(l_md, r.squaredGLMM))
```

_Porcentagem da variância explicada pelos efeitos fixos_

- R2m / R2c

```{r porcentagem da variancia explicada efeitos fixos}
# porcentagem de variância explicada pelo modelo #
r2_U[1,]/r2_U[2,]
```

##### Predito e Intervalo de Confiança

```{r predito e IC modelo U, fig.height=7}
## Uma regressao entre log_S.z e pz ##
lm1 <- lm(lS.z ~ p.z, data=df_resultados[duplicated(df_resultados$Site),]) # estima relacao linear entre log S e p.z
cf1 <- unname(coef(lm1)) ## guarda os coeficientes dessa regressao para usar no bootstrap

## Intervalo de Confiança Bootstrap ##
# novo conjunto de dados
df_newdat <- expand.grid(Site=df_resultados$Site[1], 
                         k=unique(df_resultados$k), 
                         p.z = seq(min(df_resultados$p.z)*1.1,max(df_resultados$p.z)*1.1, length=50))
# Adiciona a média de log(S) padronizado para cada cobertura, estimado pela regrassao Sxp
df_newdat %<>% mutate(lS.z = cf1[1] + cf1[2]*p.z) %>% as.data.frame()
## Passo 2: crie as função que devem ser calculadas dos modelos a cada simulação
## Previstos por efeitos fixos e aleatórios
f1 <- function(.) predict(., newdata=df_newdat)
## Previstos por efeitos fixos (argumento re.form=~0)
f2 <- function(.) predict(., newdata=df_newdat, re.form=~0)
## Os dois bootstraps. Ajuste o argumento ncpus para o numero de cores de seu computador
md_U <- l_md[["p * k + S"]]
b3 <- bootMer(md_U, FUN = f1, nsim=1000, parallel="multicore", ncpus=2)
b4 <- bootMer(md_U, FUN = f2, nsim=1000, parallel="multicore", ncpus=2)
## calcula as médias e intervalos de confiança quantílicos para cada combinação de preditoras
## no novo conjunto de dados
df_newdat$p <- df_newdat$p.z*sd(df_resultados$p) + mean(df_resultados$p)
df_newdat$mean <- apply(b3$t,2,mean)
df_newdat$IC.low <- apply(b3$t,2,quantile, 0.025)
df_newdat$IC.upp <- apply(b3$t,2,quantile, 0.975)
df_newdat$mean.fixed <- apply(b4$t,2,mean)
df_newdat$IC.low.fixed <- apply(b4$t,2,quantile, 0.025)
df_newdat$IC.upp.fixed <- apply(b4$t,2,quantile, 0.975)

## Plots de logito(U) x cobertura standardizada com intervalos de predição ##
## PI: note que a incerteza total diminuiu um pouco com a adicao da riqueza ao modelo
## (as faixas cinza claro são mais largas em sua figura antiga, que nao tinha este efeito)
df_resultados %>%
  ggplot(aes(x=p,y=lU)) + 
  geom_ribbon(aes(y = mean, ymin=IC.low, ymax=IC.upp), data=df_newdat, col="gray", alpha=0.5) +
  geom_ribbon(aes(y=mean, ymin=IC.low.fixed, ymax=IC.upp.fixed), data=df_newdat, col="gray", alpha=0.5) +
  geom_line(aes(x=p, y=mean.fixed), data=df_newdat) +
  geom_point() +
  labs(x="% cobertura vegetal", y = "logito(U)") +
  facet_wrap(~k,ncol=3)
```

__Figura 7__ Logito de U pela porcentagem de cobertura vegetal. A linha é a estimativa da tendência, a região cinza mais escuro corresponde ao intervalo de confiança dos efeitos fixos e a região cinza mais clara o intervalo de confiança considerando todo o modelo. 

##### Sumário do modelo mais plausível

```{r sumario de md U}
summary(l_md[[1]])
```


##### Status

Falta atualizar o método de obtenção do R2m e R2c e recuperar/revisar o texto da dissertação dessa sessão

_Questões_

a) Quando a hipótese de equilíbrio é válida? E quando não for ainda é uma boa aproximação utilizar U como taxa de extinção de espécies raras? O quê é uma espécie rara?


### Theta

#### Gráficos Exploratórios 

- theta é uma função de U e J_M (que por sua vez é uma função de p e DA)
- no modelo EI se pressupõem que J_M >> J, o quê para paisagens finitas e fragmentadas pode não ser uma boa aproximação
- assim, além de avaliar as variáveis de interesse (p e k) vou também avaliar o efeito de: J e J_M, S (uma vez que é uma função de U)

##### Possíveis Variáveis de interesse

```{r graf exp theta 11,fig.height=6,fig.width=9}
df_resultados %<>% mutate(JM = p * DA * 500, theta = U * (JM - 1)/(1-U))
l_p <- vector("list",6)
l_p[[1]] <- ggplot(df_resultados,aes(x=S,y=theta)) +
  geom_point() + geom_smooth(method="loess",se=FALSE)
l_p[[2]] <- ggplot(df_resultados,aes(x=k,y=theta)) + 
  geom_jitter() + geom_boxplot() + labs(y="")
l_p[[3]] <- ggplot(df_resultados,aes(x=p,y=theta)) + 
  geom_point() + geom_smooth(method="loess",se=FALSE) + labs(y="")
l_p[[4]] <- ggplot(df_resultados,aes(x=JM,y=theta)) +
  geom_point() + geom_smooth(method="loess",se=FALSE)
l_p[[5]] <- ggplot(df_resultados,aes(x=log(J),y=theta)) +
  geom_point() + geom_smooth(method="loess",se=FALSE) + labs(y="")
l_p[[6]] <- ggplot(df_resultados,aes(x=log(J/JM),y=theta)) +
  geom_point() + geom_smooth(method="loess",se=FALSE) + labs(y="")
do.call("grid.arrange",c(l_p,ncol=3))
```

__Figura 8.1__ Theta e possíveis variáveis variáveis de intresse


##### Interação entre variáveis

```{r graf exp tehta 121}
ggplot(df_resultados,aes(x=p,y=theta)) + 
  geom_point() + geom_smooth(method="loess",se=FALSE) +
  facet_wrap(~k,ncol=3) +
  labs(title = "~ p * k")
```

__Figura 8.2.1__ theta ~ p * k


```{r graf exp tehta 122}
ggplot(df_resultados,aes(x=S,y=theta)) + 
  geom_point() + geom_smooth(method="loess",se=FALSE) +
  facet_wrap(~k,ncol=3) +
  labs(title = "~ S * k")
```

__Figura 8.2.2__ theta ~ S * k

```{r graf exp tehta 123}
ggplot(df_resultados,aes(x=log(J/JM),y=theta)) + 
  geom_point() + geom_smooth(method="loess",se=FALSE) +
  facet_wrap(~k,ncol=3) +
  labs(title = "~ log(J/JM) * k")
```

__Figura 8.2.3__ theta ~ log(J/JM) * k

#### Status

- análise da variável não foi iniciada;


## Comparação da predição com o observado (GOF)

### Gráficos exploratórios

#### Efeitos indivíduais das variáveis de interesse

- 3 variáveis de interesse: p, k e MN (classe de modelo neutro)

```{r graf exp GOF 1, fig.width=10,fig.height=4}
l_p <- vector("list",3)
l_p[[1]] <- ggplot(df_resultados,aes(x=p,y=GOF)) +
  geom_point() +
  geom_smooth(method = "loess",se=FALSE)
l_p[[2]] <- ggplot(df_resultados,aes(x=k,y=GOF)) +
  geom_jitter() +
  geom_boxplot() + labs(y="")
l_p[[3]] <- ggplot(df_resultados,aes(x=MN,y=GOF)) +
  geom_jitter() +
  geom_boxplot() + labs(y="")
do.call("grid.arrange",c(l_p,ncol=3))
```

__Figura 9__ GOF e variáveis de interesse p, k ,MN

#### Possíveis interações entre as variáveis

```{r graf exp GOF 21}
ggplot(df_resultados,aes(x=p,y=GOF)) +
  geom_point() +
  geom_smooth(method = "loess",se=FALSE) +
  facet_wrap(~k,ncol=3) +
  labs(title="~ p * k")
```

__Figura 10.1__ GOF ~ p * k

```{r graf exp GOF 22, fig.height=3.5}
ggplot(df_resultados,aes(x=p,y=GOF)) +
  geom_point() +
  geom_smooth(method = "loess",se=FALSE) +
  facet_wrap(~MN,ncol=2) +
  labs(title="~ p * MN")
```

__Figura 10.2__ GOF ~ p * MN

```{r graf exp GOF 23}
ggplot(df_resultados,aes(x=MN,y=GOF)) +
  geom_jitter() +
  geom_boxplot() +
  facet_wrap(~k,ncol=3) +
  labs(title="~ MN * k")
```

__Figura 10.3__ GOF ~ MN * K

```{r graf exp GOF 24}
print(
    ggplot(df_resultados,aes(x=p,y=GOF,color=MN)) +
      geom_point() +
      geom_smooth(method = "loess",se=FALSE) +
      facet_wrap(~k,ncol=3) +
      labs(title="~ p * k * MN") +
      scale_colour_manual(values = c("Blue", "Red"))
)
```

__Figura 10.4__ GOF ~ p * k * MN

```{r gra exp logito GOF 25}
## remoção de 0 e 100 ##
df_ad <- df_resultados
df_ad$GOF[df_ad$GOF==0] <- 0.01
df_ad$GOF[df_ad$GOF==100] <- 99.99
## transformação logito ##
df_ad %<>% mutate(lGOF = log((GOF/100)/(1-(GOF/100)) ))
# df_ad$lGOF %>% summary
## gráfico ##
print(
    ggplot(df_ad,aes(x=p,y=lGOF,color=MN)) +
      geom_point() +
      geom_smooth(method = "loess",se=FALSE) +
      facet_wrap(~k,ncol=3) +
      labs(title="~ p * k * MN") +
      scale_colour_manual(values = c("Blue", "Red"))
)
```

__Figura 10.5__ Logito GOF ~ p * k * MN

#### Possíveis estruturas aleatórias

__1|Site__

```{r GOF graf exp 2 logito pela estrutura aleatoria1,fig.height=8,fig.width=8}
df_ad %>% mutate(p.class = cut(p,12)) %>% ggplot(aes(x=Site,y=lGOF)) +
  geom_jitter() +
  geom_boxplot() +
  coord_flip() +
  theme(axis.text.y = element_blank(),axis.ticks = element_blank(), legend.position="bottom") +
  facet_wrap(~p.class,ncol=3,scales="free_y")
```

__Figura 11.1__ logito de GOF ~ site (~p.class)

__MN|Site__

```{r GOF graf exp 2 logito pela estrutura aleatoria 2,fig.height=8,fig.width=8}
df_ad %>% mutate(p.class = cut(p,12)) %>% ggplot(aes(x=Site,y=lGOF,color=MN)) +
  geom_jitter() +
  geom_boxplot() +
  coord_flip() +
  theme(axis.text.y = element_blank(),axis.ticks = element_blank(), legend.position="bottom") +
  facet_wrap(~p.class,ncol=3,scales="free_y")
```

__Figura 11.2__ logito de GOF ~ MN * Site (~p.class)

### Anaĺise estatística

#### Modelo Cheio

##### Seleção da Estrutura Aleatória

```{r GOF escolha estrutura aleatoria}
l_md <- vector("list",2)
names(l_md) <- c("1|Site","MN|Site")
l_md[[1]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (1|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[2]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
AICctab(l_md,weights=T)
```

##### Diagnóstico do Modelo Selecioonado

- resíduos quantílicos (DHARMa)

```{r GOF diag1}
# dados #
residuos_GOF <- simulateResiduals(fittedModel = l_md[[2]], n = 1000)
plot(residuos_GOF)
```

__Figura 12.1__ Resíduos quantílicos: 1o gráfico qq-plot e teste de aderência dos resíduos com o esperado segundo uniformidade com a distribuição teórica (teste de Kolmogorov-Smirnov); 2o gráfico resíduos contro o previsto, linhas são da regressão quantílica (0.25, 0.50, 0.75) 


```{r GOF diag2,fig.width=10,fig.height=4}
df_reg <- df_resultados %>% mutate(GOF_q.resid = residuos_GOF$scaledResiduals)
l_p <- vector("list",3)
l_p[[1]] <- ggplot(df_reg,aes(x=p.z,y=GOF_q.resid)) +
  geom_point() +
  geom_smooth(method="loess") +
  labs(y="residuos")
l_p[[2]] <- ggplot(df_reg,aes(x=MN,y=GOF_q.resid)) +
  geom_jitter() +
  geom_boxplot() +
  labs(y="")
l_p[[3]] <- ggplot(df_reg,aes(x=k,y=GOF_q.resid)) +
  geom_jitter() +
  geom_boxplot() +
  labs(y="")
do.call("grid.arrange",c(l_p,ncol=3))
# grid.arrange(l_p[[1]],l_p[[2]],l_p[[3]],l_p[[4]],
#              layout_matrix=rbind(c(1,2,3),
#                                  rep(4,3),
#                                  rep(4,3) )
#              )
```

__Figura 12.2__ resíduos contra as variáveis preditoras


```{r GOF diag3}
ggplot(df_reg,aes(x=p.z,y=GOF_q.resid,color=MN)) +
  geom_point() +
  geom_smooth(method="loess") +
  labs(y="residuos") +
  theme(legend.position = "bottom") +
  facet_wrap(~k,ncol=4)
```

__Figura 12.3__ resíduos contra as variáveis preditoras p * MN * k


```{r GOF diag4}
ggplot(df_reg,aes(x=MN,y=GOF_q.resid)) +
  geom_jitter() +
  geom_boxplot() +
  labs(y="residuos") +
  facet_wrap(~k,ncol=4)
```

__Figura 12.4__ resíduos contra as variáveis preditoras MN * k

- o teste de uniformidade mostra que desvio é significativo apontando para o modelo não prediz corretamente as observações
- o gráfico dos resíduos conra os valores previstos indica que a variação não está igualmente distribuida (como se pode ver pelas regressões quantílicas)
- parece que o modelo está com dificuldades de fazer um bom ajuste k:0.25 e para MN:EI
- vou explorar outras funções de ligação para avaliar se o ajuste do modelo pode ficar melhor

##### Comparação das três funções de ligação canônicas para a distribuição binomial

```{r GOF escolha funcao de ligacao}
l_md <- vector("list",6)
names(l_md) <- c("l 1|Site","l MN|Site", 
                 "p 1|Site","p MN|Site", 
                 "c 1|Site","c MN|Site")
l_md[[1]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (1|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[2]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[3]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (1|Site), family = "binomial"(link = probit),data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[4]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (MN|Site), family = "binomial"(link = probit),data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[5]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (1|Site), family = "binomial"(link = cloglog),data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[6]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (MN|Site), family = "binomial"(link = cloglog),data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
AICctab(l_md,weights=T)
```

- o modelo mais plausível considera a função de ligação cloglog

```{r diag GOF cloglog1}
l_residuos <- llply(l_md[c(2,4,6)],function(x) (simulateResiduals(fittedModel = x, n=1000)))
plot(l_residuos[[3]])
```

__Figura 12.5__ Resíduos quantílicos do modelo com função de ligação cloglog, o único plausível

- não observo melhorar significativa do modelo (figura 12.1 e 12.5)
- para comparação segue o teste de aderência das três funções de ligação

```{r GOF teste de aderencia funcoes de ligacao,fig.height=3.5,fig.width=8}
par(mfrow=c(1,3))
l_ply(l_residuos,function(x) plotQQunif(x))
```

__Figura 12.6__ Testes de aderência à uniformidade dos resíduos quantílicos: 1o painel - logito; 2o painel - probito; 3o painel - cloglog

- Não diferenças significativas entre as três funções de ligação
- uma vez que não observamos melhora, optamos prosseguir com a função de ligação logito pois sua interpretação e comunicação é mais fácil.


#### Seleção de Variáveis

- comparamos todos os submodelos criados a partir do modelo cheio que considera a interação de terceira ordem entre as variável p, k e MN

##### Seleção do modelo mais plausível

```{r GOF selecao de modelos}
l_md <- vector("list",19)
names(l_md) <- c("p*k*MN",# modelo cheio
                 "p*k*MN-p:k:MN", #MC - 3a ordem
                 "p*(k+MN)","k*(p+MN)","MN*(p+k)", #2 interações
                 "p*k+MN","p*MN+k","k*MN+p", #1 interação + preditor
                 "p*k","p*MN","k*MN", #1 interação
                 "p+k+MN",#aditivo 3
                 "p+k","p+MN","k+MN", #aditivo 2 
                 "p","k","MN", #preditor isolado
                 "1") #nulo
#modelo cheio
l_md[[1]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
#modelo cheio - interação 3a ordem
l_md[[2]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN - p.z:k:MN + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
#2 interações
l_md[[3]] <- glmer(cbind(GOF,100-GOF) ~ p.z * (k + MN) + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[4]] <- glmer(cbind(GOF,100-GOF) ~ k * (p.z + MN) + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[5]] <- glmer(cbind(GOF,100-GOF) ~ MN * (p.z + k) + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
#1 interação + preditor
l_md[[6]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k + MN + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[7]] <- glmer(cbind(GOF,100-GOF) ~ p.z * MN + k + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[8]] <- glmer(cbind(GOF,100-GOF) ~ k * MN + p.z + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
#1 interação
l_md[[9]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k + (1|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[10]] <- glmer(cbind(GOF,100-GOF) ~ p.z * MN + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[11]] <- glmer(cbind(GOF,100-GOF) ~ k * MN + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
#aditivo 3
l_md[[12]] <- glmer(cbind(GOF,100-GOF) ~ p.z + k + MN + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
#aditivo 2
l_md[[13]] <- glmer(cbind(GOF,100-GOF) ~ p.z + k + (1|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[14]] <- glmer(cbind(GOF,100-GOF) ~ p.z + MN + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[15]] <- glmer(cbind(GOF,100-GOF) ~ k + MN + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
#aditivo 1
l_md[[16]] <- glmer(cbind(GOF,100-GOF) ~ p.z + (1|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[17]] <- glmer(cbind(GOF,100-GOF) ~ k + (1|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[18]] <- glmer(cbind(GOF,100-GOF) ~ MN + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
# nulo
l_md[[19]] <- glmer(cbind(GOF,100-GOF) ~ 1 + (1|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
AICctab(l_md,weights=T)
```

- O modelos cheio foi o único modelo plausível somando peso de evidência próximo de 1.

##### Estimativas do modelo mais plausível

- segue súmario do modelo mais plausível:

```{r md_GOF sumario}
md_GOF <- l_md[[1]]
fastdisp(md_GOF)
```

Pontos para avaliação:

i) o erro padrão das estimativas dos coef está baixa com relação a seus valores (quais seriam valores altos?);
ii) o desvio padrão estimado para a estrutura aleatória indica que existe grande variância dentro das categórias (pesquisar essa questão)
iii) a correlação intra estrutura aleatória é baixa (pesquisar segundo ponto)


```{r md_GOF simulate values fixed effects}
# simulacao
fe_GOF <- FEsim(md_GOF,n.sims = 1000)

# grafico #
plotFEsim(fe_GOF,stat = "mean",intercept = TRUE) + theme_bw() + labs(y="taxa de GOF",x="média do efeito estimado")

# ggplot(fe_GOF) + aes(x = term, ymin = mean - 1.96 * sd, 
#       ymax = mean + 1.96 * sd, y = mean) + 
#   geom_pointrange() + 
#   geom_hline(yintercept = 0, size = I(1.1), color = I("red")) + 
#   coord_flip() +
#   theme_bw() + labs(y="taxa de GOF",x="média do efeito estimado")
```

__Figura 13.1__ Média e Interval de confiança de 95% estimado para cada coeficiente do modelo mais plausível. Método de estimativa a parti de simulação (Gelman & Hill 2006) (?). Intervalo de confiança criado com o desvio padrão da simulação com 1000 ciclos. 

- gráfico com as estimativas dos efeitos fixos; os coeficientes não estão ordenados por relação entre eles 
- a maior parte dos coeficientes apresenta pequeno intervalo de confiança

__tabela 1__ Efeitos Aleatórios: variância, erro padrão e correlação

```{r variance covariance random effects}
VarCorr(md_GOF)
```


```{r md_GOF simulate values random effects}
# simulacao
re_GOF <- REsim(md_GOF,n.sims = 1000)
# re_GOF

# grafico
plotREsim(re_GOF,stat = "mean")
```

__Figura 13.2__ Média e Intervalo de Confiança de 95% dos parâmetros estimados da estrutura aleatória (MN|Site). 

- parece que existe grande variação entre sítios: há diferentes combinações entre intercepto e inclinação de MN:EE, e.g. valores baixos de intercepto com altos e baixos valores de MN:EE. 

##### Observado e Predito

```{r md_GOF obs e predito, fig.height=7}
## novo conjunto de dados: todas as combinações entre as preditoras ##
df_new.data <- expand.grid(Site = df_resultados$Site[1],
                           p.z = seq(min(df_resultados$p.z)*1.1,max(df_resultados$p.z)*1.1, length=length(unique(df_ad$p))),
                           k = unique(df_resultados$k),
                           MN = unique(df_resultados$MN))
## predicao merTools ##
df_new.data <- cbind(df_new.data,
                     predictInterval(md_GOF,newdata = df_new.data,level=0.95,n.sims = 1000,stat = "mean"))
# add de p na escala padrão #
df_new.data$p <- df_new.data$p.z*sd(df_ad$p) + mean(df_ad$p)
# transformando a predicao para escala da observacao #
# df_new.data %<>% mutate(media = ( 1 / ( 1+exp(-fit) )), upr_media =  (1/(1+exp(-upr))), lwr_media =  (1/(1+exp(-lwr))))

## remoção de 0 e 100 ##
df_ad <- df_resultados
df_ad$GOF[df_ad$GOF==0] <- 100/(1+exp(-min(df_new.data$lwr)))
df_ad$GOF[df_ad$GOF==100] <- 100/(1+exp(-max(df_new.data$upr)))
## transformação logito ##
df_ad %<>% mutate(lGOF = log( (GOF/100) / ( 1 - (GOF/100) ) ))


## Gráfico ##
ggplot(data=df_new.data,aes(x=p,y=lGOF,color=MN)) + 
  geom_point(data=df_ad,aes(color=MN)) +
  geom_ribbon(aes(y = fit, ymin=lwr, ymax=upr,color=MN,fill=MN), alpha=0.5) +
  geom_line(aes(x=p, y=fit,color=MN)) +
  facet_wrap(~k,ncol=3) +
  scale_colour_manual(values = c("Blue", "Red")) + 
  scale_fill_manual(values = c("Blue", "Red")) +
  theme(legend.position = "bottom")
```

__Figura 14__ Logito de GOF (lGOF) e propoção de cobertura vegetal (p), por proporção de propágulos que permanece até a planta (k, o título dos quadros) e colorido pela classe de modelo neutro (MN: EI - modelo neutro de espaço implícito; EE - modelo neutro de espaço explícito). A linha central representa a média estimado e a área colorida representa o intervalo de confiança de 95%. 


```{r md_GOF obs e predito 2,fig.height=10,fig.width=9}
l_p <- vector("list",2)
# merTools
l_p[[1]] <- ggplot(data=df_new.data,aes(x=p,y=lGOF)) + 
  geom_point(data=df_ad) +
  geom_ribbon(aes(y = fit, ymin=lwr, ymax=upr), alpha=0.5) +
  geom_line(aes(x=p, y=fit)) +
  labs(title="merTools") +
  facet_grid(k~MN)

# bootMer
load(file = "/home/danilo/Documentos/Doutorado/artigo_mestrado/Rmd_e_dados/bootMer_md-logit-GOF.Rdata")
df_new.data1 <- df_new.data
df_new.data1$p <- df_new.data1$p.z*sd(df_resultados$p) + mean(df_resultados$p) 
df_new.data1$mean <- apply(b1$t,2,mean)
df_new.data1$IC.low <- apply(b1$t,2,quantile, 0.025)
df_new.data1$IC.upp <- apply(b1$t,2,quantile, 0.975)
df_new.data1$mean.fixed <- apply(b2$t,2,mean)
df_new.data1$IC.low.fixed <- apply(b2$t,2,quantile, 0.025)
df_new.data1$IC.upp.fixed <- apply(b2$t,2,quantile, 0.975)
## Modificação dos dados
df_ad <- df_resultados
df_ad$GOF[df_ad$GOF==0] <- 100/(1+exp(-min(df_new.data1$IC.low)))
df_ad$GOF[df_ad$GOF==100] <- 100/(1+exp(-max(df_new.data1$IC.upp)))
## transformação logito ##
df_ad %<>% mutate(lGOF = log( (GOF/100) / ( 1 - (GOF/100) ) ))
# grafico #
l_p[[2]] <- ggplot(df_ad,aes(x=p,y=lGOF) ) + 
    geom_ribbon(aes(y=mean, ymin=IC.low, ymax=IC.upp), data=df_new.data1, col="gray", alpha=0.5) +
    geom_ribbon(aes(y=mean, ymin=IC.low.fixed, ymax=IC.upp.fixed), data=df_new.data1, col="gray", alpha=0.5) +
    geom_line(aes(x=p, y=mean.fixed), data=df_new.data1) +
    geom_point() +
    labs(title="bootMer",y="") +
    facet_grid(k~MN)
do.call("grid.arrange",c(l_p,ncol=2))
```

__Figura 15__ Comparação entre dois métodos de criação de intervalo de confiança de 95% em torno da média: coluna da esquerda pelo método do merTools e coluna da direita pelo método bootMers.


##### Coeficiente de determinação

__tabela 2__ Coeficiente de determinação do modelo mais plausível - R2m (condicional à estrutura fixa); R2c (condicional ao modelo como um todo). Estimativa presente na versão 1.42 do pacote MuMin (Bartoń 2018). 
  
```{r R2 mf_GOF, warning=FALSE, message=FALSE}
r.squaredGLMM(md_GOF)
```

