---
title: "Resultados - artigo"
author: "Mori, Danilo Pereira"
date: "21 de maio de 2018"
output: html_document
---

```{r setup, include=FALSE} 
knitr::opts_chunk$set(echo = FALSE, tidy = TRUE, include = TRUE, warning = FALSE,cache = TRUE)
```

```{r dados e pacotes,warning=FALSE,message=FALSE,echo=FALSE}
# library(reshape2) # para mudar formato dos dados
library(RVAideMemoire) #gráficos diagnóstico dos GLMM
library(sjPlot) #gráficos de GLMM
library(MuMIn) # para R^2
# library(gridExtra)  #pacote para gráficos
# library(ggplot2)  # idem
library(sads)
library(lme4) # pacote de criação dos modelos estatísticos
library(blme) # pacote para comparar os modelos, seleção per se
library(merTools) # para intervalos de previsao
library(tidyverse)
# library(broom) # para manipular os modelos 
library(magrittr) # p escrita
# library(plyr) 
# library(dplyr) 
df_resultados <- read_csv("/home/danilo/Documentos/Doutorado/artigo_mestrado/Rmd_e_dados/df_resultados.csv")
# df_resultados %>% str
df_resultados$MN <- factor(df_resultados$MN)
df_resultados$SiteCode <- factor(df_resultados$SiteCode)
df_resultados$k <- factor(df_resultados$k,levels=unique(df_resultados$k))

# df_resultados$k %>% unique
```
<!-- Esqueleto dos resultados

a) MNEI por verossimilhança
-GOF) Se MNEI tiver seus parâmetros livres ele sempre apresentara boa congruência com o observado?
-theta) Se o ajuste dos parâmetros informa algo além da SAD em si, esperamos observar efeito positivo de p, pois para maiores coberturas vegetais há mais indivíduos na região biogeográfica.
-m) Idem, esperamos observar efeito positivo de p, uma vez que quanto menor a cobertura vegetal de uma paisagem menor a concetividade entre as manchas de habitat (REFERÊNCIA)

b) Conversão de parâmetros de imigração
-par{MNEI} -> par{MNEE} [parâmetros com maior interpretação biológica - que permite a parametrização a partir de valores observados]
-distância médias de dispersão -> m segundo uma simulação coalescente em paisagem fragmentada.

c) Estimando U a partir de uma simulação coalescente
- 20 valores de U a partir de cada nível de d [MM]
- U -> theta, pela formula de conversão de theta [MM]
- U ~ p * d + (d | Site) [ou a formula que estamos utilizando]

d) Congruência do observado entre os modelos neutros consideramos mesmo conjunto de parâmetros
[MM]: estabelecemos distâncias de dispersões segundo diferentes cenários de limitação à dispersão médio (d), que parametrizados com valores observados na natureza para diferentes sindromes de dispersão. Para cada nível de d estimamos a taxa de especiação necessária para manter a riqueza observada, sob a hipótese de equilíbrio dinâmico, (U - singleton/evento de morte) segundo MNEE. Utilizamos o par U e d para gerar SADs segundo MNEE e convertemos U e d em theta e m, respectivamente, para gerar SADs segundo MNEI. Para cada MN geramos 100 SADs réplicas que comparamos com a respectiva SAD observada pelo teste de Kolmogorov-Smirnov; contabilizamos o número de vezes que não foi possível refutar a hipótese nula de que a SAD réplica e SAD observada são amostras de uma mesma distribuição teórica na variável GOF (Goodness-of-fit). Temos 80 sítios de amostragens, 30 rodadas de simulação para cada nível de MN (EE e EI).

- GOF ~ p * d * MN + (d | Site / MN)
MN: factor 2 levels: EE, EI
d: numeric 30 valores para todas as simulações

e) Parâmetro a posteori: espécies input (Condit et al. 2012)
- spp_I ~ p * d + (d|Site)
- GOF ~ spp_I * d * MN + (d | Site / MN)


-->



<!-- última paragráfo de material e métodos

Organizamos os resultados em 3 blocos de dados, aqueles para MNEE, MNEI e MNEE + MNEI. As variáveis resposta são: GOF, $\theta$, m, U, spp_I e d. As variáveis indepedentes são cobertura vegetal (p) e função de dispersão, que está sendo expressa de forma categorica(k), assim, podemos avaliar tanto os dados de MNEE, quanto para MNEE + MNEI; e de forma contínua d (distância média de dispersão da função de dispersão), para os dados de MNEE. Convertemos os parâmetros de MNEE U e d em $\theta'$, m'; e $\theta$ e m de MNEI em  U' e (d' e k'), considerando que $J_M$ = número de indivíduos na paisagem. Quando houve mais de uma observação para um mesmo Sítio de amostragem, então utilizamos a variável Sítio como variável categórica dos efeitos aleatórios do modelo linear; quando a função de dispersão foi categória utilizamos (1|Site) e  (d|Site) se ela foi contínua. Assim, temos duas maneiras de partir a variação prevista pelo modelo. O $R_m^2$ é a variação explicada pelos efeitos fixos do modelo, ou seja, p e/ou a variável relacionada à limitação à dispersão (k ou d) ('R quadrado marginal'); já o R quadrado condicional, $R_c^2$, é a variação associado tanto às variáveis de efeito fixo quanto ao efeito aleatório (sítio de amostragem). 
Acredito que uma métrica de comparação entre $R^2$ para GLM e GLMM seria considerar a razão $R_{GLMM}^2 = R_m^2 / R_c^2$? -->

<!--
## Sessão antiga, 18jun ##
Introdução da sessão de resultados:

Vou explorar o terceiro bloco de dados c(MNEE, MNEI), em anexo a análise dos dados para o conjunto de dados MNEE e MNEI. MNEE e MNEI diferem na forma que implementam a teoria neutra e na forma com que estimam os parâmetros a priori simulação. Assim, unir os resultados em uma mesma análise de dados tem que ser feita considerando a origem dos dados, para adequar com os resultados de MNEE organizei os dados pela proporção da chuva de propágulos que permanece até a área imediata a da copa da árvore progenitora (l_cel metros). Incluindo os dados de MNEI, são 13 níveis na variável "k", o primeiro nível é aquele com cenário de limitação à dispersão mais rigoroso (=0.99), o penúltimo nível é o cenário de limitação à dispersão menos realista (=0.25) e o último nível são os dados de MNEI. Em análise exploratória observamos que mesmo com valores razoáveis de m, MNEI apresentou d's superiores ao de MNEE em escala log (anexo) e como d está relacionado com a proporção de propágulos até a área imediata da planta progenitora (k) ordenei os níveis de "k" agrupando os valores de MNEI juntos no último nível. Existe grande variação no parâmetro 'm' estimado por verossimilhança, contudo, essa variação não apresenta efeito de p (anexo), então, não considerar a variação interna de m em MNEI não deve interferir na análise dos dados. Em anexo, há as análises auxiliares que inclui dos outros conjuntos de dados.
i) Os dois modelos conseguem apresentar boa congruência com o observado? 
ii) Se sim quais as característica da paisagem e da relação com a área amostrada que propiciam esse resultado? 
iii) Em cenários de limitação à dispersão biologicamente realistas o modelo neutro apresente boa congruência com os dados?
iv) Qual o efeito da fragmentação na diversidade da paisagem segundo o predito neutro?


## Esqueleto dos resultados - 18jun ##

a) resultados para os parâmetros de imigração para as distâncias simuladas: m, I e k. Tentar incluir os valores estimados em campo
b) v ~ p * par_imig + S + (par_imig | Site); par_imig = d, m, I, k
c) GOF ~ p * MN * par_imig + S + (par_imig | Site / MN) 


-->
<!--
Para faciltar o ajuste dos modelos mistos aplicamos a transformação z nas variáveis contínuas: 
-->

```{r preparacao dos dados, echo=FALSE}
f_z <- function(x){
  m <- base::mean(x,na.rm=TRUE)
  sd <- sd(x,na.rm=TRUE)
  output <- (x-m)/sd
  return(output)
} 

df_resultados %<>% mutate(GOF.z = f_z(GOF),
                          p.z = f_z(p),
                          S.z = f_z(S),
                          U.z = f_z(U),
                          m_.z = f_z(m_),
                          I.z = f_z(I),
                          d.z = f_z(d),
                          k.z0 = as.numeric(as.character(k)),
                          k.z = f_z(k.z0))

names(df_resultados)[1] <- "Site"
```

__GOF__

<!--
i) selecao da funcao de ligacao e distribuicao de erros a partir da modelo cheio
ii) selecao do modelo mais plausível
iii) diagnóstico do modelo: Bolker et al.
-->

```{r GOF selecao de funcao de ligacao, echo=FALSE}
l_md <- vector("list", length = 16)
names(l_md) <- paste(paste(rep("(par_imig|Site/MN)",4),c("d","k","m","I")),rep(c("logit","probit","cloglog","ID normal"),each=4))
# logito
l_md[[1]] <- glmer(cbind(GOF,100-GOF) ~ p.z * MN * d.z + S.z + (d.z | Site / MN), 
                   family = "binomial"(link=logit),
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   data = df_resultados)
l_md[[2]] <- glmer(cbind(GOF,100-GOF) ~ p.z * MN * k.z + S.z + (k.z | Site / MN), 
                   family = "binomial"(link=logit),
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   data = df_resultados)
l_md[[3]] <- glmer(cbind(GOF,100-GOF) ~ p.z * MN * m_.z + S.z + (m_.z | Site / MN), 
                   family = "binomial"(link=logit),
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   data = df_resultados)
l_md[[4]] <- glmer(cbind(GOF,100-GOF) ~ p.z * MN * I.z + S.z + (I.z | Site / MN), 
                    family = "binomial"(link=logit),
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   data = df_resultados)
# probito
l_md[[5]] <- glmer(cbind(GOF,100-GOF) ~ p.z * MN * d.z + S.z + (d.z | Site / MN), 
                    family = "binomial"(link=probit),
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   data = df_resultados)
l_md[[6]] <- glmer(cbind(GOF,100-GOF) ~ p.z * MN * k.z + S.z + (k.z | Site / MN), 
                    family = "binomial"(link=probit),
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   data = df_resultados)
l_md[[7]] <- glmer(cbind(GOF,100-GOF) ~ p.z * MN * m_.z + S.z + (m_.z | Site / MN), 
                    family = "binomial"(link=probit),
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   data = df_resultados)
l_md[[8]] <- glmer(cbind(GOF,100-GOF) ~ p.z * MN * I.z + S.z + (I.z | Site / MN), 
                    family = "binomial"(link=probit),
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   data = df_resultados)
# cloglog
l_md[[9]] <- glmer(cbind(GOF,100-GOF) ~ p.z * MN * d.z + S.z + (d.z | Site / MN), 
                    family = "binomial"(link=cloglog),
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   data = df_resultados)
l_md[[10]] <- glmer(cbind(GOF,100-GOF) ~ p.z * MN * k.z + S.z + (k.z | Site / MN), 
                    family = "binomial"(link=cloglog),
                    control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   data = df_resultados)
l_md[[11]] <- glmer(cbind(GOF,100-GOF) ~ p.z * MN * m_.z + S.z + (m_.z | Site / MN), 
                    family = "binomial"(link=cloglog),
                    control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   data = df_resultados)
l_md[[12]] <- glmer(cbind(GOF,100-GOF) ~ p.z * MN * I.z + S.z + (I.z | Site / MN), 
                    family = "binomial"(link=cloglog),
                    control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   data = df_resultados)
# ID normal
l_md[[13]] <- lmer(GOF ~ p.z * MN * d.z + S.z + (d.z | Site / MN), data = df_resultados)
l_md[[14]] <- lmer(GOF ~ p.z * MN * k.z + S.z + (k.z | Site / MN), data = df_resultados)
l_md[[15]] <- lmer(GOF ~ p.z * MN * m_.z + S.z + (m_.z | Site / MN), data = df_resultados)
l_md[[16]] <- lmer(GOF ~ p.z * MN * I.z + S.z + (I.z | Site / MN), data = df_resultados)
AICctab(l_md, weights = TRUE)
```

- classe de modelo estastítico selecionado: lmer( I + (I | Site / MN) )
```{r}
l_md <- vector("list",length = 4)
names(l_md) <- c("(1|Site)","(I|Site)","(1|Site/MN)","(I|Site/MN)")
l_md[[1]] <- lmer(GOF ~ p.z * MN * I.z + S.z + (1 | Site), data = df_resultados)
l_md[[2]] <- lmer(GOF ~ p.z * MN * I.z + S.z + (I.z | Site), data = df_resultados)
l_md[[3]] <- lmer(GOF ~ p.z * MN * I.z + S.z + (1 | Site / MN), data = df_resultados)
l_md[[4]] <- lmer(GOF ~ p.z * MN * I.z + S.z + (I.z | Site / MN), data = df_resultados)
AICctab(l_md, weights = TRUE)
```


- modelo cheio: GOF ~ p * MN * I + S + (I | Site / MN)
- todas as hipóteses: ~1, ~p; ~MN; ~I; ~S; ~p * MN; ~p * I; ~p + S; ~MN + S; ~MN * I; ~I + S; ~p * MN + S; ~p * I + S;  ~MN * I + S; ~p * MN * I + S

```{r}
l_md <- vector("list",length = 15)
names(l_md) <- c("1","p","MN","I","S","p * MN","p * I","MN * I","p + S","MN + S", "I + S","p * MN + S","p * I + S","MN * I + S","p * MN * I + S")
l_md[[1]] <- lmer(GOF ~ 1 + (1 | Site), data = df_resultados)
l_md[[2]] <- lmer(GOF ~ p.z + (1 | Site), data = df_resultados)
l_md[[3]] <- lmer(GOF ~ MN + (1 | Site / MN), data = df_resultados)
l_md[[4]] <- lmer(GOF ~ I.z + (I.z | Site), data = df_resultados)
l_md[[5]] <- lmer(GOF ~ S.z + (1 | Site), data = df_resultados)
l_md[[6]] <- lmer(GOF ~ p.z * MN + (1 | Site / MN), data = df_resultados)
l_md[[7]] <- lmer(GOF ~ p.z * I.z + (I.z | Site), data = df_resultados)
l_md[[8]] <- lmer(GOF ~ MN * I.z + (I.z | Site / MN), data = df_resultados)
l_md[[9]] <- lmer(GOF ~ p.z + S.z + (1 | Site), data = df_resultados)
l_md[[10]] <- lmer(GOF ~ MN + S.z + (1 | Site / MN), data = df_resultados)
l_md[[11]] <- lmer(GOF ~ I.z + S.z + (I.z | Site), data = df_resultados)
l_md[[12]] <- lmer(GOF ~ p.z * MN + S.z + (1 | Site / MN), data = df_resultados)
l_md[[13]] <- lmer(GOF ~ p.z * I.z + S.z + (I.z | Site), data = df_resultados)
l_md[[14]] <- lmer(GOF ~ MN * I.z + S.z + (I.z | Site / MN), data = df_resultados)
l_md[[15]] <- lmer(GOF ~ p.z * MN * I.z + S.z + (I.z | Site / MN), data = df_resultados)
AICctab(l_md, weights = TRUE)
```

```{r}
(r2_GOF <- sapply(l_md, r.squaredGLMM) %>% t)
```

```{r}
l_md[[15]] %>% summary
```

<!--
#### GOF ####
__EE + EI__

```{r GOF EE+EI 1selecao de funcao de ligacao, echo=FALSE}
#0) criação dos dados e gráfico
df_md <- df_resultados %>% dplyr::select(Site, k, GOF, p.z,p)
# df_md %>% ggplot(aes(x=p,y=GOF)) + geom_point() + facet_wrap(~k,ncol = 4)

#i) seleção da combinação de funcao de ligacao e distribuicao teorica utilizando apenas o modelo cheio
l_md <- vector("list", length = 4)
names(l_md) <- c("logit-bin","probit-bin","cloglog - bin","normal")
l_md[[1]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k + (1 | Site), 
                    family = "binomial",df_md)
l_md[[2]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k + (1 | Site), 
                    family = "binomial"(link=probit),df_md)
l_md[[3]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k + (1 | Site), 
                    family = "binomial"(link=cloglog), data = df_md)
l_md[[4]] <- lmer(GOF ~ p.z * k + (1 | Site), data = df_md)

# AICctab(l_md, weights = TRUE)
# df_md %>% ggplot(aes(x=p.z,y=GOF)) + geom_point() + facet_wrap(~k,ncol=4)
# df_md %>% ggplot(aes(x=p,y=GOF)) + geom_point() + facet_wrap(~k,ncol=4)
```
Como o R2 do modelo cheio estava muito baixo eu resolvi utilizar uma outra distribuição de probabilidade e função de ligação.


```{r GOF EE EI selecao}
# i) construção de modelos
l_md <- vector("list",length = 5)
names(l_md) <- c("GOF ~ p * k", "GOF ~ p + k", "GOF ~ p", "GOF ~ k","GOF ~ 1")
l_md[[1]] <- lmer(GOF ~ p.z * k + (1 | Site),df_md)
l_md[[2]] <- lmer(GOF ~ p.z + k + (1 | Site),df_md)
l_md[[3]] <- lmer(GOF ~ p.z + (1 | Site),df_md)
l_md[[4]] <- lmer(GOF ~ k + (1 | Site),df_md)
l_md[[5]] <- lmer(GOF ~ 1 + (1 | Site),df_md)
# l_md %<>% llply(.,function(X) update(X,control=glmerControl(optimizer="bobyqa", optCtrl = list(maxfun=2e5)))) 

# ii) seleção de modelos.
AICctab(l_md, weights = TRUE)

# hipótese selecionada #
md_GOF <- l_md[[1]]
# summary(md_GOF)
# 
(r2_GOF <- sapply(l_md, r.squaredGLMM))
# r2_GOF[1,]/r2_GOF[2,] * 100 %>% round(3)
# md_GOF %>% fixef() # parâmetros do efeito fixo
# md_GOF %>% ranef() # parâmetros do efeito aleatório

## inner_join com os resultados do modelo ##
df_md %<>% inner_join(.,augment(md_GOF),by=c("Site","k","GOF","p.z"))
```

__Figura 1__ [EE + EI] Seleção de modelos e R quadrado marginal e condicional da seleção de modelos


```{r GOF EE EI 1avaliacao modelo selecionado, echo=FALSE,message=FALSE,include=TRUE}
# gráficos diagnóstico
l_p <- vector("list",length = 3)
l_p[[1]] <- ggplot(df_md,aes(x=.fitted,y=.resid))+
  geom_smooth(se=T,col="red") +
  geom_point() +
  ggtitle("gráfico diagnostico") + 
  labs(x="predito",y="residuo") +
  facet_wrap(~k,ncol=4)
l_p[[2]] <- ggplot(df_md,aes(x=p.z,y=.resid)) + 
  geom_smooth(se=T,col="red") +
  geom_point() +
  labs(x="p(z)",y="residuo") +
  facet_wrap(~k,ncol=4)
l_p[[3]] <- ggplot(mutate(df_md,p_class = cut(p.z,12)),aes(x=k,y=.resid)) + 
  geom_boxplot() + 
  labs(x="k",y="residuo")
  # geom_smooth(se=F,col="red") +
  # geom_point() +
  # facet_wrap(~p_class,ncol=4)
# grid.arrange(l_p[[1]], l_p[[2]], l_p[[3]],
#              layout_matrix = rbind(rep(1,4),rep(1,4),
#                                    rep(2,4),rep(2,4),
#                                    rep(3,4)) 
#              )
l_p[[1]]
```

__Figura 2__- modelo selecionado GOF: resíduos ~ ajustado. A variância não é constante ao longo dos valores fitados e parece que existe uma tendência na nuvem de dados, o que pode indicar que o modelo não conseguiu linearizar os dados.

A regressão dos resíduos contra o predito e as duas variáveis respostas (p e k) mostram que os modelos ajustados não apresentam boa congruência com os dados: a variância não é constante ao longo dos valores fitados para nenhum nível de k; e parece que há uma pequena tendência nos dados, principalmente para o nível 0.25 de k. Outra forma de avaliar a congruência com os dados é plotar o modelo ajustado com o observado:

```{r GOF EE EI 1exploracao grafica dos resultados - estimativa e intervalo de confianca bootsrap, echo=F,fig.height=7}
## novo conjunto de dados ##
# objetivo: criar todas as combinações entre as preditoras
df_newdat <- expand.grid(Site = df_md$Site[1],
                         k = unique(df_md$k),
                         p.z = seq(min(df_md$p.z)*1.1,max(df_md$p.z)*1.1, length=50)) #no código original é length=50, qual a implicação dessa mudança?
## Funçoes a serem calculadas a cada simulação ##
# Previstos por efeitos fixos e aleatórios
f1 <- function(.) predict(.,newdata=df_newdat)
# Previstos por efeitos fixos (argumento re.form=~0)
f2 <- function(.) predict(.,newdata=df_newdat, re.form=~0)
## Os dois bootstraps. Ajuste o argumento ncpus para o numero de cores de seu computador
b1 <- bootMer(md_GOF, FUN = f1, nsim=1000, parallel="multicore", ncpus=3) #fixos e aleatorios
b2 <- bootMer(md_GOF, FUN = f2, nsim=1000, parallel="multicore", ncpus=3) #fixos
## calcula as médias e intervalos de confiança quantílicos para cada combinação de preditoras
## no novo conjunto de dados
df_newdat$p <- df_newdat$p.z*sd(df_md$p) + mean(df_md$p) #?
df_newdat$mean <- apply(b1$t,2,mean)
df_newdat$IC.low <- apply(b1$t,2,quantile, 0.025)
df_newdat$IC.upp <- apply(b1$t,2,quantile, 0.975)
df_newdat$mean.fixed <- apply(b2$t,2,mean)
df_newdat$IC.low.fixed <- apply(b2$t,2,quantile, 0.025)
df_newdat$IC.upp.fixed <- apply(b2$t,2,quantile, 0.975)
## Plots de GOF/100 x cobertura standardizada com intervalos de predição
df_md %>%
    ggplot(aes(x=p,y=GOF) ) + 
    geom_ribbon(aes(y=mean, ymin=IC.low, ymax=IC.upp), data=df_newdat, col="gray", alpha=0.5) +
    geom_ribbon(aes(y=mean, ymin=IC.low.fixed, ymax=IC.upp.fixed), data=df_newdat, col="gray", alpha=0.5) +
    geom_line(aes(x=p, y=mean.fixed), data=df_newdat) +
    geom_point() +
    ggtitle("[EE + EI] GOF ~ p * k + (1|Sitio)") + 
    facet_wrap(~k,ncol=4)
```

__Figura 3__ GOF: observado e o estimado segundo o modelo mais plausível + intervarlo de confiança 95% bootstrap. Entre linhas brancas o intervalo de confiança considerando apenas os efeitos fixos do modelo, fora dela, na região cinza claro, o intervalo de confiança considerando efeitos fixos e efeitos aleatórios. A inclinação da tendência geral varia em função de k para p: para a proporção de propágulos que permanecem até $l_{cel}$ metros da planta progenitora = 0.99, observamos um efeito negativo de p; com o aumento da proporção de propágulos observamos a atenuação dessa tendência chegando a ser quase nula para proporção ~ 0.50 e invertendo o efeito em 0.25, onde p apresenta efeito positivo. O efeito de p para os resultados de MNEI podem ser negligenciados, além disso é a categoria que apresenta o melhor ajuste do modelo, sendo que para k = 0.25 é onde observa-se maior variância entre os resíduos. 



__EE__

```{r GOF EE 1selecao de funcao de ligacao, echo=FALSE}
#0) criação dos dados e gráfico
df_md <- df_resultados %>% dplyr::select(Site, k, GOF, p.z,p,sd_k, DA) %>% filter(k != "EI") %>% mutate(d = sd_k/sqrt(2))
# df_md %>% ggplot(aes(x=p,y=GOF)) + geom_point() + facet_wrap(~k,ncol = 4)
# df_md %>% mutate(DA_class = cut(DA,12)) %>% ggplot(aes(x=k,y=d,group=Site)) + 
#   geom_smooth(method = "loess") + 
#   geom_point() +
#   facet_wrap(~ DA_class,ncol=4)

#i) seleção da combinação de funcao de ligacao e distribuicao teorica utilizando apenas o modelo cheio
l_md <- vector("list", length = 8)
names(l_md) <- c("lb 1|S","lb d|S","pb 1|S","pb d|S","cb 1|S","cb d|S","n 1|S","n d|S")
l_md[[1]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k + (1 | Site),  # erro de convergencia
                   family = "binomial",
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   df_md)
l_md[[2]] <- glmer(cbind(GOF,100-GOF) ~ p.z * d + (d | Site), 
                   family = "binomial",
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   df_md)
l_md[[3]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k + (1 | Site), # erro de convergencia 
                   family = "binomial"(link=probit),
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   df_md)
l_md[[4]] <- glmer(cbind(GOF,100-GOF) ~ p.z * d + (d | Site), 
                   family = "binomial"(link=probit),
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   df_md)
l_md[[5]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k + (1 | Site), # erro de convergencia 
                   family = "binomial"(link=cloglog),
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   data = df_md)
l_md[[6]] <- glmer(cbind(GOF,100-GOF) ~ p.z * d + (d | Site), 
                   family = "binomial"(link=cloglog), 
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   data = df_md)
l_md[[7]] <- lmer(GOF ~ p.z * k + (1 | Site), data = df_md)
l_md[[8]] <- lmer(GOF ~ p.z * d + (d | Site), data = df_md)

# funcao de dispersao = categorica
# l_md <- vector("list", length = 4)
# names(l_md) <- c("lb 1|S","pb 1|S","cb 1|S","n 1|S")
# l_md[[1]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k + (1 | Site), 
#                     family = "binomial",df_md)
# l_md[[2]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k + (1 | Site), 
#                     family = "binomial"(link=probit),df_md)
# l_md[[3]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k + (1 | Site), 
#                     family = "binomial"(link=cloglog), data = df_md)
# l_md[[4]] <- lmer(GOF ~ p.z * k + (1 | Site), data = df_md)

# AICctab(l_md, weights = TRUE)
# sapply(l_md, r.squaredGLMM)
# df_md %>% mutate(p_class = cut(p,20)) %>% 
  # ggplot(aes(x=d,y=GOF,group=Site)) + geom_point() + geom_line() + facet_wrap(~p_class,ncol=4)
```
Como o R2 do modelo cheio estava muito baixo eu resolvi utilizar uma outra distribuição de probabilidade e função de ligação.

__figura 4__ d ~ k, distância média de 

```{r GOF EE selecao, warning=FALSE}
# # i) construção de modelos
l_md <- vector("list",length = 5)
names(l_md) <- c("GOF ~ p * d", "GOF ~ p + d", "GOF ~ p", "GOF ~ d","GOF ~ 1")
l_md[[1]] <- glmer(cbind(GOF,100-GOF) ~ p.z * d + (d | Site), 
                   family = "binomial"(link=probit),
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   df_md)
l_md[[2]] <- glmer(cbind(GOF,100-GOF) ~ p.z + d + (d | Site), 
                   family = "binomial"(link=probit),
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   df_md)
l_md[[3]] <- glmer(cbind(GOF,100-GOF) ~ p.z + (1 | Site), 
                   family = "binomial"(link=probit),
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   df_md)
l_md[[4]] <- glmer(cbind(GOF,100-GOF) ~ d + (d | Site), 
                   family = "binomial"(link=probit),
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   df_md)
l_md[[5]] <- glmer(cbind(GOF,100-GOF) ~ 1 + (1 | Site), 
                   family = "binomial"(link=probit),
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   df_md)
# # l_md %<>% llply(.,function(X) update(X,control=glmerControl(optimizer="bobyqa", optCtrl = list(maxfun=2e5)))) 
# 
# # ii) seleção de modelos.
print("tabela de selecao de hipoteses")
AICctab(l_md, weights = TRUE)
# 
# # hipótese selecionada #
# md_GOF <- l_md[[1]]
# # summary(md_GOF)
# # 
print("R2m e R2c")
(r2_GOF <- sapply(l_md, r.squaredGLMM))
print("R2m / R2c")
r2_GOF[1,]/r2_GOF[2,] * 100 %>% round(3)
# # md_GOF %>% fixef() # parâmetros do efeito fixo
# # md_GOF %>% ranef() # parâmetros do efeito aleatório
# 
# ## inner_join com os resultados do modelo ##
# df_md %<>% inner_join(.,augment(md_GOF),by=c("Site","k","GOF","p.z"))
```

__Figura 4__ [EE] Seleção de modelos e R quadrado marginal e condicional da seleção de modelos

Três hipóteses são igualmente plausíveis para descrever os efeitos da porcentagem de cobertura vegetal na paisagem (p) e da distância média de dispersão (d), o maior peso de evidência está para a hipótese que considera apenas o efeito de d, seguindo para a hipótese de interação entre p e d e de soma entre as duas variáveis. Nota-se que as hipóteses fora do intervalo de plausibilidade são aquelas que apresentam R2m < 0.57. O poder de explicação de R2m do modelo considerando apenas o conjunto de dados EE é menor do que o observado para os modelos selecionados para o conjunto de dados  
 

```{r GOF EE 1avaliacao modelo selecionado, echo=FALSE,message=FALSE,include=TRUE}
# gráficos diagnóstico
# l_p <- vector("list",length = 3)
# l_p[[1]] <- ggplot(df_md,aes(x=.fitted,y=.resid))+
#   geom_smooth(se=T,col="red") +
#   geom_point() +
#   ggtitle("gráfico diagnostico") + 
#   labs(x="predito",y="residuo") +
#   facet_wrap(~k,ncol=4)
# l_p[[2]] <- ggplot(df_md,aes(x=p.z,y=.resid)) + 
#   geom_smooth(se=T,col="red") +
#   geom_point() +
#   labs(x="p(z)",y="residuo") +
#   facet_wrap(~k,ncol=4)
# l_p[[3]] <- ggplot(mutate(df_md,p_class = cut(p.z,12)),aes(x=k,y=.resid)) + 
#   geom_boxplot() + 
#   labs(x="k",y="residuo")
#   # geom_smooth(se=F,col="red") +
#   # geom_point() +
#   # facet_wrap(~p_class,ncol=4)
# # grid.arrange(l_p[[1]], l_p[[2]], l_p[[3]],
# #              layout_matrix = rbind(rep(1,4),rep(1,4),
# #                                    rep(2,4),rep(2,4),
# #                                    rep(3,4)) 
# #              )
# l_p[[1]]
```

__Figura 2__- modelo selecionado GOF: resíduos ~ ajustado. A variância não é constante ao longo dos valores fitados e parece que existe uma tendência na nuvem de dados, o que pode indicar que o modelo não conseguiu linearizar os dados.

A regressão dos resíduos contra o predito e as duas variáveis respostas (p e k) mostram que os modelos ajustados não apresentam boa congruência com os dados: a variância não é constante ao longo dos valores fitados para nenhum nível de k; e parece que há uma pequena tendência nos dados, principalmente para o nível 0.25 de k. Outra forma de avaliar a congruência com os dados é plotar o modelo ajustado com o observado:

```{r GOF EE 1exploracao grafica dos resultados - estimativa e intervalo de confianca bootsrap, echo=FALSE,fig.height=7}
## novo conjunto de dados ##
# objetivo: criar todas as combinações entre as preditoras
# df_newdat <- expand.grid(Site = df_md$Site[1],
#                          k = unique(df_md$k),
#                          p.z = seq(min(df_md$p.z)*1.1,max(df_md$p.z)*1.1, length=50)) #no código original é length=50, qual a implicação dessa mudança?
# ## Funçoes a serem calculadas a cada simulação ##
# # Previstos por efeitos fixos e aleatórios
# f1 <- function(.) predict(.,newdata=df_newdat)
# # Previstos por efeitos fixos (argumento re.form=~0)
# f2 <- function(.) predict(.,newdata=df_newdat, re.form=~0)
# ## Os dois bootstraps. Ajuste o argumento ncpus para o numero de cores de seu computador
# b1 <- bootMer(md_GOF, FUN = f1, nsim=1000, parallel="multicore", ncpus=3) #fixos e aleatorios
# b2 <- bootMer(md_GOF, FUN = f2, nsim=1000, parallel="multicore", ncpus=3) #fixos
# ## calcula as médias e intervalos de confiança quantílicos para cada combinação de preditoras
# ## no novo conjunto de dados
# df_newdat$p <- df_newdat$p.z*sd(df_md$p) + mean(df_md$p) #?
# df_newdat$mean <- apply(b1$t,2,mean)
# df_newdat$IC.low <- apply(b1$t,2,quantile, 0.025)
# df_newdat$IC.upp <- apply(b1$t,2,quantile, 0.975)
# df_newdat$mean.fixed <- apply(b2$t,2,mean)
# df_newdat$IC.low.fixed <- apply(b2$t,2,quantile, 0.025)
# df_newdat$IC.upp.fixed <- apply(b2$t,2,quantile, 0.975)
# ## Plots de GOF/100 x cobertura standardizada com intervalos de predição
# df_md %>%
#     ggplot(aes(x=p,y=GOF) ) + 
#     geom_ribbon(aes(y=mean, ymin=IC.low, ymax=IC.upp), data=df_newdat, col="gray", alpha=0.5) +
#     geom_ribbon(aes(y=mean, ymin=IC.low.fixed, ymax=IC.upp.fixed), data=df_newdat, col="gray", alpha=0.5) +
#     geom_line(aes(x=p, y=mean.fixed), data=df_newdat) +
#     geom_point() +
#     ggtitle("GOF ~ p * k + (1|Sitio)") + 
#     facet_wrap(~k,ncol=4)
```

__Figura 3__ GOF: observado e o estimado segundo o modelo mais plausível + intervarlo de confiança 95% bootstrap. Entre linhas brancas o intervalo de confiança considerando apenas os efeitos fixos do modelo, fora dela, na região cinza claro, o intervalo de confiança considerando efeitos fixos e efeitos aleatórios. A inclinação da tendência geral varia em função de k para p: para a proporção de propágulos que permanecem até $l_{cel}$ metros da planta progenitora = 0.99, observamos um efeito negativo de p; com o aumento da proporção de propágulos observamos a atenuação dessa tendência chegando a ser quase nula para proporção ~ 0.50 e invertendo o efeito em 0.25, onde p apresenta efeito positivo. O efeito de p para os resultados de MNEI podem ser negligenciados, além disso é a categoria que apresenta o melhor ajuste do modelo, sendo que para k = 0.25 é onde observa-se maior variância entre os resíduos. 

__EI__

#### m ####
```{r 2selecao de funcao de ligacao e distribuicao teorica, echo=FALSE}
## Dados ##
# df_resultados %>% select(Site, k, p, m, m_) %>% 
  # melt(.,id.vars = c("Site","k","p"))


#i) seleção da combinação de funcao de ligacao e distribuicao teorica utilizando apenas o modelo cheio
```

```{r m}
# i) construção de modelos
# ii) seleção de modelos.
```

```{r 2avaliacao modelo selecionado, echo=FALSE}
# gráficos diagnóstico
```

```{r 2exploracao grafica dos resultados, echo=FALSE}
# plotar os dados completos: x = p, y = VR; 13 paineis o primeiro é 0.99 e o último EI
```

#### $\theta$ ####
```{r 3selecao de funcao de ligacao e distribuicao teorica, echo=FALSE}
#i) seleção da combinação de funcao de ligacao e distribuicao teorica utilizando apenas o modelo cheio
```

```{r theta}
# i) construção de modelos
# ii) seleção de modelos.
```

```{r 3avaliacao modelo selecionado, echo=FALSE}
# gráficos diagnóstico
```

```{r 3exploracao grafica dos resultados, echo=FALSE}
# plotar os dados completos: x = p, y = VR; 13 paineis o primeiro é 0.99 e o último EI
```


__B) Parâmetro com maior significado biológico, uma vez que no equilíbrio U = taxa de extinção de espécies por evento de morte; uma aproximação da probabilidade de extinção de espécies raras na paisagem dado a riqueza observada na área amostrada.__

#### U ####
```{r 4selecao de funcao de ligacao e distribuicao teorica, echo=FALSE}
#i) seleção da combinação de funcao de ligacao e distribuicao teorica utilizando apenas o modelo cheio
```

```{r U}
# i) construção de modelos
# ii) seleção de modelos.
```

```{r 4avaliacao modelo selecionado, echo=FALSE}
# gráficos diagnóstico
```

```{r 4exploracao grafica dos resultados, echo=FALSE}
# plotar os dados completos: x = p, y = VR; 13 paineis o primeiro é 0.99 e o último EI
```



__C) Parâmetros a posteriori__


#### spp_I ####
```{r 5selecao de funcao de ligacao e distribuicao teorica, echo=FALSE}
#i) seleção da combinação de funcao de ligacao e distribuicao teorica utilizando apenas o modelo cheio
```

```{r spp_I}
# i) construção de modelos
# ii) seleção de modelos.
```

```{r 5avaliacao modelo selecionado, echo=FALSE}
# gráficos diagnóstico
```

```{r 5exploracao grafica dos resultados, echo=FALSE}
# plotar os dados completos: x = p, y = VR; 13 paineis o primeiro é 0.99 e o último EI
```


#### GOF ~ spp_I ####
```{r 6selecao de funcao de ligacao e distribuicao teorica, echo=FALSE}
#i) seleção da combinação de funcao de ligacao e distribuicao teorica utilizando apenas o modelo cheio
```

```{r GOF_spp.I}
# i) construção de modelos
# ii) seleção de modelos.
```

```{r 6avaliacao modelo selecionado, echo=FALSE}
# i) summary
# ii) gráficos diagnóstico
```



#########################################################################################################
m de MNEI 
#########################################################################################################

```{r selecao de hipoteses para m}
# dados #
df_md <- df_resultados %>% filter(k == "EI") %>% select(SiteCode,k,p,sd_k_,J,DA,m) %>% mutate(l_cel = 100/sqrt(J/DA),d=sd_k_/sqrt(2))

# selecao de dist. prob #
l_md <- vector("list", length = 4)
names(l_md) <- c("logit-bin","probit-bin","cloglog - bin","normal")
l_md[[1]] <- glm(cbind(m,1-m) ~ p * l_cel, 
                    family = "binomial",df_md)
l_md[[2]] <- glm(cbind(m,1-m) ~ p * l_cel, 
                    family = "binomial"(link=probit),df_md)
l_md[[3]] <- glm(cbind(m,1-m) ~ p * l_cel, 
                    family = "binomial"(link=cloglog), data = df_md)
l_md[[4]] <- lm(m ~ p * l_cel, data = df_md)
# AICctab(l_md, weights = TRUE)
## modelo mais plausivel: lm

# selecao de modelos #
l_md <- vector("list",length = 5)
names(l_md) <- c("~ p * l", "~ p + l", "~ l", "~ p", "~ 1")
l_md[[1]] <- lm(m ~ p * l_cel,df_md)
l_md[[2]] <- lm(m ~ p + l_cel,df_md)
l_md[[3]] <- lm(m ~ l_cel,df_md)
l_md[[4]] <- lm(m ~ p,df_md)
l_md[[5]] <- lm(m ~ 1,df_md)
AICctab(l_md, weights = TRUE)

#modelo mais plausível
coef(l_md[[5]])

```

ANEXO:
 apenas os itens 
_Resultados para MNEI_

A) Variável de congruência com o observado e parâmetros livres
-GOF, $\theta$, m ~ p 

B) Parâmetros convertidos
-U', d' ~ p

vi.a) d' ~ m
vi.b) k' ~ d'

C) Parâmetros estimados a posteriori
-spp_I, $S_M'$ ~ p

D) Congruência com o observado e spp input como métrica composto de theta e m
-GOF ~ spp_I

_Resultados para MNEE_ 
k <- factor( as.character( c(0.99,seq(0.95,0.50,by=-0.05),0.25) ) ) - a proporção de propágulos até a área imediata da planta progenitora ($l_{cel}$ metros da copa da árvore progenitora)

A) Variável de congruência com o observado e parâmetro livre 
-GOF, U ~ p * k + (1|Site)
        ~ p * d + (d|Site)
     
B) Parâmetros convertidos     
-m' ~ p * k + (1|Site)
    ~ p * d + (d|Site)

iv)$\theta'$ ~ p * k + (1|Site)
     ~ p * d + (d|Site)

C) Parâmetros estimados a posteriori
-spp_I' ~ p * k + (1|Site)
        ~ p * d + (d|Site)

vi)$S_M$ ~ p * k + (1|Site)
         ~ p * d + (d|Site)

-GOF ~ spp_I' * k + (1|Site)
     ~ spp_I' * d + (d|Site)
-->