---
title: "Resultados - artigo"
author: "Mori, Danilo Pereira"
date: "21 de maio de 2018"
output: html_document
---

```{r setup, include=FALSE} 
knitr::opts_chunk$set(echo = FALSE, tidy = TRUE, include = TRUE, warning = FALSE,cache = TRUE)
```

```{r dados e pacotes,warning=FALSE,message=FALSE,echo=FALSE}
# library(reshape2) # para mudar formato dos dados
library(RVAideMemoire) #gráficos diagnóstico dos GLMM
library(sjPlot) #gráficos de GLMM
library(MuMIn) # para R^2
# library(gridExtra)  #pacote para gráficos
# library(ggplot2)  # idem
library(sads)
library(lme4) # pacote de criação dos modelos estatísticos
# library(blme) # pacote para comparar os modelos, seleção per se
library(merTools) # para intervalos de previsao
library(tidyverse)
# library(broom) # para manipular os modelos 
library(magrittr) # p escrita
library(MASS)
library(car)
# library(plyr) 
# library(dplyr) 
df_resultados <- read_csv("/home/danilo/Documentos/Doutorado/artigo_mestrado/Rmd_e_dados/df_resultados.csv")
# df_resultados %>% str
df_resultados$MN <- factor(df_resultados$MN,levels = c("EI","EE"))
df_resultados$SiteCode <- factor(df_resultados$SiteCode)
df_resultados$k <- factor(df_resultados$k,levels=unique(df_resultados$k))
# df_resultados$k %>% contrasts()
# df_resultados$MN %>% contrasts()
```

<!--
Ideia geral dos métodos:

i) estabelecer valores do parâmetro de dispersão a priori;
ii) estimar taxa de especiação necessária para manter a riqueza no equilíbrio a partir do método de MNEE
iii) simular SADs neutras segundo MNEI e MNEE a partir dos mesmo parâmetros
-->


<!--
Resultados 2 completos:
-> distância média de dispersão ~ k * p + (k|Site) ou k_factor * p + (1|Site) [modelo completo se houver mais níveis de k e estiverem igualmente espaçados - segunda etapa] 

  - com isso avaliar quais as situações biológicas de limitação à dispersão que a simulação está ocorrendo
  - para comparação podemos plotar a curva das médias como comparação visual?
  - 1o gráfico: eixo y
-> congruência do simulado com o observado ~ k_factor * p + (1|Site)
  - em ambientes fragmentados o pressuposto de equivalência funcional não é uma boa aproximação
  -
  - com isso podemos avaliar se a SAD pode ser evidência suficiente para refutar neutralidade
  
  a SAD observada em um gradiente biológico onde o pressupostos da equivalência funcional não é uma boa aproximação (a fragmentação leva à modificação do habitat remanescente que se reflete nas taxas demográficas das populações observadas segundo sua espécies) [REESCREVER]

-> taxa de especiação necessária para manter a riqueza observada no equilíbrio dinâmico segundo um modelo neutro espacialmente explícito (U) ~ k_factor * p + (1|Site)
  - a teoria neutra pode ser uma boa aproximaçaõ para descrever a taxa de extinção de espécies raras em ambientes fragmentados (Gilbert et al. 2006)
  - o modelo neutro coalescente é uma boa aproximação para descrever o comportamento dos sistemas biológicos em diferentes contextos de fragmentação (Campos et al.)
  - no modelo coalescente o equilíbrio dinâmico é observado, nesse cenário a taxa de surgimento de singletons por evento de morte se igual à taxa de extinção de singletons
  - assim, a estimativa de taxa de especiaçaõ necessária para manter a riqueza observada no equilíbrio pode ser uma aproximação da taxa de extinção das espécies raras na paisagem.
-->


<!-- Esqueleto dos resultados 1

a) MNEI por verossimilhança
-GOF) Se MNEI tiver seus parâmetros livres ele sempre apresentara boa congruência com o observado?
-theta) Se o ajuste dos parâmetros informa algo além da SAD em si, esperamos observar efeito positivo de p, pois para maiores coberturas vegetais há mais indivíduos na região biogeográfica.
-m) Idem, esperamos observar efeito positivo de p, uma vez que quanto menor a cobertura vegetal de uma paisagem menor a concetividade entre as manchas de habitat (REFERÊNCIA)

b) Conversão de parâmetros de imigração
-par{MNEI} -> par{MNEE} [parâmetros com maior interpretação biológica - que permite a parametrização a partir de valores observados]
-distância médias de dispersão -> m segundo uma simulação coalescente em paisagem fragmentada.

c) Estimando U a partir de uma simulação coalescente
- 20 valores de U a partir de cada nível de d [MM]
- U -> theta, pela formula de conversão de theta [MM]
- U ~ p * d + (d | Site) [ou a formula que estamos utilizando]

d) Congruência do observado entre os modelos neutros consideramos mesmo conjunto de parâmetros
[MM]: estabelecemos distâncias de dispersões segundo diferentes cenários de limitação à dispersão médio (d), que parametrizados com valores observados na natureza para diferentes sindromes de dispersão. Para cada nível de d estimamos a taxa de especiação necessária para manter a riqueza observada, sob a hipótese de equilíbrio dinâmico, (U - singleton/evento de morte) segundo MNEE. Utilizamos o par U e d para gerar SADs segundo MNEE e convertemos U e d em theta e m, respectivamente, para gerar SADs segundo MNEI. Para cada MN geramos 100 SADs réplicas que comparamos com a respectiva SAD observada pelo teste de Kolmogorov-Smirnov; contabilizamos o número de vezes que não foi possível refutar a hipótese nula de que a SAD réplica e SAD observada são amostras de uma mesma distribuição teórica na variável GOF (Goodness-of-fit). Temos 80 sítios de amostragens, 30 rodadas de simulação para cada nível de MN (EE e EI).

- GOF ~ p * d * MN + (d | Site / MN)
MN: factor 2 levels: EE, EI
d: numeric 30 valores para todas as simulações

e) Parâmetro a posteori: espécies input (Condit et al. 2012)
- spp_I ~ p * d + (d|Site)
- GOF ~ spp_I * d * MN + (d | Site / MN)


-->



<!-- última paragráfo de material e métodos

Organizamos os resultados em 3 blocos de dados, aqueles para MNEE, MNEI e MNEE + MNEI. As variáveis resposta são: GOF, $\theta$, m, U, spp_I e d. As variáveis indepedentes são cobertura vegetal (p) e função de dispersão, que está sendo expressa de forma categorica(k), assim, podemos avaliar tanto os dados de MNEE, quanto para MNEE + MNEI; e de forma contínua d (distância média de dispersão da função de dispersão), para os dados de MNEE. Convertemos os parâmetros de MNEE U e d em $\theta'$, m'; e $\theta$ e m de MNEI em  U' e (d' e k'), considerando que $J_M$ = número de indivíduos na paisagem. Quando houve mais de uma observação para um mesmo Sítio de amostragem, então utilizamos a variável Sítio como variável categórica dos efeitos aleatórios do modelo linear; quando a função de dispersão foi categória utilizamos (1|Site) e  (d|Site) se ela foi contínua. Assim, temos duas maneiras de partir a variação prevista pelo modelo. O $R_m^2$ é a variação explicada pelos efeitos fixos do modelo, ou seja, p e/ou a variável relacionada à limitação à dispersão (k ou d) ('R quadrado marginal'); já o R quadrado condicional, $R_c^2$, é a variação associado tanto às variáveis de efeito fixo quanto ao efeito aleatório (sítio de amostragem). 
Acredito que uma métrica de comparação entre $R^2$ para GLM e GLMM seria considerar a razão $R_{GLMM}^2 = R_m^2 / R_c^2$? -->

<!--
## Sessão antiga, 18jun ##
Introdução da sessão de resultados:

Vou explorar o terceiro bloco de dados c(MNEE, MNEI), em anexo a análise dos dados para o conjunto de dados MNEE e MNEI. MNEE e MNEI diferem na forma que implementam a teoria neutra e na forma com que estimam os parâmetros a priori simulação. Assim, unir os resultados em uma mesma análise de dados tem que ser feita considerando a origem dos dados, para adequar com os resultados de MNEE organizei os dados pela proporção da chuva de propágulos que permanece até a área imediata a da copa da árvore progenitora (l_cel metros). Incluindo os dados de MNEI, são 13 níveis na variável "k", o primeiro nível é aquele com cenário de limitação à dispersão mais rigoroso (=0.99), o penúltimo nível é o cenário de limitação à dispersão menos realista (=0.25) e o último nível são os dados de MNEI. Em análise exploratória observamos que mesmo com valores razoáveis de m, MNEI apresentou d's superiores ao de MNEE em escala log (anexo) e como d está relacionado com a proporção de propágulos até a área imediata da planta progenitora (k) ordenei os níveis de "k" agrupando os valores de MNEI juntos no último nível. Existe grande variação no parâmetro 'm' estimado por verossimilhança, contudo, essa variação não apresenta efeito de p (anexo), então, não considerar a variação interna de m em MNEI não deve interferir na análise dos dados. Em anexo, há as análises auxiliares que inclui dos outros conjuntos de dados.
i) Os dois modelos conseguem apresentar boa congruência com o observado? 
ii) Se sim quais as característica da paisagem e da relação com a área amostrada que propiciam esse resultado? 
iii) Em cenários de limitação à dispersão biologicamente realistas o modelo neutro apresente boa congruência com os dados?
iv) Qual o efeito da fragmentação na diversidade da paisagem segundo o predito neutro?


## Esqueleto dos resultados - 18jun ##

a) resultados para os parâmetros de imigração para as distâncias simuladas: m, I e k. Tentar incluir os valores estimados em campo
b) v ~ p * par_imig + S + (par_imig | Site); par_imig = d, m, I, k
c) GOF ~ p * MN * par_imig + S + (par_imig | Site / MN) 


-->
<!--
Para faciltar o ajuste dos modelos mistos aplicamos a transformação z nas variáveis contínuas: 
-->

### Anexo 1: código auxiliar ###

```{r preparacao dos dados, echo=FALSE}
f_z <- function(x){
  m <- base::mean(x,na.rm=TRUE)
  sd <- sd(x,na.rm=TRUE)
  output <- (x-m)/sd
  return(output)
} 

df_resultados %<>% mutate(GOF.z = f_z(GOF),
                          DA.z = f_z(DA),
                          p.z = f_z(p),
                          S.z = f_z(S),
                          U.z = f_z(U),
                          m_.z = f_z(m_),
                          I.z = f_z(I),
                          d.z = f_z(d),
                          k.z0 = as.numeric(as.character(k)),
                          k.z = f_z(k.z0))

names(df_resultados)[1] <- "Site"
```

__par_imig ~ k __
<!--
i) seleção da estrutura aleatória, distribuição teórica e função de ligação
ii) seleção das hipóteses estatísticas  
-->

_d_

## Exploração gráfica ##

```{r graf}
# x11()
par(mfrow=c(3,2))
## d e d.z ##
# ~ norm
qqp(df_resultados$d, "norm",ylab="d (metros)") 
qqp(df_resultados$d.z, "norm",ylab="d.z (Z(d))") 
# ~ lnorm
qqp(df_resultados$d, "lnorm",ylab="d (metros)")
qqp(df_resultados$d.z, "lnorm",ylab="d.z (Z(d))")
# ~ gamma
fit_gamma1 <- fitdistr(df_resultados$d, "gamma")
qqp(df_resultados$d, "gamma", shape = fit_gamma1$estimate[[1]], rate = fit_gamma1$estimate[[2]],ylab="d (metros)")
## d.z ##
# ~ norm
# ~ lnorm
# ~ gamma
```

Figura A1. Gráficos quantile-quantile para três distribuições teóricas (normal, lognormal e gamma) e a variável d (metros) e z-transformada (d.z). Para a distribuição gamma utilizei ajustamos apenas a variável d, uma vez que o domínio da distribuição não contempla valores menores do que zero.

A distribuição que melhor se adequa aos dados é a distribuição gamma: i) ajusta maior porção dos dados em comparação com a normal (segunda melhor distribuição) e ii) consegue capturar a variação nas caudas da distribuição de valores obervados (em especial para valores pequenos), diferente da normal. Contudo, para comparar os resíduos eu vou construir duas classes de modelos cheio: uma normal e outra gamma.

O objetivo é avaliar o efeito da variável k na distância média de dispersão (d), para isso o modelo cheio vai considerar a variável DA, uma vez que k é definido como a proporção de propágulos até l_cel metros da planta progenitora. A largura da célula de simulação (l_cel) = 100/sqrt(DA) (PERGUNTA:devo utilizar DA ou a transformação de DA = I( 100/sqrt(DA) )? ).

-Formulas dos modelos estatísticos:
d ~ k + DA + (k|Site)
d ~ k_factor + DA + (1|Site)
```{r d k}
# df_resultados %>% str
## Seleção da estrutura eleatória ##
l_md <- vector("list",length = 8)
names(l_md) <- c("Gamma 1|Site","Gamma k|Site",
                 "log.Gamma 1|Site","log.Gamma k|Site",
                 "normal 1|Site","normal k|Site",
                 "log.normal 1|Site","log.normal k|Site")
l_md[[1]] <-  glmer(d ~ k + DA.z + (1|Site),family = "Gamma",data = df_resultados)
l_md[[2]] <-  glmer(d ~ k.z + DA.z + (k.z|Site),family = "Gamma",data = df_resultados)
l_md[[3]] <-  glmer(d ~ k + DA.z + (1|Site),family = "Gamma"(link=log),data = df_resultados)
l_md[[4]] <-  glmer(d ~ k.z + DA.z + (k.z|Site),family = "Gamma"(link=log),data = df_resultados)
l_md[[5]] <-  glmer(d ~ k + DA.z * (1|Site),family = "gaussian",data = df_resultados)
l_md[[6]] <-  glmer(d ~ k.z + DA.z + (k.z|Site),family = "gaussian",data = df_resultados)
l_md[[7]] <-  glmer(d ~ k + DA.z + (1|Site),family = "gaussian"(link=log),data = df_resultados)
l_md[[8]] <-  glmer(d ~ k.z + DA.z + (k.z|Site),family = "gaussian"(link=log),data = df_resultados)
AICctab(l_md,weights=T)
```
<!--
A estrutura aleatória selecionada foi (1|Site).
-->

O modelo global com distribuição gamma, função de ligação log e estrutura aleatória 1|Site foi o mais plausível. Segue sumário

```{r d k R2}
summary(l_md[[3]]) # problema de convergência, indicam para reescalonar as variáveis
```
<!--
Error: Error in r.squaredGLMM.merMod(X[[i]], ...) : do not know how to calculate variance for this family/link combination
27jun2018[Válido para lmer, não para normal link=log: acredito que se houver mais níveis de k e melhor distribuidos no campo de parâmetros aumentaria o R^2 de k|Site
-->

## 31jun2018 ##
- Problema de convergência:
convergence code: 0
Model is nearly unidentifiable: very large eigenvalue
 - Rescale variables?
ajuda: ?convergence

"
if you do see convergence warnings, and want to trouble-shoot/double-check the results, the following steps are recommended (examples are given below):

double-check the model specification and the data for mistakes

center and scale continuous predictor variables (e.g. with scale)

check for singularity: if any of the diagonal elements of the Cholesky factor are zero or very small, the convergence testing methods may be inappropriate (see examples)

double-check the Hessian calculation with the more expensive Richardson extrapolation method (see examples)

restart the fit from the apparent optimum, or from a point perturbed slightly away from the optimum

try all available optimizers (e.g. several different implementations of BOBYQA and Nelder-Mead, L-BFGS-B from optim, nlminb, ...) via the allFit() function, see ‘5.’ in the examples. While this will of course be slow for large fits, we consider it the gold standard; if all optimizers converge to values that are practically equivalent, then we would consider the convergence warnings to be false positives.
"


A única variável contínua que não foi rescalonada foi a resposta d, se aplicar transformação z em d, a variável resposta terá números negativos. Utilizando a variável DA ao inves de DA.z piora o caso. Alternativamente busquei simplificar o modelo: a) retirando a variável DA.z; e b) retirando o último nível de k (contudo como é um factor não há de fazer muita diferença) - para ambos não houve melhora.

PRÓXIMOS PASSOS PARA MELHORAR AJUSTE: uma alternativa fácil é reajustar a partir das estimativas feitas pelo modelo com problema de convergência e/ou modificar o otimizador.
PERGUNTAS NORTEADORAS: i) o aviso de problema de convergência é um falso positivo? 

Ben Bolker: Since the likelihood differs by <0.1 between the model fits, and the largest relative differences in the parameters are of the order of about 10^(-4), I would say that you have successfully demonstrated that the warning is a false positive and you can proceed with your initial model.


<!--
[pasta GLMM (...) scale issues] Some common examples:

-Some columns of our data might be different orders of magnitude to others, for instance gender might be encoded as a binary variable, while income might be stored in whole-dollar amounts.

-An outcome might be extremely rare

-The impact of variable X1 on Y could be orders of magnitude greater than the impact of variable X2. That is, it’s not the scale of the data that is causing issues so much as the scale of the parameters.


-->


Foram estimados 13 parâmetros e seus respectivos erro-padrão. Os resíduos escalonados variam de -3.956 até 6.554, pelos valores dos quantils parece que a distribuição dos resíduos não é simétrica ao redor da estimativa. Há dois avisos sobre convergência: a) Model failed to converge with max|grad|=4.11797 (tol = 0.001, component 1); b) Modelo is nearly unidentifiable: very large eigenvalue - Rescale variables?

25jun2018:
Para lidar com b modifiquei DA -> DA.z nos modelos globais
Com isso obtive o erro: 'converge code:0; Model is nearly unidentifiable: very large eigenvalue - Rescale variables?
- a transformação z de DA deveria ser o suficiente para lidar com problemas relacionados com escalamento de variáveis; a outra variável explanatória é categórica.
- vou continuar o estudo com esse modelo como global


```{r selecao d}
l_md <- vector("list",length = 4)
names(l_md) <- c("k+DA","DA","k","1")
l_md[[1]] <-  glmer(d ~ k + DA.z + (1|Site),family = "Gamma"(link=log),data = df_resultados)
l_md[[2]] <-  glmer(d ~ DA.z + (1|Site),family = "Gamma"(link=log),data = df_resultados)
l_md[[3]] <-  glmer(d ~ k + (1|Site),family = "Gamma"(link=log),data = df_resultados)
l_md[[4]] <-  glmer(d ~ 1 + (1|Site),family = "Gamma"(link=log),data = df_resultados)
AICctab(l_md)
```

O modelo global foi o mais plausível. [PROBLEMA DE CONVERGÊNCIA].

```{r model matrix d}
df_effect <- data.frame(par.class = c("beta",rep("alfa",length(levels(df_resultados$k)) ) ),
                        par.VE = c("DA.z",
                                   paste("k=",levels(df_resultados$k),sep="")),
                        par.value = c(exp(fixef(l_md[[1]])[13]),
                                      exp(fixef(l_md[[1]])[1]),
                                      exp(fixef(l_md[[1]])[2:12]-fixef(l_md[[1]])[1])) 
                        )
df_effect %>% ggplot(aes())
```



```{r obs e predito d}
# gráfico #
# df_resultados %>% ggplot(aes(x=DA.z,y=d)) + geom_point() + facet_wrap(~k,ncol=3,scales="free")
# broom::tidy(l_md[[1]])
df_reg <- broom::augment(l_md[[1]]) %>% mutate(predito = exp(.fitted),
                                               predito_min = exp())
ggplot(df_reg,aes(x=DA.z,y=d)) + geom_point() + geom_line(aes(x=DA.z,y=predito)) + facet_wrap(~k,ncol=3,scales="free")
```

figura 1. d ~ k * DA.z + (1|Site): observado (pontos) e predito (linha contínua)

```{r}
df_diag %>% ggplot(aes(x=DA.z,y=.resid)) + geom_smooth(method = "loess") + geom_point() + facet_wrap(~k,ncol=3,scales = "free")
```

Para avaliar alguma tendência no padrão de residuos, vou repetir a associação proposta nos modelos utilizados na seleção de modelos anterior:

```{r selecao modelos resid d}
l_md <- vector("list",length = 4)
names(l_md) <- c("k+DA","DA","k","1")
l_md[[1]] <-  lmer(.resid ~ k + DA.z + (1|Site),data = df_reg)
l_md[[2]] <-  lmer(.resid ~ DA.z + (1|Site),data = df_reg)
l_md[[3]] <-  lmer(.resid ~ k + (1|Site),data = df_reg)
l_md[[4]] <-  lmer(.resid ~ 1 + (1|Site),data = df_reg)
AICctab(l_md)
```

E ainda podemos avaliar a variância explicada pelo modelos:

```{r r2 resid d}
summary(l_md[[4]])
```

O modelo mais plausível não aponta para alguma associação entre os resíduos e as variáveis explanatórias, o quê corrobora a boa congruência entre observado e o predito. A seguir vou avaliar como os efeitos. Vou seguir considerando que apesar do problema de convergência 




__GOF__

<!--
i) selecao da funcao de ligacao e distribuicao de erros a partir da modelo cheio
ii) selecao do modelo mais plausível
iii) diagnóstico do modelo: Bolker et al.
-->

```{r GOF selecao de funcao de ligacao, echo=FALSE}
l_md <- vector("list", length = 16)
names(l_md) <- paste("k",rep(c("logit","probit","cloglog"),each=4))
# logito
l_md[[1]] <- glmer(cbind(GOF,100-GOF) ~ p.z * MN * d.z + S.z + (d.z | Site / MN), 
                   family = "binomial"(link=logit),
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   data = df_resultados)
l_md[[2]] <- glmer(cbind(GOF,100-GOF) ~ p.z * MN * k.z + S.z + (k.z | Site / MN), 
                   family = "binomial"(link=logit),
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   data = df_resultados)
l_md[[3]] <- glmer(cbind(GOF,100-GOF) ~ p.z * MN * m_.z + S.z + (m_.z | Site / MN), 
                   family = "binomial"(link=logit),
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   data = df_resultados)
l_md[[4]] <- glmer(cbind(GOF,100-GOF) ~ p.z * MN * I.z + S.z + (I.z | Site / MN), 
                    family = "binomial"(link=logit),
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   data = df_resultados)
# probito
l_md[[5]] <- glmer(cbind(GOF,100-GOF) ~ p.z * MN * d.z + S.z + (d.z | Site / MN), 
                    family = "binomial"(link=probit),
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   data = df_resultados)
l_md[[6]] <- glmer(cbind(GOF,100-GOF) ~ p.z * MN * k.z + S.z + (k.z | Site / MN), 
                    family = "binomial"(link=probit),
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   data = df_resultados)
l_md[[7]] <- glmer(cbind(GOF,100-GOF) ~ p.z * MN * m_.z + S.z + (m_.z | Site / MN), 
                    family = "binomial"(link=probit),
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   data = df_resultados)
l_md[[8]] <- glmer(cbind(GOF,100-GOF) ~ p.z * MN * I.z + S.z + (I.z | Site / MN), 
                    family = "binomial"(link=probit),
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   data = df_resultados)
# cloglog
l_md[[9]] <- glmer(cbind(GOF,100-GOF) ~ p.z * MN * d.z + S.z + (d.z | Site / MN), 
                    family = "binomial"(link=cloglog),
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   data = df_resultados)
l_md[[10]] <- glmer(cbind(GOF,100-GOF) ~ p.z * MN * k.z + S.z + (k.z | Site / MN), 
                    family = "binomial"(link=cloglog),
                    control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   data = df_resultados)
l_md[[11]] <- glmer(cbind(GOF,100-GOF) ~ p.z * MN * m_.z + S.z + (m_.z | Site / MN), 
                    family = "binomial"(link=cloglog),
                    control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   data = df_resultados)
l_md[[12]] <- glmer(cbind(GOF,100-GOF) ~ p.z * MN * I.z + S.z + (I.z | Site / MN), 
                    family = "binomial"(link=cloglog),
                    control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   data = df_resultados)
# ID normal
l_md[[13]] <- lmer(GOF ~ p.z * MN * d.z + S.z + (d.z | Site / MN), data = df_resultados)
l_md[[14]] <- lmer(GOF ~ p.z * MN * k.z + S.z + (k.z | Site / MN), data = df_resultados)
l_md[[15]] <- lmer(GOF ~ p.z * MN * m_.z + S.z + (m_.z | Site / MN), data = df_resultados)
l_md[[16]] <- lmer(GOF ~ p.z * MN * I.z + S.z + (I.z | Site / MN), data = df_resultados)
AICctab(l_md, weights = TRUE)
```

- classe de modelo estastítico selecionado: lmer( I + (I | Site / MN) )
```{r}
l_md <- vector("list",length = 4)
names(l_md) <- c("(1|Site)","(I|Site)","(1|Site/MN)","(I|Site/MN)")
l_md[[1]] <- lmer(GOF ~ p.z * MN * I.z + S.z + (1 | Site), data = df_resultados)
l_md[[2]] <- lmer(GOF ~ p.z * MN * I.z + S.z + (I.z | Site), data = df_resultados)
l_md[[3]] <- lmer(GOF ~ p.z * MN * I.z + S.z + (1 | Site / MN), data = df_resultados)
l_md[[4]] <- lmer(GOF ~ p.z * MN * I.z + S.z + (I.z | Site / MN), data = df_resultados)
AICctab(l_md, weights = TRUE)
```


- modelo cheio: GOF ~ p * MN * I + S + (I | Site / MN)
- todas as hipóteses: ~1, ~p; ~MN; ~I; ~S; ~p * MN; ~p * I; ~p + S; ~MN + S; ~MN * I; ~I + S; ~p * MN + S; ~p * I + S;  ~MN * I + S; ~p * MN * I + S

```{r}
l_md <- vector("list",length = 15)
names(l_md) <- c("1","p","MN","I","S","p * MN","p * I","MN * I","p + S","MN + S", "I + S","p * MN + S","p * I + S","MN * I + S","p * MN * I + S")
l_md[[1]] <- lmer(GOF ~ 1 + (1 | Site), data = df_resultados)
l_md[[2]] <- lmer(GOF ~ p.z + (1 | Site), data = df_resultados)
l_md[[3]] <- lmer(GOF ~ MN + (1 | Site / MN), data = df_resultados)
l_md[[4]] <- lmer(GOF ~ I.z + (I.z | Site), data = df_resultados)
l_md[[5]] <- lmer(GOF ~ S.z + (1 | Site), data = df_resultados)
l_md[[6]] <- lmer(GOF ~ p.z * MN + (1 | Site / MN), data = df_resultados)
l_md[[7]] <- lmer(GOF ~ p.z * I.z + (I.z | Site), data = df_resultados)
l_md[[8]] <- lmer(GOF ~ MN * I.z + (I.z | Site / MN), data = df_resultados)
l_md[[9]] <- lmer(GOF ~ p.z + S.z + (1 | Site), data = df_resultados)
l_md[[10]] <- lmer(GOF ~ MN + S.z + (1 | Site / MN), data = df_resultados)
l_md[[11]] <- lmer(GOF ~ I.z + S.z + (I.z | Site), data = df_resultados)
l_md[[12]] <- lmer(GOF ~ p.z * MN + S.z + (1 | Site / MN), data = df_resultados)
l_md[[13]] <- lmer(GOF ~ p.z * I.z + S.z + (I.z | Site), data = df_resultados)
l_md[[14]] <- lmer(GOF ~ MN * I.z + S.z + (I.z | Site / MN), data = df_resultados)
l_md[[15]] <- lmer(GOF ~ p.z * MN * I.z + S.z + (I.z | Site / MN), data = df_resultados)
AICctab(l_md, weights = TRUE)
```

```{r}
(r2_GOF <- sapply(l_md, r.squaredGLMM) %>% t)
```

```{r}
l_md[[15]] %>% summary
```

<!--
#### GOF ####
__EE + EI__

```{r GOF EE+EI 1selecao de funcao de ligacao, echo=FALSE}
#0) criação dos dados e gráfico
df_md <- df_resultados %>% dplyr::select(Site, k, GOF, p.z,p)
# df_md %>% ggplot(aes(x=p,y=GOF)) + geom_point() + facet_wrap(~k,ncol = 4)

#i) seleção da combinação de funcao de ligacao e distribuicao teorica utilizando apenas o modelo cheio
l_md <- vector("list", length = 4)
names(l_md) <- c("logit-bin","probit-bin","cloglog - bin","normal")
l_md[[1]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k + (1 | Site), 
                    family = "binomial",df_md)
l_md[[2]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k + (1 | Site), 
                    family = "binomial"(link=probit),df_md)
l_md[[3]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k + (1 | Site), 
                    family = "binomial"(link=cloglog), data = df_md)
l_md[[4]] <- lmer(GOF ~ p.z * k + (1 | Site), data = df_md)

# AICctab(l_md, weights = TRUE)
# df_md %>% ggplot(aes(x=p.z,y=GOF)) + geom_point() + facet_wrap(~k,ncol=4)
# df_md %>% ggplot(aes(x=p,y=GOF)) + geom_point() + facet_wrap(~k,ncol=4)
```
Como o R2 do modelo cheio estava muito baixo eu resolvi utilizar uma outra distribuição de probabilidade e função de ligação.


```{r GOF EE EI selecao}
# i) construção de modelos
l_md <- vector("list",length = 5)
names(l_md) <- c("GOF ~ p * k", "GOF ~ p + k", "GOF ~ p", "GOF ~ k","GOF ~ 1")
l_md[[1]] <- lmer(GOF ~ p.z * k + (1 | Site),df_md)
l_md[[2]] <- lmer(GOF ~ p.z + k + (1 | Site),df_md)
l_md[[3]] <- lmer(GOF ~ p.z + (1 | Site),df_md)
l_md[[4]] <- lmer(GOF ~ k + (1 | Site),df_md)
l_md[[5]] <- lmer(GOF ~ 1 + (1 | Site),df_md)
# l_md %<>% llply(.,function(X) update(X,control=glmerControl(optimizer="bobyqa", optCtrl = list(maxfun=2e5)))) 

# ii) seleção de modelos.
AICctab(l_md, weights = TRUE)

# hipótese selecionada #
md_GOF <- l_md[[1]]
# summary(md_GOF)
# 
(r2_GOF <- sapply(l_md, r.squaredGLMM))
# r2_GOF[1,]/r2_GOF[2,] * 100 %>% round(3)
# md_GOF %>% fixef() # parâmetros do efeito fixo
# md_GOF %>% ranef() # parâmetros do efeito aleatório

## inner_join com os resultados do modelo ##
df_md %<>% inner_join(.,augment(md_GOF),by=c("Site","k","GOF","p.z"))
```

__Figura 1__ [EE + EI] Seleção de modelos e R quadrado marginal e condicional da seleção de modelos


```{r GOF EE EI 1avaliacao modelo selecionado, echo=FALSE,message=FALSE,include=TRUE}
# gráficos diagnóstico
l_p <- vector("list",length = 3)
l_p[[1]] <- ggplot(df_md,aes(x=.fitted,y=.resid))+
  geom_smooth(se=T,col="red") +
  geom_point() +
  ggtitle("gráfico diagnostico") + 
  labs(x="predito",y="residuo") +
  facet_wrap(~k,ncol=4)
l_p[[2]] <- ggplot(df_md,aes(x=p.z,y=.resid)) + 
  geom_smooth(se=T,col="red") +
  geom_point() +
  labs(x="p(z)",y="residuo") +
  facet_wrap(~k,ncol=4)
l_p[[3]] <- ggplot(mutate(df_md,p_class = cut(p.z,12)),aes(x=k,y=.resid)) + 
  geom_boxplot() + 
  labs(x="k",y="residuo")
  # geom_smooth(se=F,col="red") +
  # geom_point() +
  # facet_wrap(~p_class,ncol=4)
# grid.arrange(l_p[[1]], l_p[[2]], l_p[[3]],
#              layout_matrix = rbind(rep(1,4),rep(1,4),
#                                    rep(2,4),rep(2,4),
#                                    rep(3,4)) 
#              )
l_p[[1]]
```

__Figura 2__- modelo selecionado GOF: resíduos ~ ajustado. A variância não é constante ao longo dos valores fitados e parece que existe uma tendência na nuvem de dados, o que pode indicar que o modelo não conseguiu linearizar os dados.

A regressão dos resíduos contra o predito e as duas variáveis respostas (p e k) mostram que os modelos ajustados não apresentam boa congruência com os dados: a variância não é constante ao longo dos valores fitados para nenhum nível de k; e parece que há uma pequena tendência nos dados, principalmente para o nível 0.25 de k. Outra forma de avaliar a congruência com os dados é plotar o modelo ajustado com o observado:

```{r GOF EE EI 1exploracao grafica dos resultados - estimativa e intervalo de confianca bootsrap, echo=F,fig.height=7}
## novo conjunto de dados ##
# objetivo: criar todas as combinações entre as preditoras
df_newdat <- expand.grid(Site = df_md$Site[1],
                         k = unique(df_md$k),
                         p.z = seq(min(df_md$p.z)*1.1,max(df_md$p.z)*1.1, length=50)) #no código original é length=50, qual a implicação dessa mudança?
## Funçoes a serem calculadas a cada simulação ##
# Previstos por efeitos fixos e aleatórios
f1 <- function(.) predict(.,newdata=df_newdat)
# Previstos por efeitos fixos (argumento re.form=~0)
f2 <- function(.) predict(.,newdata=df_newdat, re.form=~0)
## Os dois bootstraps. Ajuste o argumento ncpus para o numero de cores de seu computador
b1 <- bootMer(md_GOF, FUN = f1, nsim=1000, parallel="multicore", ncpus=3) #fixos e aleatorios
b2 <- bootMer(md_GOF, FUN = f2, nsim=1000, parallel="multicore", ncpus=3) #fixos
## calcula as médias e intervalos de confiança quantílicos para cada combinação de preditoras
## no novo conjunto de dados
df_newdat$p <- df_newdat$p.z*sd(df_md$p) + mean(df_md$p) #?
df_newdat$mean <- apply(b1$t,2,mean)
df_newdat$IC.low <- apply(b1$t,2,quantile, 0.025)
df_newdat$IC.upp <- apply(b1$t,2,quantile, 0.975)
df_newdat$mean.fixed <- apply(b2$t,2,mean)
df_newdat$IC.low.fixed <- apply(b2$t,2,quantile, 0.025)
df_newdat$IC.upp.fixed <- apply(b2$t,2,quantile, 0.975)
## Plots de GOF/100 x cobertura standardizada com intervalos de predição
df_md %>%
    ggplot(aes(x=p,y=GOF) ) + 
    geom_ribbon(aes(y=mean, ymin=IC.low, ymax=IC.upp), data=df_newdat, col="gray", alpha=0.5) +
    geom_ribbon(aes(y=mean, ymin=IC.low.fixed, ymax=IC.upp.fixed), data=df_newdat, col="gray", alpha=0.5) +
    geom_line(aes(x=p, y=mean.fixed), data=df_newdat) +
    geom_point() +
    ggtitle("[EE + EI] GOF ~ p * k + (1|Sitio)") + 
    facet_wrap(~k,ncol=4)
```

__Figura 3__ GOF: observado e o estimado segundo o modelo mais plausível + intervarlo de confiança 95% bootstrap. Entre linhas brancas o intervalo de confiança considerando apenas os efeitos fixos do modelo, fora dela, na região cinza claro, o intervalo de confiança considerando efeitos fixos e efeitos aleatórios. A inclinação da tendência geral varia em função de k para p: para a proporção de propágulos que permanecem até $l_{cel}$ metros da planta progenitora = 0.99, observamos um efeito negativo de p; com o aumento da proporção de propágulos observamos a atenuação dessa tendência chegando a ser quase nula para proporção ~ 0.50 e invertendo o efeito em 0.25, onde p apresenta efeito positivo. O efeito de p para os resultados de MNEI podem ser negligenciados, além disso é a categoria que apresenta o melhor ajuste do modelo, sendo que para k = 0.25 é onde observa-se maior variância entre os resíduos. 



__EE__

```{r GOF EE 1selecao de funcao de ligacao, echo=FALSE}
#0) criação dos dados e gráfico
df_md <- df_resultados %>% dplyr::select(Site, k, GOF, p.z,p,sd_k, DA) %>% filter(k != "EI") %>% mutate(d = sd_k/sqrt(2))
# df_md %>% ggplot(aes(x=p,y=GOF)) + geom_point() + facet_wrap(~k,ncol = 4)
# df_md %>% mutate(DA_class = cut(DA,12)) %>% ggplot(aes(x=k,y=d,group=Site)) + 
#   geom_smooth(method = "loess") + 
#   geom_point() +
#   facet_wrap(~ DA_class,ncol=4)

#i) seleção da combinação de funcao de ligacao e distribuicao teorica utilizando apenas o modelo cheio
l_md <- vector("list", length = 8)
names(l_md) <- c("lb 1|S","lb d|S","pb 1|S","pb d|S","cb 1|S","cb d|S","n 1|S","n d|S")
l_md[[1]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k + (1 | Site),  # erro de convergencia
                   family = "binomial",
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   df_md)
l_md[[2]] <- glmer(cbind(GOF,100-GOF) ~ p.z * d + (d | Site), 
                   family = "binomial",
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   df_md)
l_md[[3]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k + (1 | Site), # erro de convergencia 
                   family = "binomial"(link=probit),
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   df_md)
l_md[[4]] <- glmer(cbind(GOF,100-GOF) ~ p.z * d + (d | Site), 
                   family = "binomial"(link=probit),
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   df_md)
l_md[[5]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k + (1 | Site), # erro de convergencia 
                   family = "binomial"(link=cloglog),
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   data = df_md)
l_md[[6]] <- glmer(cbind(GOF,100-GOF) ~ p.z * d + (d | Site), 
                   family = "binomial"(link=cloglog), 
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   data = df_md)
l_md[[7]] <- lmer(GOF ~ p.z * k + (1 | Site), data = df_md)
l_md[[8]] <- lmer(GOF ~ p.z * d + (d | Site), data = df_md)

# funcao de dispersao = categorica
# l_md <- vector("list", length = 4)
# names(l_md) <- c("lb 1|S","pb 1|S","cb 1|S","n 1|S")
# l_md[[1]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k + (1 | Site), 
#                     family = "binomial",df_md)
# l_md[[2]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k + (1 | Site), 
#                     family = "binomial"(link=probit),df_md)
# l_md[[3]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k + (1 | Site), 
#                     family = "binomial"(link=cloglog), data = df_md)
# l_md[[4]] <- lmer(GOF ~ p.z * k + (1 | Site), data = df_md)

# AICctab(l_md, weights = TRUE)
# sapply(l_md, r.squaredGLMM)
# df_md %>% mutate(p_class = cut(p,20)) %>% 
  # ggplot(aes(x=d,y=GOF,group=Site)) + geom_point() + geom_line() + facet_wrap(~p_class,ncol=4)
```
Como o R2 do modelo cheio estava muito baixo eu resolvi utilizar uma outra distribuição de probabilidade e função de ligação.

__figura 4__ d ~ k, distância média de 

```{r GOF EE selecao, warning=FALSE}
# # i) construção de modelos
l_md <- vector("list",length = 5)
names(l_md) <- c("GOF ~ p * d", "GOF ~ p + d", "GOF ~ p", "GOF ~ d","GOF ~ 1")
l_md[[1]] <- glmer(cbind(GOF,100-GOF) ~ p.z * d + (d | Site), 
                   family = "binomial"(link=probit),
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   df_md)
l_md[[2]] <- glmer(cbind(GOF,100-GOF) ~ p.z + d + (d | Site), 
                   family = "binomial"(link=probit),
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   df_md)
l_md[[3]] <- glmer(cbind(GOF,100-GOF) ~ p.z + (1 | Site), 
                   family = "binomial"(link=probit),
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   df_md)
l_md[[4]] <- glmer(cbind(GOF,100-GOF) ~ d + (d | Site), 
                   family = "binomial"(link=probit),
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   df_md)
l_md[[5]] <- glmer(cbind(GOF,100-GOF) ~ 1 + (1 | Site), 
                   family = "binomial"(link=probit),
                   control = glmerControl(optimizer = "bobyqa",optCtrl = list(maxfun=2e5)),
                   df_md)
# # l_md %<>% llply(.,function(X) update(X,control=glmerControl(optimizer="bobyqa", optCtrl = list(maxfun=2e5)))) 
# 
# # ii) seleção de modelos.
print("tabela de selecao de hipoteses")
AICctab(l_md, weights = TRUE)
# 
# # hipótese selecionada #
# md_GOF <- l_md[[1]]
# # summary(md_GOF)
# # 
print("R2m e R2c")
(r2_GOF <- sapply(l_md, r.squaredGLMM))
print("R2m / R2c")
r2_GOF[1,]/r2_GOF[2,] * 100 %>% round(3)
# # md_GOF %>% fixef() # parâmetros do efeito fixo
# # md_GOF %>% ranef() # parâmetros do efeito aleatório
# 
# ## inner_join com os resultados do modelo ##
# df_md %<>% inner_join(.,augment(md_GOF),by=c("Site","k","GOF","p.z"))
```

__Figura 4__ [EE] Seleção de modelos e R quadrado marginal e condicional da seleção de modelos

Três hipóteses são igualmente plausíveis para descrever os efeitos da porcentagem de cobertura vegetal na paisagem (p) e da distância média de dispersão (d), o maior peso de evidência está para a hipótese que considera apenas o efeito de d, seguindo para a hipótese de interação entre p e d e de soma entre as duas variáveis. Nota-se que as hipóteses fora do intervalo de plausibilidade são aquelas que apresentam R2m < 0.57. O poder de explicação de R2m do modelo considerando apenas o conjunto de dados EE é menor do que o observado para os modelos selecionados para o conjunto de dados  
 

```{r GOF EE 1avaliacao modelo selecionado, echo=FALSE,message=FALSE,include=TRUE}
# gráficos diagnóstico
# l_p <- vector("list",length = 3)
# l_p[[1]] <- ggplot(df_md,aes(x=.fitted,y=.resid))+
#   geom_smooth(se=T,col="red") +
#   geom_point() +
#   ggtitle("gráfico diagnostico") + 
#   labs(x="predito",y="residuo") +
#   facet_wrap(~k,ncol=4)
# l_p[[2]] <- ggplot(df_md,aes(x=p.z,y=.resid)) + 
#   geom_smooth(se=T,col="red") +
#   geom_point() +
#   labs(x="p(z)",y="residuo") +
#   facet_wrap(~k,ncol=4)
# l_p[[3]] <- ggplot(mutate(df_md,p_class = cut(p.z,12)),aes(x=k,y=.resid)) + 
#   geom_boxplot() + 
#   labs(x="k",y="residuo")
#   # geom_smooth(se=F,col="red") +
#   # geom_point() +
#   # facet_wrap(~p_class,ncol=4)
# # grid.arrange(l_p[[1]], l_p[[2]], l_p[[3]],
# #              layout_matrix = rbind(rep(1,4),rep(1,4),
# #                                    rep(2,4),rep(2,4),
# #                                    rep(3,4)) 
# #              )
# l_p[[1]]
```

__Figura 2__- modelo selecionado GOF: resíduos ~ ajustado. A variância não é constante ao longo dos valores fitados e parece que existe uma tendência na nuvem de dados, o que pode indicar que o modelo não conseguiu linearizar os dados.

A regressão dos resíduos contra o predito e as duas variáveis respostas (p e k) mostram que os modelos ajustados não apresentam boa congruência com os dados: a variância não é constante ao longo dos valores fitados para nenhum nível de k; e parece que há uma pequena tendência nos dados, principalmente para o nível 0.25 de k. Outra forma de avaliar a congruência com os dados é plotar o modelo ajustado com o observado:

```{r GOF EE 1exploracao grafica dos resultados - estimativa e intervalo de confianca bootsrap, echo=FALSE,fig.height=7}
## novo conjunto de dados ##
# objetivo: criar todas as combinações entre as preditoras
# df_newdat <- expand.grid(Site = df_md$Site[1],
#                          k = unique(df_md$k),
#                          p.z = seq(min(df_md$p.z)*1.1,max(df_md$p.z)*1.1, length=50)) #no código original é length=50, qual a implicação dessa mudança?
# ## Funçoes a serem calculadas a cada simulação ##
# # Previstos por efeitos fixos e aleatórios
# f1 <- function(.) predict(.,newdata=df_newdat)
# # Previstos por efeitos fixos (argumento re.form=~0)
# f2 <- function(.) predict(.,newdata=df_newdat, re.form=~0)
# ## Os dois bootstraps. Ajuste o argumento ncpus para o numero de cores de seu computador
# b1 <- bootMer(md_GOF, FUN = f1, nsim=1000, parallel="multicore", ncpus=3) #fixos e aleatorios
# b2 <- bootMer(md_GOF, FUN = f2, nsim=1000, parallel="multicore", ncpus=3) #fixos
# ## calcula as médias e intervalos de confiança quantílicos para cada combinação de preditoras
# ## no novo conjunto de dados
# df_newdat$p <- df_newdat$p.z*sd(df_md$p) + mean(df_md$p) #?
# df_newdat$mean <- apply(b1$t,2,mean)
# df_newdat$IC.low <- apply(b1$t,2,quantile, 0.025)
# df_newdat$IC.upp <- apply(b1$t,2,quantile, 0.975)
# df_newdat$mean.fixed <- apply(b2$t,2,mean)
# df_newdat$IC.low.fixed <- apply(b2$t,2,quantile, 0.025)
# df_newdat$IC.upp.fixed <- apply(b2$t,2,quantile, 0.975)
# ## Plots de GOF/100 x cobertura standardizada com intervalos de predição
# df_md %>%
#     ggplot(aes(x=p,y=GOF) ) + 
#     geom_ribbon(aes(y=mean, ymin=IC.low, ymax=IC.upp), data=df_newdat, col="gray", alpha=0.5) +
#     geom_ribbon(aes(y=mean, ymin=IC.low.fixed, ymax=IC.upp.fixed), data=df_newdat, col="gray", alpha=0.5) +
#     geom_line(aes(x=p, y=mean.fixed), data=df_newdat) +
#     geom_point() +
#     ggtitle("GOF ~ p * k + (1|Sitio)") + 
#     facet_wrap(~k,ncol=4)
```

__Figura 3__ GOF: observado e o estimado segundo o modelo mais plausível + intervarlo de confiança 95% bootstrap. Entre linhas brancas o intervalo de confiança considerando apenas os efeitos fixos do modelo, fora dela, na região cinza claro, o intervalo de confiança considerando efeitos fixos e efeitos aleatórios. A inclinação da tendência geral varia em função de k para p: para a proporção de propágulos que permanecem até $l_{cel}$ metros da planta progenitora = 0.99, observamos um efeito negativo de p; com o aumento da proporção de propágulos observamos a atenuação dessa tendência chegando a ser quase nula para proporção ~ 0.50 e invertendo o efeito em 0.25, onde p apresenta efeito positivo. O efeito de p para os resultados de MNEI podem ser negligenciados, além disso é a categoria que apresenta o melhor ajuste do modelo, sendo que para k = 0.25 é onde observa-se maior variância entre os resíduos. 

__EI__

#### m ####
```{r 2selecao de funcao de ligacao e distribuicao teorica, echo=FALSE}
## Dados ##
# df_resultados %>% select(Site, k, p, m, m_) %>% 
  # melt(.,id.vars = c("Site","k","p"))


#i) seleção da combinação de funcao de ligacao e distribuicao teorica utilizando apenas o modelo cheio
```

```{r m}
# i) construção de modelos
# ii) seleção de modelos.
```

```{r 2avaliacao modelo selecionado, echo=FALSE}
# gráficos diagnóstico
```

```{r 2exploracao grafica dos resultados, echo=FALSE}
# plotar os dados completos: x = p, y = VR; 13 paineis o primeiro é 0.99 e o último EI
```

#### $\theta$ ####
```{r 3selecao de funcao de ligacao e distribuicao teorica, echo=FALSE}
#i) seleção da combinação de funcao de ligacao e distribuicao teorica utilizando apenas o modelo cheio
```

```{r theta}
# i) construção de modelos
# ii) seleção de modelos.
```

```{r 3avaliacao modelo selecionado, echo=FALSE}
# gráficos diagnóstico
```

```{r 3exploracao grafica dos resultados, echo=FALSE}
# plotar os dados completos: x = p, y = VR; 13 paineis o primeiro é 0.99 e o último EI
```


__B) Parâmetro com maior significado biológico, uma vez que no equilíbrio U = taxa de extinção de espécies por evento de morte; uma aproximação da probabilidade de extinção de espécies raras na paisagem dado a riqueza observada na área amostrada.__

#### U ####
```{r 4selecao de funcao de ligacao e distribuicao teorica, echo=FALSE}
#i) seleção da combinação de funcao de ligacao e distribuicao teorica utilizando apenas o modelo cheio
```

```{r U}
# i) construção de modelos
# ii) seleção de modelos.
```

```{r 4avaliacao modelo selecionado, echo=FALSE}
# gráficos diagnóstico
```

```{r 4exploracao grafica dos resultados, echo=FALSE}
# plotar os dados completos: x = p, y = VR; 13 paineis o primeiro é 0.99 e o último EI
```



__C) Parâmetros a posteriori__


#### spp_I ####
```{r 5selecao de funcao de ligacao e distribuicao teorica, echo=FALSE}
#i) seleção da combinação de funcao de ligacao e distribuicao teorica utilizando apenas o modelo cheio
```

```{r spp_I}
# i) construção de modelos
# ii) seleção de modelos.
```

```{r 5avaliacao modelo selecionado, echo=FALSE}
# gráficos diagnóstico
```

```{r 5exploracao grafica dos resultados, echo=FALSE}
# plotar os dados completos: x = p, y = VR; 13 paineis o primeiro é 0.99 e o último EI
```


#### GOF ~ spp_I ####
```{r 6selecao de funcao de ligacao e distribuicao teorica, echo=FALSE}
#i) seleção da combinação de funcao de ligacao e distribuicao teorica utilizando apenas o modelo cheio
```

```{r GOF_spp.I}
# i) construção de modelos
# ii) seleção de modelos.
```

```{r 6avaliacao modelo selecionado, echo=FALSE}
# i) summary
# ii) gráficos diagnóstico
```



#########################################################################################################
m de MNEI 
#########################################################################################################

```{r selecao de hipoteses para m, include=FALSE}
# dados #
#df_md <- df_resultados %>% filter(k == "EI") %>% select(SiteCode,k,p,sd_k_,J,DA,m) %>% mutate(l_cel = 100/sqrt(J/DA),d=sd_k_/sqrt(2))

# selecao de dist. prob #
#l_md <- vector("list", length = 4)
#names(l_md) <- c("logit-bin","probit-bin","cloglog - bin","normal")
#l_md[[1]] <- glm(cbind(m,1-m) ~ p * l_cel, 
#                    family = "binomial",df_md)
#l_md[[2]] <- glm(cbind(m,1-m) ~ p * l_cel, 
#                    family = "binomial"(link=probit),df_md)
#l_md[[3]] <- glm(cbind(m,1-m) ~ p * l_cel, 
#                    family = "binomial"(link=cloglog), data = df_md)
#l_md[[4]] <- lm(m ~ p * l_cel, data = df_md)
# AICctab(l_md, weights = TRUE)
## modelo mais plausivel: lm

# selecao de modelos #
#l_md <- vector("list",length = 5)
#names(l_md) <- c("~ p * l", "~ p + l", "~ l", "~ p", "~ 1")
#l_md[[1]] <- lm(m ~ p * l_cel,df_md)
#l_md[[2]] <- lm(m ~ p + l_cel,df_md)
#l_md[[3]] <- lm(m ~ l_cel,df_md)
#l_md[[4]] <- lm(m ~ p,df_md)
#l_md[[5]] <- lm(m ~ 1,df_md)
#AICctab(l_md, weights = TRUE)

#modelo mais plausível
#coef(l_md[[5]])

```

ANEXO:
 apenas os itens 
_Resultados para MNEI_

A) Variável de congruência com o observado e parâmetros livres
-GOF, $\theta$, m ~ p 

B) Parâmetros convertidos
-U', d' ~ p

vi.a) d' ~ m
vi.b) k' ~ d'

C) Parâmetros estimados a posteriori
-spp_I, $S_M'$ ~ p

D) Congruência com o observado e spp input como métrica composto de theta e m
-GOF ~ spp_I

_Resultados para MNEE_ 
k <- factor( as.character( c(0.99,seq(0.95,0.50,by=-0.05),0.25) ) ) - a proporção de propágulos até a área imediata da planta progenitora ($l_{cel}$ metros da copa da árvore progenitora)

A) Variável de congruência com o observado e parâmetro livre 
-GOF, U ~ p * k + (1|Site)
        ~ p * d + (d|Site)
     
B) Parâmetros convertidos     
-m' ~ p * k + (1|Site)
    ~ p * d + (d|Site)

iv)$\theta'$ ~ p * k + (1|Site)
     ~ p * d + (d|Site)

C) Parâmetros estimados a posteriori
-spp_I' ~ p * k + (1|Site)
        ~ p * d + (d|Site)

vi)$S_M$ ~ p * k + (1|Site)
         ~ p * d + (d|Site)

-GOF ~ spp_I' * k + (1|Site)
     ~ spp_I' * d + (d|Site)
-->


### John Fox A R companion to applied regression ###

ii) visualização gráfica

"
For two- (and higher-) way tables, however, the design principles of perception, detection, and comparison imply that we should try to show the observed frequencies in the cells in relation to what we would expect those frequencies to be under a reasonable null model — for example, the hypothesis that the row and column variables are unassociated.

To this end, several schemes for representing contingency tables graphically are based on the fact that when the row and column variables are independent, the estimated expected frequencies, m ij , are products of the row and column totals (divided by the grand total): m ij = n i + n + j =n ++ . Then, each cell can be represented by a rectangle whose area shows the cell frequency, n ij , or the deviation from independence.
"

