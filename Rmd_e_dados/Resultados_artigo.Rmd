---
title: "Resultados - artigo"
author: "Mori, Danilo Pereira"
date: "21 de maio de 2018"
output: html_document
---

```{r setup, include=FALSE} 
knitr::opts_chunk$set(echo = FALSE, tidy = TRUE, include = TRUE, warning = FALSE,cache = TRUE,message = FALSE)
```

```{r dados e pacotes,warning=FALSE,message=FALSE,echo=FALSE}
library(reshape2)
library(MASS)
library(arm)
library(gridExtra)
library(MuMIn)
library(doMC)
library(bbmle)
library(lme4)
library(merTools)
library(ggplot2)
library(broom) 
library(magrittr)
library(DHARMa)
library(tidyr)
library(purrr)
library(plyr)
library(dplyr)
```

```{r organização dos dados,warning=FALSE,message=FALSE}
df_resultados <- readr::read_csv("/home/danilo/Documentos/Doutorado/artigo_mestrado/Rmd_e_dados/df_resultados.csv")
# df_resultados %>% str
df_resultados$MN <- factor(df_resultados$MN,levels = c("EI","EE"))
df_resultados$SiteCode <- factor(df_resultados$SiteCode)
df_resultados$k <- factor(df_resultados$k,levels=unique(df_resultados$k))
# df_resultados$k %>% contrasts()
# df_resultados$MN %>% contrasts()

#### z score ###

f_z <- function(x){
  m <- base::mean(x,na.rm=TRUE)
  sd <- sd(x,na.rm=TRUE)
  output <- (x-m)/sd
  return(output)
} 

df_resultados %<>% mutate(GOF.z = f_z(GOF),
                          DA.z = f_z(DA),
                          p.z = f_z(p),
                          S.z = f_z(S),
                          U.z = f_z(U),
                          m_.z = f_z(m_),
                          I.z = f_z(I),
                          d.z = f_z(d),
                          J.z = f_z(J),
                          k.z0 = as.numeric(as.character(k)),
                          k.z = f_z(k.z0))

names(df_resultados)[1] <- "Site"
```

#################################################################################
######################### código ajuda artigo ###################################
#################################################################################

## 1a parte descrição dos levantamentos fito

```{r figura 1, fig.width=8, fig.height=5, fig.align="center"}
df_plot <- df_resultados %>% filter(k=="0.99" & MN=="EE") %>% dplyr::select(Site, p, S,p.z,S.z) %>% unique

# avaliando as curvas pelo quantiles
df_plot %<>% mutate(terceiro_quantil = ifelse(p>quantile(df_plot$p,probs=0.75),">_3oQ","<_3oQ")) 

l_p <- vector("list",6)
l_p[[1]] <- ggplot(df_plot, aes(x=p)) +
  geom_histogram(bins=30) +
  geom_vline(xintercept = c(quantile(df_plot$p,probs = c(0.25,0.50,0.75))),color="red")
  # geom_density()
l_p[[2]] <- ggplot(df_plot, aes(x=p.z)) +
  geom_histogram(bins=30) +
  geom_vline(xintercept = c(quantile(df_plot$p.z,probs = c(0.25,0.50,0.75))),color="red")
  # geom_density()
l_p[[3]] <- ggplot(df_plot, aes(x=S)) +
  geom_histogram(bins=30) +
  geom_vline(xintercept = quantile(df_plot$S,probs = c(0.25,0.50,0.75)),color="red")
l_p[[4]] <- ggplot(df_plot, aes(x=S.z)) +
  geom_histogram(bins=30) +
  geom_vline(xintercept = c(quantile(df_plot$S.z,probs = c(0.25,0.50,0.75))),color="red")
l_p[[5]] <- ggplot(df_plot, aes(x=p,y=S)) +
  geom_hline(yintercept = quantile(df_plot$S,probs = c(0.25,0.50,0.75)),color="red") +
  geom_vline(xintercept = quantile(df_plot$p,probs = c(0.25,0.50,0.75)),color="red") +
  geom_point() + 
  geom_smooth()
l_p[[6]] <- ggplot(df_plot, aes(x=p.z,y=S.z)) +
  geom_hline(yintercept = quantile(df_plot$S.z,probs = c(0.25,0.50,0.75)),color="red") +
  geom_vline(xintercept = quantile(df_plot$p.z,probs = c(0.25,0.50,0.75)),color="red") +
  geom_point() + 
  geom_smooth()
# do.call("grid.arrange",c(l_p,ncol=3))
grid.arrange(l_p[[1]],l_p[[2]],l_p[[3]],l_p[[4]],l_p[[5]],l_p[[6]],
             layout_matrix = rbind(c(1,1,3,3,5,5),
                                   c(2,2,4,4,6,6) )
             )

```

Figura 1. Apêndice 1- Análise Estatística completa. Na primeira linha há as variáveis na escala padrão; na segunda linha as variáveis após transformação Z (centra a média em zero e desloca a variação para o centro da distribuição REVISÃO). As linhas em vermelho equivalem ao quantil de 0.25%, 0.50% e 0.75% da amostra.

  A cobertura vegetal mínima é de 0.0074, o quantil de 25% é de 0.2916, a média é 0.6727 e o quantil de 75% é de 0.9216 (figura 1). A riqueza observada variou de 26 até 230, o quantil de 25% é de 73.75, a média é 105.85, e o quantil de 75% é 134. Há um vies na amostra que apresenta mais trabalhos em paisagens com alta cobertura vegetal do que em baixas, por exemplo, o primeiro 1/4 da amostra está entre 0.00 e 0.30, enquanto o último 1/4 está comprimido entre 0.92 e 1 (figura 1). A riqueza observada apresenta um outro padrão com uma tendência central e uma assimetria para a esquerda [REVISAR]: 50% da amostra está entre 73 e 134 com média próxima de 100; o primeiro 1/4 da amostra está entre 26 e 73 enquanto o último 1/4 varia entre 134 e 230, o range do 1o quarto equivalente à metade do range do último quarto da amostra. Há certa covariação entre p e S: o último quarto de p está acima de 

```{r}

```










##################################################################################


## 2) GOF - número de SADs preditas que não foram refutadas ##

a) avaliar qual a melhor distribuição de probabilidade
b) avaliar função de ligação
c) seleção de modelos
d) avaliação do modelo selecionado
e) estudo das estimativas e interpretação

- a combinação entre distribuição de probabilidade e função de ligação canonica para porcentagem é a distribuição binomial com a função de ligação logito
-> exploração gráfica

__EFEITOS FIXOS__

```{r GOF exp graf funcao de ligacao logito}
## remoção de 0 e 100 ##
df_ad <- df_resultados
df_ad$GOF[df_ad$GOF==0] <- 0.01
df_ad$GOF[df_ad$GOF==100] <- 99.99
## transformação logito ##
df_ad %<>% mutate(lGOF = log((GOF/100)/(1-(GOF/100)) ))
# df_ad$lGOF %>% summary
## gráfico ##
print(
    ggplot(df_ad,aes(x=p,y=lGOF,color=MN)) +
      geom_point() +
      geom_smooth(method = "lm",se=FALSE) +
      facet_wrap(~k,ncol=3) +
      labs(title="~ p * k * MN") +
      scale_colour_manual(values = c("Blue", "Red"))
)
```

__Figura 1__ logito de GOF ~ p * k * MN 

- para o cenário com menor limitação à dispersão (k=0.25) parece que a linearização de GOF para o modelo EI não é uma boa aproximação, provavelmente o padrão de resíduos não vai ser muito 'comportado'

__EFEITOS ALEATÓRIOS__

- 1|Site

```{r GOF graf exp 2 logito pela estrutura aleatoria1,fig.height=8,fig.width=8}
df_ad %>% mutate(p.class = cut(p,12)) %>% ggplot(aes(x=Site,y=lGOF)) +
  geom_jitter() +
  geom_boxplot() +
  coord_flip() +
  theme(axis.text.y = element_blank(),axis.ticks = element_blank(), legend.position="bottom") +
  facet_wrap(~p.class,ncol=3,scales="free_y")
```

__Figura 2.1__ logito de GOF ~ site (~p.class)

- MN|Site

```{r GOF graf exp 2 logito pela estrutura aleatoria 2,fig.height=8,fig.width=8}
mutate(df_ad,p.class = cut(p,12)) %>% ggplot(aes(x=Site,y=lGOF,color=MN)) +
  geom_jitter() +
  geom_boxplot() +
  coord_flip() +
  theme(axis.text.y = element_blank(),axis.ticks = element_blank(), legend.position="bottom") +
  facet_wrap(~p.class,ncol=3,scales="free_y")
```

__Figura 2.1__ logito de GOF ~ MN * Site (~p.class)

- como efeito aleatório vamos considerar um intercepto por observações agrupadas por Sítio de amostragem (Site)

__Escolha da estrutura aleatória__

- o modelo cheio vai apresentar interação entre as três variáveis: p + k + MN + p:k + p:MN + MN:k + p:k:MN
- vou avaliar duas possíveis estruturas aleatórias: 1 | Site e MN | Site
- obtive erro de convergência: Model failed to converge with max|grad| = 0.00126561 (tol = 0.001, component 1)
- ao acrescentar " control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)) " não obtive mais erro de convergência


```{r GOF escolha estrutura aleatoria}
l_md <- vector("list",2)
names(l_md) <- c("1|Site","MN|Site")
l_md[[1]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (1|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[2]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
AICctab(l_md,weights=T)
```

- a estrutura aleatória que considera que há um intercepto para cada modelo neutro por sítio de amostragem é aquela mais plausível
- alternativamente poderiamos considerar k | Site, contudo seria estimado 1 intercepto para cada duas observações. 1|Site corresponde ao ajustar 1 intercepto para cada 24 observações e MN para cada 12. Na prática a diferença entre 1|Site e MN|Site é de dois parâmetros.
- vou ajusta-lo e seguir o protocolo de avaliação de Bolker et al. (2008)
1) Checagem gráfica: 
i) variância dos dados é homogêneo entre as catergórias? Considerando os efeitos fixos, a variância parece ser homogênea para todos os casos menos quando consideramos o modelo EI, k=0.25 para todo o p
ii) a resposta é linear com relação ao preditor contínuo? Para a classe citada acima os dados particulamente não se adequam à uma linha com relação à p
iii) A distribuição de valores dentro do grupos corresponde à distribuição de probabilidade escolhida? Diria que a resposta é: corresponde suficientemente à distribuição escolhida? Para responder isso vou avaliar os resíduos do modelo escolhido

__Diagnóstico do modelo cheio selecionado__

Reunião 11 de outubro de 2018:

PI recomendou utilizar resíduos quantílicos para diagnosticar o modelo cheio. O pacote DHARMa oferece a possibilidade de utilizar esse recurso

```{r GOF diag1}
residuos_GOF <- simulateResiduals(fittedModel = l_md[[2]], n = 1000)
plot(residuos_GOF)
```

__Figura 3.1__ Resíduos quantílicos: 1o gráfico qq-plot e teste de aderência dos resíduos com o esperado segundo uniformidade com a distribuição teórica (teste de Kolmogorov-Smirnov); 2o gráfico resíduos contro o previsto, linhas são da regressão quantílica (0.25, 0.50, 0.75) 

- o teste de uniformidade mostra que desvio é significativo apontando para o modelo não prediz corretamente as observações
- o gráfico dos resíduos conra os valores previstos indica que a variação não está igualmente distribuida (como se pode ver pelas regressões quantílicas)

```{r GOF diag2,fig.width=10,fig.height=4}
df_reg <- df_resultados %>% mutate(GOF_q.resid = residuos_GOF$scaledResiduals)
l_p <- vector("list",3)
l_p[[1]] <- ggplot(df_reg,aes(x=p.z,y=GOF_q.resid)) +
  geom_point() +
  geom_smooth(method="loess") +
  labs(y="residuos")
l_p[[2]] <- ggplot(df_reg,aes(x=MN,y=GOF_q.resid)) +
  geom_jitter() +
  geom_boxplot() +
  labs(y="")
l_p[[3]] <- ggplot(df_reg,aes(x=k,y=GOF_q.resid)) +
  geom_jitter() +
  geom_boxplot() +
  labs(y="")
do.call("grid.arrange",c(l_p,ncol=3))
# grid.arrange(l_p[[1]],l_p[[2]],l_p[[3]],l_p[[4]],
#              layout_matrix=rbind(c(1,2,3),
#                                  rep(4,3),
#                                  rep(4,3) )
#              )
```

__Figura 3.2__ resíduos contra as variáveis preditoras

```{r GOF diag3}
ggplot(df_reg,aes(x=p.z,y=GOF_q.resid,color=MN)) +
  geom_point() +
  geom_smooth(method="loess") +
  labs(y="residuos") +
  theme(legend.position = "bottom") +
  facet_wrap(~k,ncol=4)
```

__Figura 3.3__ resíduos contra as variáveis preditoras p * MN * k

```{r GOF diag4}
ggplot(df_reg,aes(x=MN,y=GOF_q.resid)) +
  geom_jitter() +
  geom_boxplot() +
  labs(y="residuos") +
  facet_wrap(~k,ncol=4)
```

__Figura 3.4__ resíduos contra as variáveis preditoras MN * k

- uma vez que o modelo cheio não apresentou bom ajuste com os valores observados, então irei explorar alternativas. Primeiramente irei explorar outras funções de ligação e em seguida buscar outras distribuições teóricas

__Seleção do modelo cheio 2: logit, probit e cloglog__

```{r GOF escolha estrutura aleatoria}
l_md <- vector("list",6)
names(l_md) <- c("l 1|Site","l MN|Site", 
                 "p 1|Site","p MN|Site", 
                 "c 1|Site","c MN|Site")
l_md[[1]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (1|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[2]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[3]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (1|Site), family = "binomial"(link = probit),data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[4]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (MN|Site), family = "binomial"(link = probit),data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[5]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (1|Site), family = "binomial"(link = cloglog),data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[6]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (MN|Site), family = "binomial"(link = cloglog),data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
AICctab(l_md,weights=T)
```

o modelo com a função de ligação cloglog foi o único modelo plausível. O diagnóstico do modelo:

```{r diag GOF cloglog1}
l_residuos <- llply(l_md[c(2,4,6)],function(x) (simulateResiduals(fittedModel = x, n=1000)))
plot(l_residuos[[3]])
```

__Figura 3.5__ Resíduos quantílicos do modelo binomial mais plausível (cloglog)

Os resíduos quantílicos não apresentam boa aderência ao padrão de uniformidade como mostra o teste KS que aponta que o desvio é significante. Para comparação vou plotar os gráficos dos testes de uniformidade para os três modelos binomiais:

```{r GOF diag uniformidade tres binom}
par(mfrow=c(3,1))
l_ply(l_residuos,function(x) plotQQunif(x))
```

__Figura 3.6__

### Comentário sobre GOF ###

  Apesar dos resíduos quantílicos de GOF apresentarem desvio significativo da uniformidade, devido a inflação de zeros, iremos prosseguir com o modelo logito para avaliar os resultados. Concomitantemente iremos investigar como lidar com a infação de zeros, mas quero preparar o script para analisar os dados.
  
__Seleção do modelo mais plausível__
<!--
Hipóteses a priori:

I) a SAD não é suficiente para refutar neutralidade.
I.P) portanto, qualquer modelo neutro apresenta boa congruência com o observado independentemente se a SAD observada foi amostrada em contexto ecológio onde o pressuposto de neutralidade não é uma boa aproximação e assim para todo gradiente de cobertura vegetal.

II) nenhum modelo neutro é suficiente para explicar a SAD observada em um gradiente natural de cobertura vegetal.
II.P) portanto quanto maior a cobertura vegetal melhor a congruência do observado e predito por um modelo neutro.

III) a estrutura espacial da paisagem é necessária para descrever a SAD. 
III.P) portanto o modelo neutro de espaço explícito (EE) apresenta melhor congruência com o observado do que o modelo neutro de espaço implícito (EI).

IV) um modelo neutro é suficiente para descrever a SAD se corretamente aproximar o processo de limitação à dispersão
IV.P.a) portanto, existe um valor ótimo de limitação à dispersão onde observamos a maior congruência com o observado
IV.P.b) portanto, se a fragmentação da paisagem modificar a limitação à dispersão 

-->

```{r GOF selecao de modelos}
l_md <- vector("list",19)
names(l_md) <- c("p*k*MN",# modelo cheio
                 "p*k*MN-p:k:MN", #MC - 3a ordem
                 "p*(k+MN)","k*(p+MN)","MN*(p+k)", #2 interações
                 "p*k+MN","p*MN+k","k*MN+p", #1 interação + preditor
                 "p*k","p*MN","k*MN", #1 interação
                 "p+k+MN",#aditivo 3
                 "p+k","p+MN","k+MN", #aditivo 2 
                 "p","k","MN", #preditor isolado
                 "1") #nulo
#modelo cheio
l_md[[1]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
#modelo cheio - interação 3a ordem
l_md[[2]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN - p.z:k:MN + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
#2 interações
l_md[[3]] <- glmer(cbind(GOF,100-GOF) ~ p.z * (k + MN) + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[4]] <- glmer(cbind(GOF,100-GOF) ~ k * (p.z + MN) + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[5]] <- glmer(cbind(GOF,100-GOF) ~ MN * (p.z + k) + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
#1 interação + preditor
l_md[[6]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k + MN + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[7]] <- glmer(cbind(GOF,100-GOF) ~ p.z * MN + k + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[8]] <- glmer(cbind(GOF,100-GOF) ~ k * MN + p.z + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
#1 interação
l_md[[9]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k + (1|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[10]] <- glmer(cbind(GOF,100-GOF) ~ p.z * MN + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[11]] <- glmer(cbind(GOF,100-GOF) ~ k * MN + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
#aditivo 3
l_md[[12]] <- glmer(cbind(GOF,100-GOF) ~ p.z + k + MN + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
#aditivo 2
l_md[[13]] <- glmer(cbind(GOF,100-GOF) ~ p.z + k + (1|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[14]] <- glmer(cbind(GOF,100-GOF) ~ p.z + MN + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[15]] <- glmer(cbind(GOF,100-GOF) ~ k + MN + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
#aditivo 1
l_md[[16]] <- glmer(cbind(GOF,100-GOF) ~ p.z + (1|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[17]] <- glmer(cbind(GOF,100-GOF) ~ k + (1|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[18]] <- glmer(cbind(GOF,100-GOF) ~ MN + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
# nulo
l_md[[19]] <- glmer(cbind(GOF,100-GOF) ~ 1 + (1|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
AICctab(l_md,weights=T)
```

O modelos cheio foi o único modelo plausível somando peso de evidência próximo de 1.

### roteiro merTools ###

-Sumário do modelo:

```{r md_GOF sumario}
md_GOF <- l_md[[1]]
fastdisp(md_GOF)
```

Pontos para avaliação:

i) o erro padrão das estimativas dos coef está baixa com relação a seus valores (quais seriam valores altos?);
ii) o desvio padrão estimado para a estrutura aleatória indica que existe grande variância dentro das categórias (PESQUISAR MELHOR ESSA QUESTÃO)
iii) a correlação intra estrutura aleatória é baixa (pesquisar segundo ponto)

- gráficos dos coeficientes com os erros padrão

PESQUISAR: confint.merMod

"An alternative is to simulate values of the fixed effects from the posterior using the function arm::sim. Our next tool, FEsim, is a convenience wrapper to do this and provide an informative data frame of the results."

```{r md_GOF simulate values fixed effects}
# simulacao
fe_GOF <- FEsim(md_GOF,n.sims = 1000)
# fe_GOF
# grafico
plotFEsim(fe_GOF,stat = "mean") + theme_bw() + labs(y="taxa de GOF",x="média do efeito estimado")
```

__Figura 4__ Mediana dos efeitos estimados pelo modelo mais plausível (modelo logito)

Futuras avaliações:

i) pesquisar a função
ii) no y ("taxa de GOF") está a inclinação na escala logito? 
iii) em x está a mediana de cada coef?

- avaliação dos efeitos aleatórios

"The result is a dataframe with estimates of the values of each of the random effects provided by the arm::sim() function. groupID represents the identfiable level for the variable for one random effect, term represents whether the simulated values are for an intercept or which slope, and groupFctr identifies which of the (1|x) terms the values represent"
"To make unique identifiers for each term, we need to use both the groupID and the groupFctr term in case these two variables use overlapping label names for their groups."


```{r md_GOF simulate values random effects}
# simulacao
re_GOF <- REsim(md_GOF,n.sims = 1000)
# re_GOF

# grafico
plotREsim(re_GOF,stat = "mean")
```


__Predição e Observado na escala logito__

```{r GOF predicao IC e observado na escala logito}
## novo conjunto de dados: todas as combinações entre as preditoras ##
df_new.data <- expand.grid(Site = df_resultados$Site[1],
                           p.z = seq(min(df_resultados$p.z)*1.1,max(df_resultados$p.z)*1.1, length=length(unique(df_ad$p))),
                           k = unique(df_resultados$k),
                           MN = unique(df_resultados$MN))
## predicao merTools ##
df_new.data <- cbind(df_new.data,
                     predictInterval(md_GOF,newdata = df_new.data,level=0.95,n.sims = 1000,stat = "mean"))
# add de p na escala padrão #
df_new.data$p <- df_new.data$p.z*sd(df_ad$p) + mean(df_ad$p)
# transformando a predicao para escala da observacao #
# df_new.data %<>% mutate(media = ( 1 / ( 1+exp(-fit) )), upr_media =  (1/(1+exp(-upr))), lwr_media =  (1/(1+exp(-lwr))))

## remoção de 0 e 100 ##
df_ad <- df_resultados
df_ad$GOF[df_ad$GOF==0] <- 100/(1+exp(-min(df_new.data$lwr)))
df_ad$GOF[df_ad$GOF==100] <- 100/(1+exp(-max(df_new.data$upr)))
## transformação logito ##
df_ad %<>% mutate(lGOF = log( (GOF/100) / ( 1 - (GOF/100) ) ))


## Gráfico ##
ggplot(data=df_new.data,aes(x=p,y=lGOF,color=MN)) + 
  geom_point(data=df_ad,aes(color=MN)) +
  geom_ribbon(aes(y = fit, ymin=lwr, ymax=upr,color=MN,fill=MN), alpha=0.5) +
  geom_line(aes(x=p, y=fit,color=MN)) +
  facet_wrap(~k,ncol=3) +
  scale_colour_manual(values = c("Blue", "Red")) + 
  scale_fill_manual(values = c("Blue", "Red")) +
  theme(legend.position = "bottom")
```

__Figura 14__ Logito de GOF (lGOF) e propoção de cobertura vegetal (p), por proporção de propágulos que permanece até a planta (k, o título dos quadros) e colorido pela classe de modelo neutro (MN: EI - modelo neutro de espaço implícito; EE - modelo neutro de espaço explícito). A linha central representa a média estimado e a área colorida representa o intervalo de confiança de 95%. 

-> Reunião 25 outubro 2018

- o gráfico de observado e predito com intervalo de confiança mostra que a estimativa do modelo não está sendo suficiente para 

```{r md_GOF estruturas aleatorias alternativas}
l_md <- vector("list",21)
names(l_md) <- c("l k.f 1|Site","l k.f MN|Site", "l k.z 1|Site", "l k.z MN|Site", "l k.z k.z|Site", "l k.z MN + k.z|Site", "l k.z MN * k.z|Site",
                 "p k.f 1|Site","p k.f MN|Site", "p k.z 1|Site", "p k.z MN|Site", "p k.z k.z|Site", "p k.z MN + k.z|Site", "p k.z MN * k.z|Site",
                 "c k.f 1|Site","c k.f MN|Site", "c k.z 1|Site", "c k.z MN|Site", "c k.z k.z|Site", "c k.z MN + k.z|Site", "c k.z MN * k.z|Site")
# logito #
l_md[[1]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (1|Site), family = "binomial",data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[2]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (MN|Site), family = "binomial",data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[3]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k.z * MN + (1|Site), family = "binomial",data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[4]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k.z * MN + (MN|Site), family = "binomial",data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[5]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k.z * MN + (k.z|Site), family = "binomial",data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[6]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k.z * MN + (MN+k.z|Site), family = "binomial",data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[7]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k.z * MN + (MN*k.z|Site), family = "binomial",data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
# probito #
l_md[[8]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (1|Site), family = "binomial"(link = probit),data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[9]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (MN|Site), family = "binomial"(link = probit),data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[10]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k.z * MN + (1|Site), family = "binomial"(link = probit),data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[11]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k.z * MN + (MN|Site), family = "binomial"(link = probit),data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[12]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k.z * MN + (k.z|Site), family = "binomial"(link = probit),data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[13]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k.z * MN + (MN+k.z|Site), family = "binomial"(link = probit),data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[14]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k.z * MN + (MN*k.z|Site), family = "binomial"(link = probit),data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
# # cloglog #
l_md[[15]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (1|Site), family = "binomial"(link = cloglog),data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[16]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (MN|Site), family = "binomial"(link = cloglog),data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[17]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k.z * MN + (1|Site), family = "binomial"(link = cloglog),data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[18]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k.z * MN + (MN|Site), family = "binomial"(link = cloglog),data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[19]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k.z * MN + (k.z|Site), family = "binomial"(link = cloglog),data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[20]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k.z * MN + (MN+k.z|Site), family = "binomial"(link = cloglog),data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[21]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k.z * MN + (MN*k.z|Site), family = "binomial"(link = cloglog),data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
AICctab(l_md,weights=T)
```

- o único modelo plausível é aquele que considera k como um fator, MN|Site como estrutura aleatória e cloglog como função de ligação. Abaixo deste há a mesma estrutura mas com as funções de ligação probito e logito, respectivamente, contudo, fora do intervalo de plausibilidade. O quarto modelo mais plausível é aquele que considera k como variável contínua e a estrutura aleatória MN * k.z|Site. 

- como o objetivo é avaliar se algumas dessas opções apresenta uma melhora significativa no padrão de resíduos e capacidade de explicar a variação presente nos dados vou comparar esses 4 primeiros modelos, mesmo apenas o primeiro sendo plausível, utilizando os resíduos quantílicos e o R2

__cloglog k como categórica e MN|Site__

```{r cloglog k MN|Site diag}
residuos_cloglog <- simulateResiduals(fittedModel = l_md[[16]], n = 1000)
plot(residuos_cloglog)
```

__Figura 15.1__ Resíduos quantílicos GOF ~ modelo cheio[cloglog, k.f, MN|Site]

```{r R2 cloglog k.f MN|Site}
r.squaredGLMM(l_md[[16]])
```


__probit k como categórica e MN|Site__

```{r probit k MN|Site diag}
residuos_probit <- simulateResiduals(fittedModel = l_md[[9]], n = 1000)
plot(residuos_probit)
```

__Figura 15.2__ Resíduos quantílicos GOF ~ modelo cheio[cloglog, k.f, MN|Site]

```{r R2 probit k.f MN|Site}
r.squaredGLMM(l_md[[9]])
```


__logit k como categórica e MN|Site__

```{r cloglog k MN|Site diag}
residuos_logit <- simulateResiduals(fittedModel = l_md[[2]], n = 1000)
plot(residuos_logit)
```

__Figura 15.1__ Resíduos quantílicos GOF ~ modelo cheio[cloglog, k.f, MN|Site]

```{r R2 logit k.f MN|Site}
r.squaredGLMM(l_md[[2]])
```


__logit k como categórica e MN|Site__

```{r logit k.z MN*k.z|Site diag}
residuos_logit.k <- simulateResiduals(fittedModel = l_md[[7]], n = 1000)
plot(residuos_logit.k)
```

```{r R2 logit k.z MN*k.z|Site}
r.squaredGLMM(l_md[[7]])
```

A distribuição dos resíduos quantílicos de todos os modelos apresenta desvio significativo da uniformidade. O modelo com MN*k.z|Site e função de ligação logito apresenta uma pequena melhora na aderência dos resíduos à uniformidade, contudo, há uma piora considerável na variância explicada pela estrutura fixa do modelo em comparação com o modelo logito com k enquanto variável categórica e MN|Site. Além disso a regressão quantílica para o modelo logito MN:k.z|Site diverge mais do esperado do que o outro modelo logito MN|Site.

Os modelos com função de ligação logito são aqueles que melhor descrevem a variação dos dados (maior R2c), apesar do modelo cloglog ser o mais plausível. Como o intervalo de confiança da predição é uma qualidade importante do modelo que utilizaremos para analisar os dados vou comparar o modelo mais plausível (cloglog) com o melhor modelo logito, o modelo logito é de interesse por conta da sua facilidade de interpretação. Como a construção de intervalo de confiança utilizando bootMer é muito longo, irei utilizar o pacote merTools para uma primeira comparação entre os dois; entretanto, pelo R2 podemos esperar que a predição do modelo logito englobe a maior parte da variação dos dados.

__Comparação intervalo de predição: cloglog e logit__

```{r comparacao cloglog logit predito IC,fig.height=10}
## novo conjunto de dados: todas as combinações entre as preditoras ##
df_new.data <- expand.grid(Site = df_resultados$Site[1],
                           p.z = seq(min(df_resultados$p.z)*1.1,max(df_resultados$p.z)*1.1, length=length(unique(df_resultados$p))),
                           k = unique(df_resultados$k),
                           MN = unique(df_resultados$MN))

### Logit ###
## predicao merTools ##
df_nd.logit <- cbind(df_new.data,
                     predictInterval(l_md[[2]],newdata = df_new.data,level=0.95,n.sims = 1000,stat = "mean"))
# add de p na escala padrão #
df_nd.logit$p <- df_new.data$p.z*sd(df_resultados$p) + mean(df_resultados$p)

## remoção de 0 e 100 ##
df_logit <- df_resultados
df_logit$GOF[df_logit$GOF==0] <- 100/(1+exp(-min(df_nd.logit$lwr)))
df_logit$GOF[df_logit$GOF==100] <- 100/(1+exp(-max(df_nd.logit$upr)))
## transformação logito ##
df_logit %<>% mutate(lGOF = log( (GOF/100) / ( 1 - (GOF/100) ) ))

## Gráfico ##
l_p <- vector("list",2)
l_p[[1]] <- ggplot(data=df_nd.logit,aes(x=p,y=lGOF)) + 
  geom_point(data=df_logit) +
  geom_ribbon(aes(y = fit, ymin=lwr, ymax=upr), alpha=0.5) +
  geom_line(aes(x=p, y=fit)) +
  labs(title="logit") +
  facet_grid(k~MN)

### clogclog ###
## predicao merTools ##
df_nd.cloglog <- cbind(df_new.data,
                       predictInterval(l_md[[16]],newdata = df_new.data,level=0.95,n.sims = 1000,stat = "mean"))
# add de p na escala padrão #
df_nd.cloglog$p <- df_new.data$p.z*sd(df_resultados$p) + mean(df_resultados$p)

## remoção de 0 e 100 ##
df_cloglog <- df_resultados
df_cloglog$GOF[df_cloglog$GOF==0] <- 1-exp(-exp(min(df_nd.cloglog$lwr)))
df_cloglog$GOF[df_cloglog$GOF==100] <- 1-exp(-exp(max(df_nd.cloglog$upr)))
## transformação logito ##
df_cloglog %<>% mutate(cGOF = log(-log(100-GOF)))

## Gráfico ##
l_p[[2]] <- ggplot(data=df_nd.cloglog,aes(x=p,y=cGOF)) + 
  geom_point(data=df_cloglog) +
  geom_ribbon(aes(y = fit, ymin=lwr, ymax=upr), alpha=0.5) +
  geom_line(aes(x=p, y=fit)) +
  labs(title="cloglog") +
  facet_grid(k~MN)

### comparacao ###
do.call("grid.arrange",c(l_p,ncol=2))
```

- problemas em plotar na escala cloglog
- vou deixar rodando o bootMer

```{r IC bootMer logit GOF,fig.height=10,fig.width=5}
md_GOF <- l_md[[2]]
## novo conjunto de dados: todas as combinações entre as preditoras ##
df_new.data <- expand.grid(Site = df_resultados$Site[1],
                           p.z = seq(min(df_resultados$p.z)*1.1,max(df_resultados$p.z)*1.1, length=length(unique(df_resultados$p))),
                           k = unique(df_resultados$k),
                           MN = unique(df_resultados$MN))
# previsto considerando a estrutura fixa e aleatória #
f1 <- function(.) predict(.,newdata=df_new.data)
# previsto considerando a estrutura fixa #
f2 <- function(.) predict(.,newdata=df_new.data, re.form=~0)
## Os dois bootstraps. Ajuste o argumento ncpus para o numero de cores de seu computador
# b1 <- bootMer(md_GOF, FUN = f1, nsim=1000, parallel="multicore", ncpus=4)
# b2 <- bootMer(md_GOF, FUN = f2, nsim=1000, parallel="multicore", ncpus=4)
# save(b1,b2,file="/home/danilo/Documentos/Doutorado/artigo_mestrado/Rmd_e_dados/bootMer_md-logit-GOF.Rdata")
load(file = "/home/danilo/Documentos/Doutorado/artigo_mestrado/Rmd_e_dados/bootMer_md-logit-GOF.Rdata")
# preparacao dos dados
df_new.data$p <- df_new.data$p.z*sd(df_resultados$p) + mean(df_resultados$p) 
df_new.data$mean <- apply(b1$t,2,mean)
df_new.data$IC.low <- apply(b1$t,2,quantile, 0.025)
df_new.data$IC.upp <- apply(b1$t,2,quantile, 0.975)
df_new.data$mean.fixed <- apply(b2$t,2,mean)
df_new.data$IC.low.fixed <- apply(b2$t,2,quantile, 0.025)
df_new.data$IC.upp.fixed <- apply(b2$t,2,quantile, 0.975)
## Modificação dos dados
df_ad <- df_resultados
df_ad$GOF[df_ad$GOF==0] <- 100/(1+exp(-min(df_new.data$IC.low)))
df_ad$GOF[df_ad$GOF==100] <- 100/(1+exp(-max(df_new.data$IC.upp)))
## transformação logito ##
df_ad %<>% mutate(lGOF = log( (GOF/100) / ( 1 - (GOF/100) ) ))

df_ad %>%
    ggplot(aes(x=p,y=lGOF) ) + 
    geom_ribbon(aes(y=mean, ymin=IC.low, ymax=IC.upp), data=df_new.data, col="gray", alpha=0.5) +
    geom_ribbon(aes(y=mean, ymin=IC.low.fixed, ymax=IC.upp.fixed), data=df_new.data, col="gray", alpha=0.5) +
    geom_line(aes(x=p, y=mean.fixed), data=df_new.data) +
    geom_point() +
    facet_grid(k~MN)
```

__Figura 16__ observado e predito na escala da função de ligação 

```{r md_GOF predito e observado,fig.width=10}
# coisas a fazer: otimizar o copia e cola aqui #

# novos dados 
df_new.data <- expand.grid(Site = df_resultados$Site[1],
                           p.z = seq(min(df_resultados$p.z)*1.1,max(df_resultados$p.z)*1.1, length=length(unique(df_resultados$p))),
                           k = unique(df_resultados$k),
                           MN = unique(df_resultados$MN))
# bootMer
load(file = "/home/danilo/Documentos/Doutorado/artigo_mestrado/Rmd_e_dados/bootMer_md-logit-GOF.Rdata")
df_new.data1 <- df_new.data
df_new.data1$p <- df_new.data1$p.z*sd(df_resultados$p) + mean(df_resultados$p) 
# logit
# df_new.data1$mean <- apply(b1$t,2,mean)
# df_new.data1$IC.low <- apply(b1$t,2,quantile, 0.025)
# df_new.data1$IC.upp <- apply(b1$t,2,quantile, 0.975)
# df_new.data1$mean.fixed <- apply(b2$t,2,mean)
# df_new.data1$IC.low.fixed <- apply(b2$t,2,quantile, 0.025)
# df_new.data1$IC.upp.fixed <- apply(b2$t,2,quantile, 0.975)
#inv logit
df_new.data1$mean.invlogit <- invlogit(apply(b1$t,2,mean)) * 100
df_new.data1$IC.low.invlogit <- invlogit(apply(b1$t,2,quantile, 0.025)) * 100
df_new.data1$IC.upp.invlogit <- invlogit(apply(b1$t,2,quantile, 0.975)) * 100
df_new.data1$mean.fixed.invlogit <- invlogit(apply(b2$t,2,mean)) * 100
df_new.data1$IC.low.fixed.invlogit <- invlogit(apply(b2$t,2,quantile, 0.025)) * 100
df_new.data1$IC.upp.fixed.invlogit <- invlogit(apply(b2$t,2,quantile, 0.975)) * 100
## Modificação dos dados
# df_ad <- df_resultados
# df_ad$GOF[df_ad$GOF==0] <- 100/(1+exp(-min(df_new.data1$IC.low)))
# df_ad$GOF[df_ad$GOF==100] <- 100/(1+exp(-max(df_new.data1$IC.upp)))
# ## transformação logito ##
# df_ad %<>% mutate(lGOF = log( (GOF/100) / ( 1 - (GOF/100) ) ))
# grafico #
l_p <- vector("list",2)
l_p[[1]] <- ggplot(filter(df_resultados,k %in% levels(df_resultados$k)[1:6]),aes(x=p,y=GOF) ) + 
    geom_ribbon(aes(y=mean.invlogit, ymin=IC.low.invlogit, ymax=IC.upp.invlogit), 
                data=filter(df_new.data1,k %in% levels(df_resultados$k)[1:6]), 
                fill="grey15", alpha=0.5) +
    geom_ribbon(aes(y=mean.invlogit, ymin=IC.low.fixed.invlogit, ymax=IC.upp.fixed.invlogit), 
                data=filter(df_new.data1,k %in% levels(df_resultados$k)[1:6]), 
                fill="white", alpha=0.5) +
    geom_line(aes(x=p, y=mean.fixed.invlogit), 
              data=filter(df_new.data1,k %in% levels(df_resultados$k)[1:6]),color="red") +
    geom_point() +
    labs(y="Número de predições não refutadas",x="% cobertura vegetal") +
    facet_grid(k~MN)
l_p[[2]] <- ggplot(filter(df_resultados,k %in% levels(df_resultados$k)[7:12]),aes(x=p,y=GOF) ) + 
    geom_ribbon(aes(y=mean.invlogit, ymin=IC.low.invlogit, ymax=IC.upp.invlogit), 
                data=filter(df_new.data1,k %in% levels(df_resultados$k)[7:12]), 
                fill="grey15", alpha=0.5) +
    geom_ribbon(aes(y=mean.invlogit, ymin=IC.low.fixed.invlogit, ymax=IC.upp.fixed.invlogit), 
                data=filter(df_new.data1,k %in% levels(df_resultados$k)[7:12]), 
                fill="white", alpha=0.5) +
    geom_line(aes(x=p, y=mean.fixed.invlogit), 
              data=filter(df_new.data1,k %in% levels(df_resultados$k)[7:12]),color="red") +
    geom_point() +
    labs(y="",x="% cobertura vegetal") +
    theme(axis.text.y = element_blank(),axis.ticks = element_blank()) +
    facet_grid(k~MN)
do.call("grid.arrange",c(l_p,ncol=2))
```

__Figura 17__ Número de predições não refutadas a partir da SAD observada e teste de Kolmogorov-Smirnov em função da % de cobertura vegetal. Os quadros estão dividos pelo modelo neutro que gerou as predições (colunas EI e EE) e pela proporção de propágulos que permanece até a vizinhança imediata da planta progenitora (linhas 0.99,...,0.25). A linha vermelha é a probabilidade de não refutar uma predição neutra, a região em branco ao redor da linha vermelha é o intervalo de confiança de 95% marginal ao agrupamento dos dados pelo sítio de amostragem, a região em cinza é o intervalo de confiança de 95% condicional ao agrupamento dos dados pelo sítio de amostragem. 


#### Efeitos fixos

Existem pelo menos 3 maneiras de avaliar a estimativa dos parâmetros do modelo estatístico: a) dividir os dados pelas variáveis categóricas k e MN e então ajustar um glm com distribuição binomial e função de ligação logito e, se os resíduos forem similares, utilizar as estimativas dos glms como aproximações dos parâmetros utilizados; b) utilizar a amostragem a posteori disponível em merTools; c) encontrar uma maneira de estimar a partir do bootMer, que possibilita associar a estimativa com a incerteza marginal e condicional aos efeitos aleatórios.

Vou começar avaliando a opção c por ser mais completa, caso não seja possível sigo para a opção a e então a opção b.

##### bootMer 

```{r coef e intervalo de confianca bootmer parte 1}
## funcao para aplicar e extrair coef de um lm para cada réplica
f_coef.bootMer <- function(df_=df_new.data,X){
  lm.data <- cbind(X,df_new.data)
  names(lm.data)[1] <- "replica"
  lm.object <- coef(lm(replica ~ p.z*k*MN,data = lm.data))
  return(lm.object)
}

# replicas dos coeficientes armazenados em um df
registerDoMC(3)
df_lm.coef1 <- adply(b1$t,1,function(a) f_coef.bootMer(X=a),.parallel = TRUE) %>% select(-X1)
df_lm.coef2 <- adply(b2$t,1,function(a) f_coef.bootMer(X=a),.parallel = TRUE) %>% select(-X1)

## funcao para combinar e sumarizar as replicas de cada coeficiente
f_par.md3ordem <- function(df_coef,df_=df_resultados){
  l_ef <- vector("list",12)
  l_ef[[1]] <- data.frame(k = factor(levels(df_$k)[1], levels = levels(df_$k)), 
                          MN = rep(rep(levels(df_$MN),2),each=1000), 
                          termo = rep(rep(c("alfa","beta"),each=2),each=1000),
                          replica = c(df_coef[,1] , #alfa EI
                                      df_coef[,1] + df_coef[,14], # alfa EE
                                      df_coef[,2], #beta EI
                                      df_coef[,2] + df_coef[,26])) #beta EE  
  for(i in 2:12){
  l_ef[[i]] <- data.frame(k = factor(levels(df_$k)[i], levels = levels(df_$k)), 
                           MN = rep(rep(levels(df_$MN),2),each=1000), 
                           termo = rep(rep(c("alfa","beta"),each=2),each=1000),
                           replica = c(df_coef[,1] + df_coef[,1+i] , #alfa EI
                                       df_coef[,1] + df_coef[,1+i] + df_coef[,14] + df_coef[,25+i], # alfa EE
                                       df_coef[,2] + df_coef[,13+i], #beta EI
                                       df_coef[,2] + df_coef[,13+i] + df_coef[,26] + df_coef[,36+i])) #beta EE
  }
  df_ef <- rbind.fill(l_ef) %>% ddply(.,c("k","MN","termo"),summarise, 
                                       media = mean(replica), mediana = median(replica), 
                                       upr = quantile(replica, 0.975), lwr = quantile(replica, 0.025)) 
return(df_ef)
}
## data frame com ambas estimativas
df_ef <- cbind(f_par.md3ordem(df_coef = df_lm.coef1),
               f_par.md3ordem(df_coef = df_lm.coef2)[,4:7])
names(df_ef)[8:11] <- c("media.m","mediana.m","upr.m","lwr.m")

## gráfico dos dois intervalos ##
l_p <- vector("list",4)
l_p[[1]] <- ggplot(filter(df_ef,termo == "alfa"),aes(x=k,y=invlogit(media),color=MN)) +
  geom_linerange(aes(ymin=invlogit(lwr),ymax=invlogit(upr))) +
  geom_crossbar(aes(x=k,ymin=invlogit(lwr.m),ymax=invlogit(upr.m))) +
  scale_colour_manual(values = c("Blue", "Red")) +
  labs(y="invlogit(alfa)") +
  theme(legend.position = "none")
l_p[[3]] <- ggplot(filter(df_ef,termo == "beta"),aes(x=k,y=invlogit(media),color=MN)) +
  geom_linerange(aes(ymin=invlogit(lwr),ymax=invlogit(upr))) +
  geom_crossbar(aes(x=k,ymin=invlogit(lwr.m),ymax=invlogit(upr.m))) +
  scale_colour_manual(values = c("Blue", "Red")) +
  labs(y="invlogit(beta)") +
  theme(legend.position = "bottom")
l_p[[2]] <- ggplot(filter(df_ef,termo == "alfa"),aes(x=k,y=media,color=MN)) +
  geom_linerange(aes(ymin=lwr,ymax=upr)) +
  geom_crossbar(aes(x=k,ymin=lwr.m,ymax=upr.m)) +
  scale_colour_manual(values = c("Blue", "Red")) +
  labs(y="alfa") +
  theme(legend.position = "none")
l_p[[4]] <- ggplot(filter(df_ef,termo == "beta"),aes(x=k,y=media,color=MN)) +
  geom_linerange(aes(ymin=lwr,ymax=upr)) +
  geom_crossbar(aes(x=k,ymin=lwr.m,ymax=upr.m)) +
  scale_colour_manual(values = c("Blue", "Red")) +
  labs(y="beta") +
  theme(legend.position = "bottom")
do.call("grid.arrange",c(l_p,ncol=2))
```

__Figura 18__ Probabilidade média de não refutar (alfa) e o efeito da porcentagem de cobertura vegetal (p) na probabilidade de não refutar neutralidade (beta) pela proporção de propágulos até a vizinhança imediata da planta progenitora (k) e pelo modelo neutro que gerou a predição neutra (MN), em azul MN de espaço explícito e em vermelho MN de espaço explícito. As linhas horizontais são os efeitos médios, a caixa representa o intervalo de confiança de 95% (IC) para as predições marginais aos efeitos aleatórios e a linha vertical representa IC para as predições condicionais aos efeitos aleatórios do modelo mais plausível. Na coluna da direita os alfas e betas estão na escala da respostae, em porcentagens; na coluna da direita os parâmetros estão na escala da função de ligação. Os ICs e a média foram estimados a partir do ajuste de uma regressão linear considerando a interação de terceira ordem entre as preditoras (p, k e MN) para cada réplica do bootstrap da predição do modelo plausível, que está na escala da função de ligação; somou-se os vetores de coeficienes réplicas para obter os respectivos alfas e betas para cada combinação entre k e MN, então calculou-se as médias e os quantis para 2.5% e 97.5% dos coeficientes estimados. O coeficiente de determinação de todos as regressões lineares foi igual a 1.


  A tendềncia geral é robusta à variação na limitação à dispersão, mas boa parte da variação está associada com o sítio de amostragem e não é descrita pelo efeito da cobertura vegetal da paisagem nos dados (figura 17). O sinal de que a fragmentação leva à diminuição da congruência entre predito e observado explica pouca variação apresentada nos dados. A maior parte da variação está associada com o sítio de amostragem. Além disso, o modelo misto não consegue prever boa parte da variação dos dados, o coeficiente de determinação condicional não é superior à 70% (figura 17). No nível do sítio de amostragem é possível estabelecer diferentes relações entre as variáveis preditoras k (enquanto variável contínua) e MN (EE;EI). Podemos ter até 4 parâmetros por modelo estatístico (alfa (média), alfa_MN:EE (diferença média); k.z (inclinação), k.z_MN:EE(diferença média na inclinação)), avaliaremos o efeito de p e S na estimativa destes parâmetros.
  
JUSTIFICATIVA: Introdução: "how confounding factors have either masked the detection/prevented the predicted fragmentation effects(Ewers & Didham 2006, Villard & Metzger 2014, Collins et al. 2017)?"
  
  Uma possibilidade é avaliar o efeito da limitação à dispersão para cada sítio de amostragem separadamente, permitindo explicar a probabilidade de não refutar uma predição neutra como resultado da classe de modelo neutro (EE e EI) e de k como variável contínua. Podemos selecionar os coeficientes do modelo mais plausível e avaliar os modelos ajustados: i) o coeficiente de explicação (R2); ii) probabilidade dos resíduos quantílicos apresentarem distribuição uniforme; iii) métrica de incerteza da estimativa do parâmetro (e.g. IC). Esperamos que os três itens sejam independente  de p e S. Então avaliamos os coeficientes ajustados em função da cobertura vegetal.


Sequência de trabalho:

i) agrupar dados pelo sítio de amostragem
ii) criar função que executa a seleção dos modelos e retorna: a) estimativa dos coeficientes do modelo mais plausível; b) coeficiente de determinação (R2); c) se os resíduos quantílicos aderem à uniformidade (resid)
iii) aplicar teste de pressupostos estatísticos: a) variação explicada pelo modelo não apresenta influência da cobertura vegetal e do número de espécies observado; b) 
iv) descrição do padrão dos coeficientes (regressão linear: logito(U) ~ p * term)


```{r glm por site para Pr(nao refutar)}
# teste
# df <- filter(df_resultados,Site==unique(df_resultados$Site)[80])
# função com as hipóteses estatísticas
# função aplicada para cada site
f_glm.Site <- function(df){
  # ajustar modelos concorrentes
  # seleção de modelos
  f_ <- function(X){
      l_ <- vector("list",5)
      names(l_) <- c("k * MN","k + MN","k","MN","1")
      l_[[1]] <- glm(cbind(GOF,100-GOF) ~ k.z * MN, family = binomial, data = X)
      l_[[2]] <- glm(cbind(GOF,100-GOF) ~ k.z + MN, family = binomial, data = X)
      l_[[3]] <- glm(cbind(GOF,100-GOF) ~ k.z, family = binomial, data = X)
      l_[[4]] <- glm(cbind(GOF,100-GOF) ~ MN, family = binomial, data = X)
      l_[[5]] <- glm(cbind(GOF,100-GOF) ~ 1, family = binomial, data = X)
      return(l_)
    } 
  l_md <- f_(X=df) #filter(df_resultados,Site=="BAjuss") #X=df
  names_like.md <- row.names.data.frame(AICctab(l_md))
  dAIC_like.md <- AICctab(l_md)$dAICc
  if( length(dAIC_like.md[dAIC_like.md<2]) == 1 ){
    # modelo mais plausível
    md_like <- l_md[[ names_like.md[1] ]]
    # coef
    df_md <- tidy(md_like)
    # deviance ~ R2
    df_md$deviance <- summary(md_like)$deviance
    # resíduos quantílicos e teste de uniformidade
    resid_md.like <- simulateResiduals(md_like,n=1000)  
    df_md$p_test.uni <- testUniformity(resid_md.like,plot = F)$p.value
    # output = df resumo
    return(df_md)
  } else {
    df_md1 <- data.frame(term = "#l_md[dAIC<=2]>1", 
                         estimate = "#l_md[dAIC<=2]>1",
                         std.error = "#l_md[dAIC<=2]>1", 
                         statistic = "#l_md[dAIC<=2]>1", 
                         p.value="#l_md[dAIC<=2]>1", 
                         deviance="#l_md[dAIC<=2]>1", 
                         p_test.uni="#l_md[dAIC<=2]>1")
    return(df_md1)
  }
}
# armazenamento dos dados 
# f_glm.Site(df = filter(df_resultados,Site=="BAjuss"))
df_Pr.Site <- ddply(df_resultados,"Site",function(a) f_glm.Site(df=a)) %>% inner_join(x=.,y=unique(df_resultados[,c(1,6,10,11)]),by="Site")
# df_Pr.Site$term %>% table

# gráfico
# df_Pr.Site %>% filter(std.error > 400) 
# outliers <- c("PRdiam2","PRanto15","PRanto4")
# gráfico sem outliers
df_Pr.Site %>% filter(term != "#l_md[dAIC<=2]>1" & std.error < 400) %>% 
  ggplot(aes(x=p,y=estimate,size=std.error)) +
  geom_point() +
  geom_smooth(se=FALSE,color="red",method="lm") +
  facet_wrap(~term, ncol=2,scales="free")
```

__Figura 19__ Interceptos(intercept, MNEE) e Inclinação(k.z, k.z:MNEE) estimados do modelo mais plausível para cada sítio de amostragem pela cobertura vegetal.

Para utilizar esses dados é válido avaliar se (i) a probabilidade de resíduos aderirem à uniformidade, (ii) a deviance e (iii) o erro padrão das estimativas sejam independentes da cobertura vegetal, a variável preditora de interesse.

Ideia para avaliar com PI


## 3) Taxa de especiação, U ##

Gráficos exploratório


```{r taxa de especiacao U}
# opções para modelar U:
df_resultados %<>% mutate(lU = log(U/(1-U)),
                          lS.z = (log(S) - mean(log(S)))/sd(log(S)))

car::scatterplotMatrix(~U+lU+p.z+lS.z,data=df_resultados)

# df_resultados %>% ggplot(aes(x=k,y=U)) + geom_boxplot()
# 
# df_resultados %>% ggplot(aes(y=lU,x=log(S))) +
#   geom_point() +
#   geom_smooth(se=F,method='loess',color="red") +
#   facet_wrap(~k,ncol=3,scales="free")
```

figura 20. Taxa de especiação e preditoras continuas


Para modelar U aplicamos uma transformação logito e tomando U enquanto probabilidade média de especiação (U e lU). As preditoras p.z esta z-transformada e lS.z é o log da riqueza z-transformado. Segue gráfico de lU pela preditora

### Diagnóstico do modelo cheio ###

O modelo cheio de U descreve lU ~ p*k + S + (1|Site). Segue diagnóstico do modelo cheio com distribuição lmer:

```{r md U e residuos quantilicos}
# modelo linear
md_U <- lmer(lU ~ p.z * k + lS.z + (1|Site), data=df_resultados)

# residuos quantilicos
residuos_U <- simulateResiduals(fittedModel = md_U, n = 1000)
plot(residuos_U)
```

figura 21. Resíduos quantílicos do modelo cheio lU ~ p.z * k + l.S_z

O teste de aderência à uniformidade mostra que há desvio significativo; a regressão quantílica parece estar ok. Então o modelo cheio pode não ser apropriado para descrever a relação entre as variáveis, mais testes são necessários para avaliar a origem do desvio. Vou prosseguir com o lmer.


### Seleção de modelos e coeficiente de determinação ###


```{r tabela de selecao logito U}
l_md <- vector("list",length=10)
names(l_md) <- c("p * k + S", "p + k + S", "p + S", "k + S", "S", "p * k", "p + k", "p", "k", "1")
l_md[[1]] <- lmer(lU ~ p.z * k + lS.z + (1 | Site), data = df_resultados)
l_md[[2]] <- lmer(lU ~ p.z + k + lS.z + (1 | Site), data = df_resultados)
l_md[[3]] <- lmer(lU ~ p.z + lS.z + (1 | Site), data = df_resultados)
l_md[[4]] <- lmer(lU ~ k + lS.z + (1 | Site), data = df_resultados)
l_md[[5]] <- lmer(lU ~ lS.z + (1 | Site), data = df_resultados)
l_md[[6]] <- lmer(lU ~ p.z * k + (1 | Site), data = df_resultados)
l_md[[7]] <- lmer(lU ~ p.z + k + (1 | Site), data = df_resultados)
l_md[[8]] <- lmer(lU ~ p.z + (1 | Site), data = df_resultados)
l_md[[9]] <- lmer(lU ~ k + (1 | Site), data = df_resultados)
l_md[[10]] <- lmer(lU ~ 1 + (1 | Site), data = df_resultados)
# selecao #
AICctab(l_md, weights = TRUE)
```

O modelo cheio apresentou a única hipótese plausível acumulando todo o peso de evidência.


```{r R2 logito U}
# R2 marginal e condicional #
(r2_U <- sapply(l_md, r.squaredGLMM))
```


O modelo mais plausível apresenta o maior coeficiente de determinação condicional e marginal. O modelo que considera apenas p*k acumula apenas 5% de coeficiente de determinação marginal, enquanto o modelo que considera apenas S explica cerca de 31% da variação total. O modelo onde há o efeito aditivo de p e S acumula mais do que a soma do modelo com apenas p e S. Assim boa parte da variação explicada pelo modelo está associada com a riqueza observada e parte da correlação desta com a cobertura vegetal da paisagem.  


### Intervalo de confiança do modelo mais plausível ###

```{r IC U}
## Uma regressao entre log_S.z e pz ##
lm1 <- lm(lS.z ~ p.z, data=df_resultados[duplicated(df_resultados$Site),]) # estima relacao linear entre log S e p.z
cf1 <- unname(coef(lm1)) ## guarda os coeficientes dessa regressao para usar no bootstrap

## Intervalo de Confiança Bootstrap ##
# novo conjunto de dados
df_newdat <- expand.grid(Site=df_resultados$Site[1],
                         k=unique(df_resultados$k),
                         p.z = seq(min(df_resultados$p.z)*1.1,max(df_resultados$p.z)*1.1, length=50))
# Adiciona a média de log(S) padronizado para cada cobertura, estimado pela regrassao Sxp
df_newdat %<>% mutate(lS.z = cf1[1] + cf1[2]*p.z) %>% as.data.frame()
## Passo 2: crie as função que devem ser calculadas dos modelos a cada simulação
## Previstos por efeitos fixos e aleatórios
f1 <- function(.) predict(., newdata=df_newdat)
## Previstos por efeitos fixos (argumento re.form=~0)
f2 <- function(.) predict(., newdata=df_newdat, re.form=~0)
## Os dois bootstraps. Ajuste o argumento ncpus para o numero de cores de seu computador
md_U <- l_md[["p * k + S"]]
# b3 <- bootMer(md_U, FUN = f1, nsim=1000, parallel="multicore", ncpus=2)
# b4 <- bootMer(md_U, FUN = f2, nsim=1000, parallel="multicore", ncpus=2)
# save(b3,b4,file="/home/danilo/Documentos/Doutorado/artigo_mestrado/Rmd_e_dados/bootMer_md-U.Rdata")
load(file = "/home/danilo/Documentos/Doutorado/artigo_mestrado/Rmd_e_dados/bootMer_md-U.Rdata")
## calcula as médias e intervalos de confiança quantílicos para cada combinação de preditoras
## no novo conjunto de dados
df_newdat$p <- df_newdat$p.z*sd(df_resultados$p) + mean(df_resultados$p)
df_newdat$mean <- apply(b3$t,2,mean)
df_newdat$IC.low <- apply(b3$t,2,quantile, 0.025)
df_newdat$IC.upp <- apply(b3$t,2,quantile, 0.975)
df_newdat$mean.fixed <- apply(b4$t,2,mean)
df_newdat$IC.low.fixed <- apply(b4$t,2,quantile, 0.025)
df_newdat$IC.upp.fixed <- apply(b4$t,2,quantile, 0.975)

## Gráfico

df_resultados %>%
  ggplot(aes(x=p,y=lU)) +
  geom_ribbon(aes(y = mean, ymin=IC.low, ymax=IC.upp), data=df_newdat, fill="grey15", alpha=0.5) +
  geom_ribbon(aes(y=mean, ymin=IC.low.fixed, ymax=IC.upp.fixed), data=df_newdat, fill="white", alpha=0.5) +
  geom_line(aes(x=p, y=mean.fixed), data=df_newdat,color="red") +
  geom_point() +
  labs(x="% cobertura vegetal", y = "logito(U)") +
  facet_wrap(~k,ncol=3)
```

figura 22. logito(U) p e k 

Avaliar os efeitos a partir do bootstrap e a partir do merTools para S



## 4) Viés de estimativa da riqueza ##

23 março de 2019

Quando desenvolvi os dados de MNEI eu substitui as informações da riqueza estimado de MNEE para o correspodente. Não há motivo para questionar se cometi o mesmo erro para GOF uma vez que eles diferem em seu perfil e me recordo de fazer uma bateria de auditorias na época. Contudo, vi que os .Rmds não estão organizados e se faz necessário organizar tudo para o futuro.

Pretendo acertar os .Rmds de geração dos dados quando for fazer os métodos pois não estou com tempo para isso agora, além de que quero aproveitar o embalo das reuniões de orientação com PI. Assim, não irei juntar os dados e (re)fazer uma auditoria geral de tudo (GOF está ok), vou pelo caminho direto que é construir um df com a riqueza de MNEE de df antigos (que sei que estão corretos) com a riqueza para MNEI de df_resultados.

```{r}
## df_ com a S_EI ##
df_bias.S_EI <- df_resultados %>% filter(MN == "EI") %>% select(Site,S_m,S_sd,k,MN) %>% unique

## df_ com S_EE correto ##
load("/home/danilo/Documentos/Doutorado/dados/l_dados_brutos.Rdata")
# l_dados_brutos %>% names
df_bias.S_EE <- l_dados_brutos[[1]] %>% ddply(.variables = c("SiteCode","kernel"),summarise,
                                              S_m = mean(S),S_sd = sd(S))
names(df_bias.S_EE)[1:2] <- c("Site","k")
df_bias.S_EE$MN <- "EE"
# remoção de sites não utilizados
df_bias.S_EE %<>% filter(Site %in% levels(df_resultados$Site))

## df_ para análise dos dados ##
df_bias.S <- df_resultados %>% select(Site,k,MN,GOF,U,S,p,m_,J,DA)
df_bias.S %<>% inner_join(x=.,
                        y=rbind(df_bias.S_EI,df_bias.S_EE),
                        by = c("Site","k","MN"))
df_bias.S$Site %<>% as.factor()
# df_bias.S %>% str

write.csv(df_bias.S,file = "/home/danilo/Documentos/Doutorado/artigo_mestrado/Rmd_e_dados/df_bias_S.csv",row.names = FALSE)

ggplot(df_bias.S,aes(x=S,y=S_m,color=MN)) + 
  geom_point() + 
  geom_abline(intercept = 0,slope=1,color="red") +
  facet_wrap(~k,ncol=3,scales = "free")
```

