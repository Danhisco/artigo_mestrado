---
title: "Resultados - artigo"
author: "Mori, Danilo Pereira"
date: "21 de maio de 2018"
output: html_document
---

```{r setup, include=FALSE} 
knitr::opts_chunk$set(echo = FALSE, tidy = TRUE, include = TRUE, warning = FALSE,cache = TRUE)
```

```{r dados e pacotes,warning=FALSE,message=FALSE,echo=FALSE}
# library(reshape2) # para mudar formato dos dados
library(lattice)
library(gridExtra)
library(RVAideMemoire) #gráficos diagnóstico dos GLMM
library(sjPlot) #gráficos de GLMM
library(MuMIn) # para R^2
# library(gridExtra)  #pacote para gráficos
# library(ggplot2)  # idem
library(sads)
library(lme4) # pacote de criação dos modelos estatísticos
# library(bblme) # pacote para comparar os modelos, seleção per se
library(merTools) # para intervalos de previsao
library(tidyverse)
library(broom) # para manipular os modelos
library(magrittr) # p escrita
library(MASS)
library(car)
# library(plyr) 
# library(dplyr) 
df_resultados <- read_csv("/home/danilo/Documentos/Doutorado/artigo_mestrado/Rmd_e_dados/df_resultados.csv")
# df_resultados %>% str
df_resultados$MN <- factor(df_resultados$MN,levels = c("EI","EE"))
df_resultados$SiteCode <- factor(df_resultados$SiteCode)
df_resultados$k <- factor(df_resultados$k,levels=unique(df_resultados$k))
# df_resultados$k %>% contrasts()
# df_resultados$MN %>% contrasts()

#### z score ###

f_z <- function(x){
  m <- base::mean(x,na.rm=TRUE)
  sd <- sd(x,na.rm=TRUE)
  output <- (x-m)/sd
  return(output)
} 

df_resultados %<>% mutate(GOF.z = f_z(GOF),
                          DA.z = f_z(DA),
                          p.z = f_z(p),
                          S.z = f_z(S),
                          U.z = f_z(U),
                          m_.z = f_z(m_),
                          I.z = f_z(I),
                          d.z = f_z(d),
                          k.z0 = as.numeric(as.character(k)),
                          k.z = f_z(k.z0))

names(df_resultados)[1] <- "Site"

```

<!--
Ideia geral dos métodos:

i) estabelecer valores do parâmetro de dispersão a priori;
ii) estimar taxa de especiação necessária para manter a riqueza no equilíbrio a partir do método de MNEE
iii) simular SADs neutras segundo MNEI e MNEE a partir dos mesmo parâmetros
-->

## Estrutura dos Resultados Completos: ##

I) parâmetros de dispersão:

  a) distância média de dispersão (d)

  b) número fundamental da dispersão (I)
- com isso podemos avaliar quais as situações biológicas de limitação à dispersão que a simulação está ocorrendo para os dois modelos neutros
<!--
distância média de dispersão ~ k * p + (k|Site) ou k_factor * p + (1|Site) [modelo completo se houver mais níveis de k e estiverem igualmente espaçados - segunda etapa] 
-->

II) Congruência do predito com o observado
- a ideia central do artigo é: "Avaliar se a SAD pode ser evidência suficiente para refutar neutralidade"
- assim optei por mudar a variável de congruência de GOF, que avalia quantas predições neutras foram refutadas por cenário neutro
- para n_ref = número de predições neutras refutadas por cenário neutro

III) taxa de especiação necessária para manter a riqueza observada no equilíbrio dinâmico segundo um modelo neutro espacialmente explícito (U)
- a teoria neutra pode ser uma boa aproximaçaõ para descrever a taxa de extinção de espécies raras em ambientes fragmentados
- o modelo neutro coalescente é uma boa aproximação para descrever o comportamento dos sistemas biológicos em diferentes contextos de fragmentação (Campos et al.)
- no modelo coalescente o equilíbrio dinâmico é observado, nesse cenário a taxa de surgimento de singletons por evento de morte se igual à taxa de extinção de singletons
- assim, a estimativa de taxa de especiação necessária para manter a riqueza observada no equilíbrio pode ser uma aproximação da taxa de extinção das espécies raras na paisagem.

IV) Anexo 1: código auxiliar
- segue a mesma ordem das variáveis
- é o local onde eu desenvolvo a análise dos dados


Notas: até o momento desenvolvi parte da análise dos dados para I.A

<!-- Esqueleto dos resultados 1

a) MNEI por verossimilhança
-GOF) Se MNEI tiver seus parâmetros livres ele sempre apresentara boa congruência com o observado?
-theta) Se o ajuste dos parâmetros informa algo além da SAD em si, esperamos observar efeito positivo de p, pois para maiores coberturas vegetais há mais indivíduos na região biogeográfica.
-m) Idem, esperamos observar efeito positivo de p, uma vez que quanto menor a cobertura vegetal de uma paisagem menor a concetividade entre as manchas de habitat (REFERÊNCIA)

b) Conversão de parâmetros de imigração
-par{MNEI} -> par{MNEE} [parâmetros com maior interpretação biológica - que permite a parametrização a partir de valores observados]
-distância médias de dispersão -> m segundo uma simulação coalescente em paisagem fragmentada.

c) Estimando U a partir de uma simulação coalescente
- 20 valores de U a partir de cada nível de d [MM]
- U -> theta, pela formula de conversão de theta [MM]
- U ~ p * d + (d | Site) [ou a formula que estamos utilizando]

d) Congruência do observado entre os modelos neutros consideramos mesmo conjunto de parâmetros
[MM]: estabelecemos distâncias de dispersões segundo diferentes cenários de limitação à dispersão médio (d), que parametrizados com valores observados na natureza para diferentes sindromes de dispersão. Para cada nível de d estimamos a taxa de especiação necessária para manter a riqueza observada, sob a hipótese de equilíbrio dinâmico, (U - singleton/evento de morte) segundo MNEE. Utilizamos o par U e d para gerar SADs segundo MNEE e convertemos U e d em theta e m, respectivamente, para gerar SADs segundo MNEI. Para cada MN geramos 100 SADs réplicas que comparamos com a respectiva SAD observada pelo teste de Kolmogorov-Smirnov; contabilizamos o número de vezes que não foi possível refutar a hipótese nula de que a SAD réplica e SAD observada são amostras de uma mesma distribuição teórica na variável GOF (Goodness-of-fit). Temos 80 sítios de amostragens, 30 rodadas de simulação para cada nível de MN (EE e EI).

- GOF ~ p * d * MN + (d | Site / MN)
MN: factor 2 levels: EE, EI
d: numeric 30 valores para todas as simulações

e) Parâmetro a posteori: espécies input (Condit et al. 2012)
- spp_I ~ p * d + (d|Site)
- GOF ~ spp_I * d * MN + (d | Site / MN)


-->



<!-- última paragráfo de material e métodos

Organizamos os resultados em 3 blocos de dados, aqueles para MNEE, MNEI e MNEE + MNEI. As variáveis resposta são: GOF, $\theta$, m, U, spp_I e d. As variáveis indepedentes são cobertura vegetal (p) e função de dispersão, que está sendo expressa de forma categorica(k), assim, podemos avaliar tanto os dados de MNEE, quanto para MNEE + MNEI; e de forma contínua d (distância média de dispersão da função de dispersão), para os dados de MNEE. Convertemos os parâmetros de MNEE U e d em $\theta'$, m'; e $\theta$ e m de MNEI em  U' e (d' e k'), considerando que $J_M$ = número de indivíduos na paisagem. Quando houve mais de uma observação para um mesmo Sítio de amostragem, então utilizamos a variável Sítio como variável categórica dos efeitos aleatórios do modelo linear; quando a função de dispersão foi categória utilizamos (1|Site) e  (d|Site) se ela foi contínua. Assim, temos duas maneiras de partir a variação prevista pelo modelo. O $R_m^2$ é a variação explicada pelos efeitos fixos do modelo, ou seja, p e/ou a variável relacionada à limitação à dispersão (k ou d) ('R quadrado marginal'); já o R quadrado condicional, $R_c^2$, é a variação associado tanto às variáveis de efeito fixo quanto ao efeito aleatório (sítio de amostragem). 
Acredito que uma métrica de comparação entre $R^2$ para GLM e GLMM seria considerar a razão $R_{GLMM}^2 = R_m^2 / R_c^2$? -->

<!--
## Sessão antiga, 18jun ##
Introdução da sessão de resultados:

Vou explorar o terceiro bloco de dados c(MNEE, MNEI), em anexo a análise dos dados para o conjunto de dados MNEE e MNEI. MNEE e MNEI diferem na forma que implementam a teoria neutra e na forma com que estimam os parâmetros a priori simulação. Assim, unir os resultados em uma mesma análise de dados tem que ser feita considerando a origem dos dados, para adequar com os resultados de MNEE organizei os dados pela proporção da chuva de propágulos que permanece até a área imediata a da copa da árvore progenitora (l_cel metros). Incluindo os dados de MNEI, são 13 níveis na variável "k", o primeiro nível é aquele com cenário de limitação à dispersão mais rigoroso (=0.99), o penúltimo nível é o cenário de limitação à dispersão menos realista (=0.25) e o último nível são os dados de MNEI. Em análise exploratória observamos que mesmo com valores razoáveis de m, MNEI apresentou d's superiores ao de MNEE em escala log (anexo) e como d está relacionado com a proporção de propágulos até a área imediata da planta progenitora (k) ordenei os níveis de "k" agrupando os valores de MNEI juntos no último nível. Existe grande variação no parâmetro 'm' estimado por verossimilhança, contudo, essa variação não apresenta efeito de p (anexo), então, não considerar a variação interna de m em MNEI não deve interferir na análise dos dados. Em anexo, há as análises auxiliares que inclui dos outros conjuntos de dados.
i) Os dois modelos conseguem apresentar boa congruência com o observado? 
ii) Se sim quais as característica da paisagem e da relação com a área amostrada que propiciam esse resultado? 
iii) Em cenários de limitação à dispersão biologicamente realistas o modelo neutro apresente boa congruência com os dados?
iv) Qual o efeito da fragmentação na diversidade da paisagem segundo o predito neutro?


## Esqueleto dos resultados - 18jun ##

a) resultados para os parâmetros de imigração para as distâncias simuladas: m, I e k. Tentar incluir os valores estimados em campo
b) v ~ p * par_imig + S + (par_imig | Site); par_imig = d, m, I, k
c) GOF ~ p * MN * par_imig + S + (par_imig | Site / MN) 


-->
<!--
Para faciltar o ajuste dos modelos mistos aplicamos a transformação z nas variáveis contínuas: 
-->

#### Anexo 1: código auxiliar ####

##### I) parâmetros de dispersão #####
__I.A) distância média de dispersão (d)__

Exploração gráfica

```{r graf d}
# x11()
par(mfrow=c(3,2))
## d e d.z ##
# ~ norm
qqp(df_resultados$d, "norm",ylab="d (metros)") 
qqp(df_resultados$d.z, "norm",ylab="d.z (Z(d))") 
# ~ lnorm
qqp(df_resultados$d, "lnorm",ylab="d (metros)")
qqp(df_resultados$d.z, "lnorm",ylab="d.z (Z(d))")
# ~ gamma
fit_gamma1 <- fitdistr(df_resultados$d, "gamma")
qqp(df_resultados$d, "gamma", shape = fit_gamma1$estimate[[1]], rate = fit_gamma1$estimate[[2]],ylab="d (metros)")
## d.z ##
# ~ norm
# ~ lnorm
# ~ gamma
```

Figura A1. Gráficos quantile-quantile para três distribuições teóricas (normal, lognormal e gamma) e a variável d (metros) e z-transformada (d.z). Para a distribuição gamma utilizei ajustamos apenas a variável d, uma vez que o domínio da distribuição não contempla valores menores do que zero.

A distribuição que melhor se adequa aos dados é a distribuição gamma: i) ajusta maior porção dos dados em comparação com a normal (segunda melhor distribuição) e ii) consegue capturar a variação nas caudas da distribuição de valores obervados (em especial para valores pequenos), diferente da normal. Contudo, para comparar os resíduos eu vou construir duas classes de modelos cheio: uma normal e outra gamma.

O objetivo é avaliar o efeito da variável k na distância média de dispersão (d), para isso o modelo cheio vai considerar a variável DA, uma vez que k é definido como a proporção de propágulos até l_cel metros da planta progenitora. A largura da célula de simulação (l_cel) = 100/sqrt(DA) (PERGUNTA:devo utilizar DA ou a transformação de DA = I( 100/sqrt(DA) )? ).

_Tabela Seleção da distribuição de probabiliade e estrutura aleatória_

```{r d k}
# df_resultados %>% str
## Seleção da estrutura eleatória ##
l_md <- vector("list",length = 8)
names(l_md) <- c("Gamma 1|Site","Gamma k|Site",
                 "log.Gamma 1|Site","log.Gamma k|Site",
                 "normal 1|Site","normal k|Site",
                 "log.normal 1|Site","log.normal k|Site")
l_md[[1]] <-  glmer(d ~ k + DA.z + (1|Site),family = "Gamma",data = df_resultados)
l_md[[2]] <-  glmer(d ~ k.z + DA.z + (k.z|Site),family = "Gamma",data = df_resultados)
l_md[[3]] <-  glmer(d ~ k + DA.z + (1|Site),family = "Gamma"(link=log),data = df_resultados)
l_md[[4]] <-  glmer(d ~ k.z + DA.z + (k.z|Site),family = "Gamma"(link=log),data = df_resultados)
l_md[[5]] <-  glmer(d ~ k + DA.z * (1|Site),family = "gaussian",data = df_resultados)
l_md[[6]] <-  glmer(d ~ k.z + DA.z + (k.z|Site),family = "gaussian",data = df_resultados)
l_md[[7]] <-  glmer(d ~ k + DA.z + (1|Site),family = "gaussian"(link=log),data = df_resultados)
l_md[[8]] <-  glmer(d ~ k.z + DA.z + (k.z|Site),family = "gaussian"(link=log),data = df_resultados)
AICctab(l_md,weights=T)
```
<!--
A estrutura aleatória selecionada foi (1|Site).
-->

O modelo global com distribuição gamma, função de ligação log e estrutura aleatória 1|Site foi o mais plausível. Segue sumário:

```{r d k R2,echo=TRUE}
summary(l_md[[3]]) # problema de convergência, indicam para reescalonar as variáveis
```
<!--
Error: Error in r.squaredGLMM.merMod(X[[i]], ...) : do not know how to calculate variance for this family/link combination
27jun2018[Válido para lmer, não para normal link=log: acredito que se houver mais níveis de k e melhor distribuidos no campo de parâmetros aumentaria o R^2 de k|Site
-->

_31jun2018_
- Problema de convergência:
convergence code: 0
Model is nearly unidentifiable: very large eigenvalue
 - Rescale variables?
ajuda: ?convergence

"
if you do see convergence warnings, and want to trouble-shoot/double-check the results, the following steps are recommended (examples are given below):

double-check the model specification and the data for mistakes

center and scale continuous predictor variables (e.g. with scale)

check for singularity: if any of the diagonal elements of the Cholesky factor are zero or very small, the convergence testing methods may be inappropriate (see examples)

double-check the Hessian calculation with the more expensive Richardson extrapolation method (see examples)

restart the fit from the apparent optimum, or from a point perturbed slightly away from the optimum

try all available optimizers (e.g. several different implementations of BOBYQA and Nelder-Mead, L-BFGS-B from optim, nlminb, ...) via the allFit() function, see ‘5.’ in the examples. While this will of course be slow for large fits, we consider it the gold standard; if all optimizers converge to values that are practically equivalent, then we would consider the convergence warnings to be false positives.
"


A única variável contínua que não foi rescalonada foi a resposta d, se aplicar transformação z em d, a variável resposta terá números negativos. Utilizando a variável DA ao inves de DA.z piora o caso. Alternativamente busquei simplificar o modelo: a) retirando a variável DA.z; e b) retirando o último nível de k (contudo como é um factor não há de fazer muita diferença) - para ambos não houve melhora.

PRÓXIMOS PASSOS PARA MELHORAR AJUSTE: uma alternativa fácil é reajustar a partir das estimativas feitas pelo modelo com problema de convergência e/ou modificar o otimizador.
PERGUNTAS NORTEADORAS: i) o aviso de problema de convergência é um falso positivo? 

Ben Bolker: Since the likelihood differs by <0.1 between the model fits, and the largest relative differences in the parameters are of the order of about 10^(-4), I would say that you have successfully demonstrated that the warning is a false positive and you can proceed with your initial model.


<!--
[pasta GLMM (...) scale issues] Some common examples:

-Some columns of our data might be different orders of magnitude to others, for instance gender might be encoded as a binary variable, while income might be stored in whole-dollar amounts.

-An outcome might be extremely rare

-The impact of variable X1 on Y could be orders of magnitude greater than the impact of variable X2. That is, it’s not the scale of the data that is causing issues so much as the scale of the parameters.


-->


Foram estimados 13 parâmetros e seus respectivos erro-padrão. Os resíduos escalonados variam de -3.956 até 6.554, pelos valores dos quantils parece que a distribuição dos resíduos não é simétrica ao redor da estimativa. Há dois avisos sobre convergência: a) Model failed to converge with max|grad|=4.11797 (tol = 0.001, component 1); b) Modelo is nearly unidentifiable: very large eigenvalue - Rescale variables?

25jun2018:
Para lidar com b modifiquei DA -> DA.z nos modelos globais
Com isso obtive o erro: 'converge code:0; Model is nearly unidentifiable: very large eigenvalue - Rescale variables?
- a transformação z de DA deveria ser o suficiente para lidar com problemas relacionados com escalamento de variáveis; a outra variável explanatória é categórica.
- vou continuar o estudo com esse modelo como global

_Tabela Selecao de variaveis para descrever 'd'_

```{r selecao d}
l_md <- vector("list",length = 4)
names(l_md) <- c("k+DA","DA","k","1")
l_md[[1]] <-  glmer(d ~ k + DA.z + (1|Site),family = "Gamma"(link=log),data = df_resultados)
l_md[[2]] <-  glmer(d ~ DA.z + (1|Site),family = "Gamma"(link=log),data = df_resultados)
l_md[[3]] <-  glmer(d ~ k + (1|Site),family = "Gamma"(link=log),data = df_resultados)
l_md[[4]] <-  glmer(d ~ 1 + (1|Site),family = "Gamma"(link=log),data = df_resultados)
AICctab(l_md)
```

O modelo global foi o mais plausível. [PROBLEMA DE CONVERGÊNCIA]. E por conta disso não consigo avaliar o ajuste visualmente:

```{r echo=TRUE}
# prof_glmm.d <- profile(l_md[[3]])

# xyplot(prof_glmm.d , aspect =1.3)
```

Avaliação gráfica do ajuste do modelo:

```{r predito e observado d}
df_reg <- broom::augment(l_md[[1]])
df_reg %<>% mutate(predito = exp(.fitted),
                   std.resid = .resid/sd(.resid),
                   sqrt.std.resid = sqrt(std.resid))
## observado e predito ##
df_reg %>%  ggplot(aes(x=DA.z,y=d)) + geom_point() +
  geom_line(aes(y=predito),color="red") + facet_wrap(~k,ncol=3,scales="free")
```

__Figura 1__ Distância média de dispersão (d) e o predito segundo d ~ DA.z + k + (1 | Sítio), family=Gamma. Os pontos são as distâncias médias estimados para o determinado percentil (k) de propágulos que permanecem até l_cel metros da planta progenitora; em vermelho o predito.

Parece que há boa congruência entre o observado e o predito pelo modelo, segue regressão dos resíduos do modelo:

```{r graf residuo d }
ggplot(df_reg,aes(x=.fitted,y=std.resid)) + 
  geom_point() +
  geom_smooth(method = "loess") + 
  facet_wrap(~k,ncol=3,scales="free")
```

__Figura 2.1__ standard resíduos ~ ajustado

```{r graf residuo d 1}
ggplot(df_reg,aes(x=.fitted,y=sqrt.std.resid)) + 
  geom_point() +
  geom_smooth(method = "loess") + 
  facet_wrap(~k,ncol=3,scales="free")
```

__Figura 2.2__ sqrt standard resíduos ~ ajustado

_Tabela efeitos estimados na escala padrão (não na escala log)_

```{r effects glmm d}
(df_effect <- data.frame(par.class = c("beta",rep("alfa",length(levels(df_resultados$k)) ) ),
                        par.VE = c("DA.z",
                                   paste("k=",levels(df_resultados$k),sep="")),
                        par.value = c(exp(fixef(l_md[[1]])[13]),
                                      exp(fixef(l_md[[1]])[1]),
                                      exp(fixef(l_md[[1]])[2:12]-fixef(l_md[[1]])[1]))
                        ))

## falta estimar os intervalos de confiança ##
```

### A partir daqui trabalho a ser feito ###

0) Continuar análise de d - distância média de dispersão

d) avaliação do modelo selecionado
e) estudo das estimativas e interpretação



1) I = número fundamental da imigração (Etienne 2005)

a) avaliar qual a melhor distribuição de probabilidade
b) avaliar função de ligação
c) seleção de modelos
d) avaliação do modelo selecionado
e) estudo das estimativas e interpretação

2) dGOF = delta GOF = log(GOF_EE / GOF_EI)
- quantas vezes melhor EE pode ser melhor que EI

a) avaliar qual a melhor distribuição de probabilidade
b) avaliar função de ligação
c) seleção de modelos
d) avaliação do modelo selecionado
e) estudo das estimativas e interpretação

3) U = probabilidade de especiação segundo modelo EE

a) avaliar qual a melhor distribuição de probabilidade
b) avaliar função de ligação
c) seleção de modelos
d) avaliação do modelo selecionado
e) estudo das estimativas e interpretação

### dGOF ###

- para explorar uma variável que é a relação entre os GOFs do modelo é necessário 'remover' os zeros observados pois: i) quando dividmos por zero temos uma indeterminação; e ii) quando zero é divido por algo perdemos a variação desse valor pois todos vão para zero.
- uma maneira de lidar com isso é somar a todos os valores o maior observado de GOF, 100. Assim a variável varia de 100 até 200
- seguimos com dGOF = EE/EI

#### Análise exploratória ####

```{r graf exp dGOF 1}
## data frame
df_ad <- df_resultados %>% select(Site,p,k,k.z,DA,S,S.z,MN,U,GOF) %>% 
  spread(key=MN,value=GOF) %>% mutate(EE0 = EE + 100, EI0 = EI + 100) %>% 
  mutate(dGOF = EE0/EI0,
         orGOF = (EE/100-EE) / (EI/100-EI),
         log.dGOF = log(dGOF),
         log.orGOF = log(orGOF),
         JM = 500 * p * DA, 
         theta = U * (JM-1) / (1-U))
## graficos
df_ad %>% select(Site,p,k,dGOF,log.dGOF) %>% reshape2::melt(id.vars = c("Site","p","k"), variable.name="GOF.type",value.name="GOF.value") %>%
  ggplot(aes(y=GOF.value,x=p,color=GOF.type)) +
  geom_point() +
  facet_wrap(~k,ncol=3)
```

__Figura__ Graf exp dGOF e log.dGOF


```{r graf exp dGOF 2}
df_ad %>% ggplot(aes(y=dGOF_EI,x=p)) +
  geom_point() +
  labs(y="EE/EI") +
  facet_wrap(~k,ncol=3)
```

__Figura__ Graf exp dGOF EE/EI

- vou seguir com dGOF = EE/EI
- Alternativamente posso utilizar a razão de chance: 