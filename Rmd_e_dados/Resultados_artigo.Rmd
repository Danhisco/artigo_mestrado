---
title: "Resultados - artigo"
author: "Mori, Danilo Pereira"
date: "21 de maio de 2018"
output: html_document
---

```{r setup, include=FALSE} 
knitr::opts_chunk$set(echo = FALSE, tidy = TRUE, include = TRUE, warning = FALSE,cache = TRUE)
```

```{r dados e pacotes,warning=FALSE,message=FALSE,echo=FALSE}
library(reshape2)
library(arm)
library(gridExtra)
library(MuMIn)
library(doMC)
library(bbmle)
library(lme4)
library(merTools)
library(ggplot2)
library(broom) 
library(magrittr)
library(DHARMa)
library(plyr)
library(dplyr)
library(tidyr)
library(purrr)
```

```{r organização dos dados}
df_resultados <- readr::read_csv("/home/danilo/Documentos/Doutorado/artigo_mestrado/Rmd_e_dados/df_resultados.csv")
# df_resultados %>% str
df_resultados$MN <- factor(df_resultados$MN,levels = c("EI","EE"))
df_resultados$SiteCode <- factor(df_resultados$SiteCode)
df_resultados$k <- factor(df_resultados$k,levels=unique(df_resultados$k))
# df_resultados$k %>% contrasts()
# df_resultados$MN %>% contrasts()

#### z score ###

f_z <- function(x){
  m <- base::mean(x,na.rm=TRUE)
  sd <- sd(x,na.rm=TRUE)
  output <- (x-m)/sd
  return(output)
} 

df_resultados %<>% mutate(GOF.z = f_z(GOF),
                          DA.z = f_z(DA),
                          p.z = f_z(p),
                          S.z = f_z(S),
                          U.z = f_z(U),
                          m_.z = f_z(m_),
                          I.z = f_z(I),
                          d.z = f_z(d),
                          k.z0 = as.numeric(as.character(k)),
                          k.z = f_z(k.z0))

names(df_resultados)[1] <- "Site"
```


<!--
Ideia geral dos métodos:

i) estabelecer valores do parâmetro de dispersão a priori;
ii) estimar taxa de especiação necessária para manter a riqueza no equilíbrio a partir do método de MNEE
iii) simular SADs neutras segundo MNEI e MNEE a partir dos mesmo parâmetros
-->

## Estrutura dos Resultados Completos: ##

I) parâmetros de dispersão:

  a) distância média de dispersão (d)

  b) número fundamental da dispersão (I)
- com isso podemos avaliar quais as situações biológicas de limitação à dispersão que a simulação está ocorrendo para os dois modelos neutros
<!--
distância média de dispersão ~ k * p + (k|Site) ou k_factor * p + (1|Site) [modelo completo se houver mais níveis de k e estiverem igualmente espaçados - segunda etapa] 
-->

II) Congruência do predito com o observado
- a ideia central do artigo é: "Avaliar se a SAD pode ser evidência suficiente para refutar neutralidade"
- assim optei por mudar a variável de congruência de GOF, que avalia quantas predições neutras foram refutadas por cenário neutro
- para n_ref = número de predições neutras refutadas por cenário neutro

III) taxa de especiação necessária para manter a riqueza observada no equilíbrio dinâmico segundo um modelo neutro espacialmente explícito (U)
- a teoria neutra pode ser uma boa aproximaçaõ para descrever a taxa de extinção de espécies raras em ambientes fragmentados
- o modelo neutro coalescente é uma boa aproximação para descrever o comportamento dos sistemas biológicos em diferentes contextos de fragmentação (Campos et al.)
- no modelo coalescente o equilíbrio dinâmico é observado, nesse cenário a taxa de surgimento de singletons por evento de morte se igual à taxa de extinção de singletons
- assim, a estimativa de taxa de especiação necessária para manter a riqueza observada no equilíbrio pode ser uma aproximação da taxa de extinção das espécies raras na paisagem.

IV) Anexo 1: código auxiliar
- segue a mesma ordem das variáveis
- é o local onde eu desenvolvo a análise dos dados


Notas: até o momento desenvolvi parte da análise dos dados para I.A

<!-- Esqueleto dos resultados 1

a) MNEI por verossimilhança
-GOF) Se MNEI tiver seus parâmetros livres ele sempre apresentara boa congruência com o observado?
-theta) Se o ajuste dos parâmetros informa algo além da SAD em si, esperamos observar efeito positivo de p, pois para maiores coberturas vegetais há mais indivíduos na região biogeográfica.
-m) Idem, esperamos observar efeito positivo de p, uma vez que quanto menor a cobertura vegetal de uma paisagem menor a concetividade entre as manchas de habitat (REFERÊNCIA)

b) Conversão de parâmetros de imigração
-par{MNEI} -> par{MNEE} [parâmetros com maior interpretação biológica - que permite a parametrização a partir de valores observados]
-distância médias de dispersão -> m segundo uma simulação coalescente em paisagem fragmentada.

c) Estimando U a partir de uma simulação coalescente
- 20 valores de U a partir de cada nível de d [MM]
- U -> theta, pela formula de conversão de theta [MM]
- U ~ p * d + (d | Site) [ou a formula que estamos utilizando]

d) Congruência do observado entre os modelos neutros consideramos mesmo conjunto de parâmetros
[MM]: estabelecemos distâncias de dispersões segundo diferentes cenários de limitação à dispersão médio (d), que parametrizados com valores observados na natureza para diferentes sindromes de dispersão. Para cada nível de d estimamos a taxa de especiação necessária para manter a riqueza observada, sob a hipótese de equilíbrio dinâmico, (U - singleton/evento de morte) segundo MNEE. Utilizamos o par U e d para gerar SADs segundo MNEE e convertemos U e d em theta e m, respectivamente, para gerar SADs segundo MNEI. Para cada MN geramos 100 SADs réplicas que comparamos com a respectiva SAD observada pelo teste de Kolmogorov-Smirnov; contabilizamos o número de vezes que não foi possível refutar a hipótese nula de que a SAD réplica e SAD observada são amostras de uma mesma distribuição teórica na variável GOF (Goodness-of-fit). Temos 80 sítios de amostragens, 30 rodadas de simulação para cada nível de MN (EE e EI).

- GOF ~ p * d * MN + (d | Site / MN)
MN: factor 2 levels: EE, EI
d: numeric 30 valores para todas as simulações

e) Parâmetro a posteori: espécies input (Condit et al. 2012)
- spp_I ~ p * d + (d|Site)
- GOF ~ spp_I * d * MN + (d | Site / MN)


-->



<!-- última paragráfo de material e métodos

Organizamos os resultados em 3 blocos de dados, aqueles para MNEE, MNEI e MNEE + MNEI. As variáveis resposta são: GOF, $\theta$, m, U, spp_I e d. As variáveis indepedentes são cobertura vegetal (p) e função de dispersão, que está sendo expressa de forma categorica(k), assim, podemos avaliar tanto os dados de MNEE, quanto para MNEE + MNEI; e de forma contínua d (distância média de dispersão da função de dispersão), para os dados de MNEE. Convertemos os parâmetros de MNEE U e d em $\theta'$, m'; e $\theta$ e m de MNEI em  U' e (d' e k'), considerando que $J_M$ = número de indivíduos na paisagem. Quando houve mais de uma observação para um mesmo Sítio de amostragem, então utilizamos a variável Sítio como variável categórica dos efeitos aleatórios do modelo linear; quando a função de dispersão foi categória utilizamos (1|Site) e  (d|Site) se ela foi contínua. Assim, temos duas maneiras de partir a variação prevista pelo modelo. O $R_m^2$ é a variação explicada pelos efeitos fixos do modelo, ou seja, p e/ou a variável relacionada à limitação à dispersão (k ou d) ('R quadrado marginal'); já o R quadrado condicional, $R_c^2$, é a variação associado tanto às variáveis de efeito fixo quanto ao efeito aleatório (sítio de amostragem). 
Acredito que uma métrica de comparação entre $R^2$ para GLM e GLMM seria considerar a razão $R_{GLMM}^2 = R_m^2 / R_c^2$? -->

<!--
## Sessão antiga, 18jun ##
Introdução da sessão de resultados:

Vou explorar o terceiro bloco de dados c(MNEE, MNEI), em anexo a análise dos dados para o conjunto de dados MNEE e MNEI. MNEE e MNEI diferem na forma que implementam a teoria neutra e na forma com que estimam os parâmetros a priori simulação. Assim, unir os resultados em uma mesma análise de dados tem que ser feita considerando a origem dos dados, para adequar com os resultados de MNEE organizei os dados pela proporção da chuva de propágulos que permanece até a área imediata a da copa da árvore progenitora (l_cel metros). Incluindo os dados de MNEI, são 13 níveis na variável "k", o primeiro nível é aquele com cenário de limitação à dispersão mais rigoroso (=0.99), o penúltimo nível é o cenário de limitação à dispersão menos realista (=0.25) e o último nível são os dados de MNEI. Em análise exploratória observamos que mesmo com valores razoáveis de m, MNEI apresentou d's superiores ao de MNEE em escala log (anexo) e como d está relacionado com a proporção de propágulos até a área imediata da planta progenitora (k) ordenei os níveis de "k" agrupando os valores de MNEI juntos no último nível. Existe grande variação no parâmetro 'm' estimado por verossimilhança, contudo, essa variação não apresenta efeito de p (anexo), então, não considerar a variação interna de m em MNEI não deve interferir na análise dos dados. Em anexo, há as análises auxiliares que inclui dos outros conjuntos de dados.
i) Os dois modelos conseguem apresentar boa congruência com o observado? 
ii) Se sim quais as característica da paisagem e da relação com a área amostrada que propiciam esse resultado? 
iii) Em cenários de limitação à dispersão biologicamente realistas o modelo neutro apresente boa congruência com os dados?
iv) Qual o efeito da fragmentação na diversidade da paisagem segundo o predito neutro?


## Esqueleto dos resultados - 18jun ##

a) resultados para os parâmetros de imigração para as distâncias simuladas: m, I e k. Tentar incluir os valores estimados em campo
b) v ~ p * par_imig + S + (par_imig | Site); par_imig = d, m, I, k
c) GOF ~ p * MN * par_imig + S + (par_imig | Site / MN) 


-->
<!--
Para faciltar o ajuste dos modelos mistos aplicamos a transformação z nas variáveis contínuas: 
-->

#### Anexo 1: código auxiliar ####

##### I) parâmetros de dispersão #####
__I.A) distância média de dispersão (d)__

Exploração gráfica

```{r graf d}
# x11()
par(mfrow=c(3,2))
## d e d.z ##
# ~ norm
qqp(df_resultados$d, "norm",ylab="d (metros)") 
qqp(df_resultados$d.z, "norm",ylab="d.z (Z(d))") 
# ~ lnorm
qqp(df_resultados$d, "lnorm",ylab="d (metros)")
qqp(df_resultados$d.z, "lnorm",ylab="d.z (Z(d))")
# ~ gamma
fit_gamma1 <- fitdistr(df_resultados$d, "gamma")
qqp(df_resultados$d, "gamma", shape = fit_gamma1$estimate[[1]], rate = fit_gamma1$estimate[[2]],ylab="d (metros)")
## d.z ##
# ~ norm
# ~ lnorm
# ~ gamma
```

Figura A1. Gráficos quantile-quantile para três distribuições teóricas (normal, lognormal e gamma) e a variável d (metros) e z-transformada (d.z). Para a distribuição gamma utilizei ajustamos apenas a variável d, uma vez que o domínio da distribuição não contempla valores menores do que zero.

A distribuição que melhor se adequa aos dados é a distribuição gamma: i) ajusta maior porção dos dados em comparação com a normal (segunda melhor distribuição) e ii) consegue capturar a variação nas caudas da distribuição de valores obervados (em especial para valores pequenos), diferente da normal. Contudo, para comparar os resíduos eu vou construir duas classes de modelos cheio: uma normal e outra gamma.

O objetivo é avaliar o efeito da variável k na distância média de dispersão (d), para isso o modelo cheio vai considerar a variável DA, uma vez que k é definido como a proporção de propágulos até l_cel metros da planta progenitora. A largura da célula de simulação (l_cel) = 100/sqrt(DA) (PERGUNTA:devo utilizar DA ou a transformação de DA = I( 100/sqrt(DA) )? ).

_Tabela Seleção da distribuição de probabiliade e estrutura aleatória_

```{r d k}
# df_resultados %>% str
## Seleção da estrutura eleatória ##
l_md <- vector("list",length = 8)
names(l_md) <- c("Gamma 1|Site","Gamma k|Site",
                 "log.Gamma 1|Site","log.Gamma k|Site",
                 "normal 1|Site","normal k|Site",
                 "log.normal 1|Site","log.normal k|Site")
l_md[[1]] <-  glmer(d ~ k + DA.z + (1|Site),family = "Gamma",data = df_resultados)
l_md[[2]] <-  glmer(d ~ k.z + DA.z + (k.z|Site),family = "Gamma",data = df_resultados)
l_md[[3]] <-  glmer(d ~ k + DA.z + (1|Site),family = "Gamma"(link=log),data = df_resultados)
l_md[[4]] <-  glmer(d ~ k.z + DA.z + (k.z|Site),family = "Gamma"(link=log),data = df_resultados)
l_md[[5]] <-  glmer(d ~ k + DA.z * (1|Site),family = "gaussian",data = df_resultados)
l_md[[6]] <-  glmer(d ~ k.z + DA.z + (k.z|Site),family = "gaussian",data = df_resultados)
l_md[[7]] <-  glmer(d ~ k + DA.z + (1|Site),family = "gaussian"(link=log),data = df_resultados)
l_md[[8]] <-  glmer(d ~ k.z + DA.z + (k.z|Site),family = "gaussian"(link=log),data = df_resultados)
AICctab(l_md,weights=T)
```
<!--
A estrutura aleatória selecionada foi (1|Site).
-->

O modelo global com distribuição gamma, função de ligação log e estrutura aleatória 1|Site foi o mais plausível. Segue sumário:

```{r d k R2,echo=TRUE}
fastdisp(l_md[[3]]) # problema de convergência, indicam para reescalonar as variáveis
```
<!--
Error: Error in r.squaredGLMM.merMod(X[[i]], ...) : do not know how to calculate variance for this family/link combination
27jun2018[Válido para lmer, não para normal link=log: acredito que se houver mais níveis de k e melhor distribuidos no campo de parâmetros aumentaria o R^2 de k|Site
-->


_31jun2018_
- Problema de convergência:
convergence code: 0
Model is nearly unidentifiable: very large eigenvalue
 - Rescale variables?
ajuda: ?convergence

"
if you do see convergence warnings, and want to trouble-shoot/double-check the results, the following steps are recommended (examples are given below):

double-check the model specification and the data for mistakes

center and scale continuous predictor variables (e.g. with scale)

check for singularity: if any of the diagonal elements of the Cholesky factor are zero or very small, the convergence testing methods may be inappropriate (see examples)

double-check the Hessian calculation with the more expensive Richardson extrapolation method (see examples)

restart the fit from the apparent optimum, or from a point perturbed slightly away from the optimum

try all available optimizers (e.g. several different implementations of BOBYQA and Nelder-Mead, L-BFGS-B from optim, nlminb, ...) via the allFit() function, see ‘5.’ in the examples. While this will of course be slow for large fits, we consider it the gold standard; if all optimizers converge to values that are practically equivalent, then we would consider the convergence warnings to be false positives.
"


A única variável contínua que não foi rescalonada foi a resposta d, se aplicar transformação z em d, a variável resposta terá números negativos. Utilizando a variável DA ao inves de DA.z piora o caso. Alternativamente busquei simplificar o modelo: a) retirando a variável DA.z; e b) retirando o último nível de k (contudo como é um factor não há de fazer muita diferença) - para ambos não houve melhora.

PRÓXIMOS PASSOS PARA MELHORAR AJUSTE: uma alternativa fácil é reajustar a partir das estimativas feitas pelo modelo com problema de convergência e/ou modificar o otimizador.
PERGUNTAS NORTEADORAS: i) o aviso de problema de convergência é um falso positivo? 

Ben Bolker: Since the likelihood differs by <0.1 between the model fits, and the largest relative differences in the parameters are of the order of about 10^(-4), I would say that you have successfully demonstrated that the warning is a false positive and you can proceed with your initial model.


<!--
[pasta GLMM (...) scale issues] Some common examples:

-Some columns of our data might be different orders of magnitude to others, for instance gender might be encoded as a binary variable, while income might be stored in whole-dollar amounts.

-An outcome might be extremely rare

-The impact of variable X1 on Y could be orders of magnitude greater than the impact of variable X2. That is, it’s not the scale of the data that is causing issues so much as the scale of the parameters.


-->


Foram estimados 13 parâmetros e seus respectivos erro-padrão. Os resíduos escalonados variam de -3.956 até 6.554, pelos valores dos quantils parece que a distribuição dos resíduos não é simétrica ao redor da estimativa. Há dois avisos sobre convergência: a) Model failed to converge with max|grad|=4.11797 (tol = 0.001, component 1); b) Modelo is nearly unidentifiable: very large eigenvalue - Rescale variables?

25jun2018:
Para lidar com b modifiquei DA -> DA.z nos modelos globais
Com isso obtive o erro: 'converge code:0; Model is nearly unidentifiable: very large eigenvalue - Rescale variables?
- a transformação z de DA deveria ser o suficiente para lidar com problemas relacionados com escalamento de variáveis; a outra variável explanatória é categórica.
- vou continuar o estudo com esse modelo como global

_Tabela Selecao de variaveis para descrever 'd'_

```{r selecao d}
l_md <- vector("list",length = 4)
names(l_md) <- c("k+DA","DA","k","1")
l_md[[1]] <-  glmer(d ~ k + DA.z + (1|Site),family = "Gamma"(link=log),data = df_resultados)
l_md[[2]] <-  glmer(d ~ DA.z + (1|Site),family = "Gamma"(link=log),data = df_resultados)
l_md[[3]] <-  glmer(d ~ k + (1|Site),family = "Gamma"(link=log),data = df_resultados)
l_md[[4]] <-  glmer(d ~ 1 + (1|Site),family = "Gamma"(link=log),data = df_resultados)
AICctab(l_md)
```

O modelo global foi o mais plausível. [PROBLEMA DE CONVERGÊNCIA]. E por conta disso não consigo avaliar o ajuste visualmente:

```{r echo=TRUE}
# prof_glmm.d <- profile(l_md[[3]])

# xyplot(prof_glmm.d , aspect =1.3)
```

__Coeficiente de determinação__

```{r}
r.squaredGLMM(md_d)
```



Avaliação gráfica do ajuste do modelo:

```{r predito e observado d}
df_reg <- broom::augment(l_md[[1]])
df_reg %<>% mutate(predito = exp(.fitted),
                   std.resid = .resid/sd(.resid),
                   sqrt.std.resid = sqrt(std.resid))
## observado e predito ##
df_reg %>%  ggplot(aes(x=DA.z,y=d)) + geom_point() +
  geom_line(aes(y=predito),color="red") + facet_wrap(~k,ncol=3,scales="free")
```

__Figura 1__ Distância média de dispersão (d) e o predito segundo d ~ DA.z + k + (1 | Sítio), family=Gamma. Os pontos são as distâncias médias estimados para o determinado percentil (k) de propágulos que permanecem até l_cel metros da planta progenitora; em vermelho o predito.

Parece que há boa congruência entre o observado e o predito pelo modelo, segue regressão dos resíduos do modelo:

```{r graf residuo DHARMA }
md_d <- l_md[[3]]
resid_d <- simulateResiduals(md_d,n=1000)
# plotResiduals(resid_d)
```

__Figura 2.1__ residuos quantílicos pelo predito




O modelo estimado está de acordo com os dados: a predição do modelo está precisa na tendẽncia central dos dados; o modelo explica praticamente toda a variação dos dados (alto R2_). O problema de convergência pode ser que não é necessário considerr a existência de correlação dos dados, talvez seja mais plausível considerar apenas um glm:

```{r comparacao glm e glmm d }
l_md <- vector("list",2)
names(l_md) <- c("glm","glmm")
l_md[[1]] <-  glm(d ~ k + DA.z,family = "Gamma"(link=log),data = df_resultados)
l_md[[2]] <-  glmer(d ~ k + DA.z + (1|Site),family = "Gamma"(link=log),data = df_resultados)
# AICctab(l_md,weights=T)
# summary(lm(coef(l_md[[1]]) ~ fixef(l_md[[2]])-1))
md_d <- glm(d ~ k + DA.z,family = "Gamma"(link=log),data = df_resultados)
```

O único modelo plausível é o glmer, contudo não há diferença nas estimativas dos dois modelos. Então vou utilizar o glm para fazer a inferência. Vou plotar a variável de interesse é k mas não a covariável DA.z

```{r tabela das estimativas do glm, message=F}
# summary(md_d)
ef_d <- sim(md_d,1000)@coef[,1:12]
ef_d <- cbind(ef_d[,1], apply(ef_d[,2:12],2,function(x) ef_d[,1]+x)) %>% as.data.frame()
names(ef_d) <- as.character(c(0.99,seq(0.95,0.5,by=-0.05),0.25))
inv.link <- family(md_d)$linkinv
df_ef.d  <- melt(ef_d,value.name = "replica") %>% 
  ddply(.,"variable",summarise, media0 = mean(replica),lwr0 = quantile(replica,0.025),upr0=quantile(replica,0.975)) %>% 
  mutate( media = inv.link(media0), IC.975 = inv.link(upr0), IC.025 = inv.link(lwr0))
df_ef.d[,c(1,5:7)] #%>% ggplot(aes(x=variable,y=media,ymin=IC.025,ymax=IC.975)) + geom_pointrange() # existe grande variação entre sítios que é explicada em função da densidade
```

<!--
1) I = número fundamental da imigração (Etienne 2005)

a) avaliar qual a melhor distribuição de probabilidade
b) avaliar função de ligação
c) seleção de modelos
d) avaliação do modelo selecionado
e) estudo das estimativas e interpretação
-->

## 2) GOF - número de SADs preditas que não foram refutadas ##

a) avaliar qual a melhor distribuição de probabilidade
b) avaliar função de ligação
c) seleção de modelos
d) avaliação do modelo selecionado
e) estudo das estimativas e interpretação

- a combinação entre distribuição de probabilidade e função de ligação canonica para porcentagem é a distribuição binomial com a função de ligação logito
-> exploração gráfica

__EFEITOS FIXOS__

```{r GOF exp graf funcao de ligacao logito}
## remoção de 0 e 100 ##
df_ad <- df_resultados
df_ad$GOF[df_ad$GOF==0] <- 0.01
df_ad$GOF[df_ad$GOF==100] <- 99.99
## transformação logito ##
df_ad %<>% mutate(lGOF = log((GOF/100)/(1-(GOF/100)) ))
# df_ad$lGOF %>% summary
## gráfico ##
print(
    ggplot(df_ad,aes(x=p,y=lGOF,color=MN)) +
      geom_point() +
      geom_smooth(method = "lm",se=FALSE) +
      facet_wrap(~k,ncol=3) +
      labs(title="~ p * k * MN") +
      scale_colour_manual(values = c("Blue", "Red"))
)
```

__Figura 1__ logito de GOF ~ p * k * MN 

- para o cenário com menor limitação à dispersão (k=0.25) parece que a linearização de GOF para o modelo EI não é uma boa aproximação, provavelmente o padrão de resíduos não vai ser muito 'comportado'

__EFEITOS ALEATÓRIOS__

- 1|Site

```{r GOF graf exp 2 logito pela estrutura aleatoria1,fig.height=8,fig.width=8}
df_ad %>% mutate(p.class = cut(p,12)) %>% ggplot(aes(x=Site,y=lGOF)) +
  geom_jitter() +
  geom_boxplot() +
  coord_flip() +
  theme(axis.text.y = element_blank(),axis.ticks = element_blank(), legend.position="bottom") +
  facet_wrap(~p.class,ncol=3,scales="free_y")
```

__Figura 2.1__ logito de GOF ~ site (~p.class)

- MN|Site

```{r GOF graf exp 2 logito pela estrutura aleatoria 2,fig.height=8,fig.width=8}
mutate(df_ad,p.class = cut(p,12)) %>% ggplot(aes(x=Site,y=lGOF,color=MN)) +
  geom_jitter() +
  geom_boxplot() +
  coord_flip() +
  theme(axis.text.y = element_blank(),axis.ticks = element_blank(), legend.position="bottom") +
  facet_wrap(~p.class,ncol=3,scales="free_y")
```

__Figura 2.1__ logito de GOF ~ MN * Site (~p.class)

- como efeito aleatório vamos considerar um intercepto por observações agrupadas por Sítio de amostragem (Site)

__Escolha da estrutura aleatória__

- o modelo cheio vai apresentar interação entre as três variáveis: p + k + MN + p:k + p:MN + MN:k + p:k:MN
- vou avaliar duas possíveis estruturas aleatórias: 1 | Site e MN | Site
- obtive erro de convergência: Model failed to converge with max|grad| = 0.00126561 (tol = 0.001, component 1)
- ao acrescentar " control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)) " não obtive mais erro de convergência


```{r GOF escolha estrutura aleatoria}
l_md <- vector("list",2)
names(l_md) <- c("1|Site","MN|Site")
l_md[[1]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (1|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[2]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
AICctab(l_md,weights=T)
```

- a estrutura aleatória que considera que há um intercepto para cada modelo neutro por sítio de amostragem é aquela mais plausível
- alternativamente poderiamos considerar k | Site, contudo seria estimado 1 intercepto para cada duas observações. 1|Site corresponde ao ajustar 1 intercepto para cada 24 observações e MN para cada 12. Na prática a diferença entre 1|Site e MN|Site é de dois parâmetros.
- vou ajusta-lo e seguir o protocolo de avaliação de Bolker et al. (2008)
1) Checagem gráfica: 
i) variância dos dados é homogêneo entre as catergórias? Considerando os efeitos fixos, a variância parece ser homogênea para todos os casos menos quando consideramos o modelo EI, k=0.25 para todo o p
ii) a resposta é linear com relação ao preditor contínuo? Para a classe citada acima os dados particulamente não se adequam à uma linha com relação à p
iii) A distribuição de valores dentro do grupos corresponde à distribuição de probabilidade escolhida? Diria que a resposta é: corresponde suficientemente à distribuição escolhida? Para responder isso vou avaliar os resíduos do modelo escolhido

__Diagnóstico do modelo cheio selecionado__

Reunião 11 de outubro de 2018:

PI recomendou utilizar resíduos quantílicos para diagnosticar o modelo cheio. O pacote DHARMa oferece a possibilidade de utilizar esse recurso

```{r GOF diag1}
residuos_GOF <- simulateResiduals(fittedModel = l_md[[2]], n = 1000)
plot(residuos_GOF)
```

__Figura 3.1__ Resíduos quantílicos: 1o gráfico qq-plot e teste de aderência dos resíduos com o esperado segundo uniformidade com a distribuição teórica (teste de Kolmogorov-Smirnov); 2o gráfico resíduos contro o previsto, linhas são da regressão quantílica (0.25, 0.50, 0.75) 

- o teste de uniformidade mostra que desvio é significativo apontando para o modelo não prediz corretamente as observações
- o gráfico dos resíduos conra os valores previstos indica que a variação não está igualmente distribuida (como se pode ver pelas regressões quantílicas)

```{r GOF diag2,fig.width=10,fig.height=4}
df_reg <- df_resultados %>% mutate(GOF_q.resid = residuos_GOF$scaledResiduals)
l_p <- vector("list",3)
l_p[[1]] <- ggplot(df_reg,aes(x=p.z,y=GOF_q.resid)) +
  geom_point() +
  geom_smooth(method="loess") +
  labs(y="residuos")
l_p[[2]] <- ggplot(df_reg,aes(x=MN,y=GOF_q.resid)) +
  geom_jitter() +
  geom_boxplot() +
  labs(y="")
l_p[[3]] <- ggplot(df_reg,aes(x=k,y=GOF_q.resid)) +
  geom_jitter() +
  geom_boxplot() +
  labs(y="")
do.call("grid.arrange",c(l_p,ncol=3))
# grid.arrange(l_p[[1]],l_p[[2]],l_p[[3]],l_p[[4]],
#              layout_matrix=rbind(c(1,2,3),
#                                  rep(4,3),
#                                  rep(4,3) )
#              )
```

__Figura 3.2__ resíduos contra as variáveis preditoras

```{r GOF diag3}
ggplot(df_reg,aes(x=p.z,y=GOF_q.resid,color=MN)) +
  geom_point() +
  geom_smooth(method="loess") +
  labs(y="residuos") +
  theme(legend.position = "bottom") +
  facet_wrap(~k,ncol=4)
```

__Figura 3.3__ resíduos contra as variáveis preditoras p * MN * k

```{r GOF diag4}
ggplot(df_reg,aes(x=MN,y=GOF_q.resid)) +
  geom_jitter() +
  geom_boxplot() +
  labs(y="residuos") +
  facet_wrap(~k,ncol=4)
```

__Figura 3.4__ resíduos contra as variáveis preditoras MN * k

- uma vez que o modelo cheio não apresentou bom ajuste com os valores observados, então irei explorar alternativas. Primeiramente irei explorar outras funções de ligação e em seguida buscar outras distribuições teóricas

__Seleção do modelo cheio 2: logit, probit e cloglog__

```{r GOF escolha estrutura aleatoria}
l_md <- vector("list",6)
names(l_md) <- c("l 1|Site","l MN|Site", 
                 "p 1|Site","p MN|Site", 
                 "c 1|Site","c MN|Site")
l_md[[1]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (1|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[2]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[3]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (1|Site), family = "binomial"(link = probit),data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[4]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (MN|Site), family = "binomial"(link = probit),data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[5]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (1|Site), family = "binomial"(link = cloglog),data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[6]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (MN|Site), family = "binomial"(link = cloglog),data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
AICctab(l_md,weights=T)
```

o modelo com a função de ligação cloglog foi o único modelo plausível. O diagnóstico do modelo:

```{r diag GOF cloglog1}
l_residuos <- llply(l_md[c(2,4,6)],function(x) (simulateResiduals(fittedModel = x, n=1000)))
plot(l_residuos[[3]])
```

__Figura 3.5__ Resíduos quantílicos do modelo binomial mais plausível (cloglog)

Os resíduos quantílicos não apresentam boa aderência ao padrão de uniformidade como mostra o teste KS que aponta que o desvio é significante. Para comparação vou plotar os gráficos dos testes de uniformidade para os três modelos binomiais:

```{r GOF diag uniformidade tres binom}
par(mfrow=c(3,1))
l_ply(l_residuos,function(x) plotQQunif(x))
```

__Figura 3.6__

### Comentário sobre GOF ###

  Apesar dos resíduos quantílicos de GOF apresentarem desvio significativo da uniformidade, devido a inflação de zeros, iremos prosseguir com o modelo logito para avaliar os resultados. Concomitantemente iremos investigar como lidar com a infação de zeros, mas quero preparar o script para analisar os dados.
  
__Seleção do modelo mais plausível__
<!--
Hipóteses a priori:

I) a SAD não é suficiente para refutar neutralidade.
I.P) portanto, qualquer modelo neutro apresenta boa congruência com o observado independentemente se a SAD observada foi amostrada em contexto ecológio onde o pressuposto de neutralidade não é uma boa aproximação e assim para todo gradiente de cobertura vegetal.

II) nenhum modelo neutro é suficiente para explicar a SAD observada em um gradiente natural de cobertura vegetal.
II.P) portanto quanto maior a cobertura vegetal melhor a congruência do observado e predito por um modelo neutro.

III) a estrutura espacial da paisagem é necessária para descrever a SAD. 
III.P) portanto o modelo neutro de espaço explícito (EE) apresenta melhor congruência com o observado do que o modelo neutro de espaço implícito (EI).

IV) um modelo neutro é suficiente para descrever a SAD se corretamente aproximar o processo de limitação à dispersão
IV.P.a) portanto, existe um valor ótimo de limitação à dispersão onde observamos a maior congruência com o observado
IV.P.b) portanto, se a fragmentação da paisagem modificar a limitação à dispersão 

-->

```{r GOF selecao de modelos}
l_md <- vector("list",19)
names(l_md) <- c("p*k*MN",# modelo cheio
                 "p*k*MN-p:k:MN", #MC - 3a ordem
                 "p*(k+MN)","k*(p+MN)","MN*(p+k)", #2 interações
                 "p*k+MN","p*MN+k","k*MN+p", #1 interação + preditor
                 "p*k","p*MN","k*MN", #1 interação
                 "p+k+MN",#aditivo 3
                 "p+k","p+MN","k+MN", #aditivo 2 
                 "p","k","MN", #preditor isolado
                 "1") #nulo
#modelo cheio
l_md[[1]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
#modelo cheio - interação 3a ordem
l_md[[2]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN - p.z:k:MN + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
#2 interações
l_md[[3]] <- glmer(cbind(GOF,100-GOF) ~ p.z * (k + MN) + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[4]] <- glmer(cbind(GOF,100-GOF) ~ k * (p.z + MN) + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[5]] <- glmer(cbind(GOF,100-GOF) ~ MN * (p.z + k) + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
#1 interação + preditor
l_md[[6]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k + MN + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[7]] <- glmer(cbind(GOF,100-GOF) ~ p.z * MN + k + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[8]] <- glmer(cbind(GOF,100-GOF) ~ k * MN + p.z + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
#1 interação
l_md[[9]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k + (1|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[10]] <- glmer(cbind(GOF,100-GOF) ~ p.z * MN + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[11]] <- glmer(cbind(GOF,100-GOF) ~ k * MN + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
#aditivo 3
l_md[[12]] <- glmer(cbind(GOF,100-GOF) ~ p.z + k + MN + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
#aditivo 2
l_md[[13]] <- glmer(cbind(GOF,100-GOF) ~ p.z + k + (1|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[14]] <- glmer(cbind(GOF,100-GOF) ~ p.z + MN + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[15]] <- glmer(cbind(GOF,100-GOF) ~ k + MN + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
#aditivo 1
l_md[[16]] <- glmer(cbind(GOF,100-GOF) ~ p.z + (1|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[17]] <- glmer(cbind(GOF,100-GOF) ~ k + (1|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[18]] <- glmer(cbind(GOF,100-GOF) ~ MN + (MN|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
# nulo
l_md[[19]] <- glmer(cbind(GOF,100-GOF) ~ 1 + (1|Site), family = "binomial",data=df_resultados,
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
AICctab(l_md,weights=T)
```

O modelos cheio foi o único modelo plausível somando peso de evidência próximo de 1.

### roteiro merTools ###

-Sumário do modelo:

```{r md_GOF sumario}
md_GOF <- l_md[[1]]
fastdisp(md_GOF)
```

Pontos para avaliação:

i) o erro padrão das estimativas dos coef está baixa com relação a seus valores (quais seriam valores altos?);
ii) o desvio padrão estimado para a estrutura aleatória indica que existe grande variância dentro das categórias (PESQUISAR MELHOR ESSA QUESTÃO)
iii) a correlação intra estrutura aleatória é baixa (pesquisar segundo ponto)

- gráficos dos coeficientes com os erros padrão

PESQUISAR: confint.merMod

"An alternative is to simulate values of the fixed effects from the posterior using the function arm::sim. Our next tool, FEsim, is a convenience wrapper to do this and provide an informative data frame of the results."

```{r md_GOF simulate values fixed effects}
# simulacao
fe_GOF <- FEsim(md_GOF,n.sims = 1000)
# fe_GOF
# grafico
plotFEsim(fe_GOF,stat = "mean") + theme_bw() + labs(y="taxa de GOF",x="média do efeito estimado")
```

__Figura 4__ Mediana dos efeitos estimados pelo modelo mais plausível (modelo logito)

Futuras avaliações:

i) pesquisar a função
ii) no y ("taxa de GOF") está a inclinação na escala logito? 
iii) em x está a mediana de cada coef?

- avaliação dos efeitos aleatórios

"The result is a dataframe with estimates of the values of each of the random effects provided by the arm::sim() function. groupID represents the identfiable level for the variable for one random effect, term represents whether the simulated values are for an intercept or which slope, and groupFctr identifies which of the (1|x) terms the values represent"
"To make unique identifiers for each term, we need to use both the groupID and the groupFctr term in case these two variables use overlapping label names for their groups."


```{r md_GOF simulate values random effects}
# simulacao
re_GOF <- REsim(md_GOF,n.sims = 1000)
# re_GOF

# grafico
plotREsim(re_GOF,stat = "mean")
```


__Predição e Observado na escala logito__

```{r GOF predicao IC e observado na escala logito}
## novo conjunto de dados: todas as combinações entre as preditoras ##
df_new.data <- expand.grid(Site = df_resultados$Site[1],
                           p.z = seq(min(df_resultados$p.z)*1.1,max(df_resultados$p.z)*1.1, length=length(unique(df_ad$p))),
                           k = unique(df_resultados$k),
                           MN = unique(df_resultados$MN))
## predicao merTools ##
df_new.data <- cbind(df_new.data,
                     predictInterval(md_GOF,newdata = df_new.data,level=0.95,n.sims = 1000,stat = "mean"))
# add de p na escala padrão #
df_new.data$p <- df_new.data$p.z*sd(df_ad$p) + mean(df_ad$p)
# transformando a predicao para escala da observacao #
# df_new.data %<>% mutate(media = ( 1 / ( 1+exp(-fit) )), upr_media =  (1/(1+exp(-upr))), lwr_media =  (1/(1+exp(-lwr))))

## remoção de 0 e 100 ##
df_ad <- df_resultados
df_ad$GOF[df_ad$GOF==0] <- 100/(1+exp(-min(df_new.data$lwr)))
df_ad$GOF[df_ad$GOF==100] <- 100/(1+exp(-max(df_new.data$upr)))
## transformação logito ##
df_ad %<>% mutate(lGOF = log( (GOF/100) / ( 1 - (GOF/100) ) ))


## Gráfico ##
ggplot(data=df_new.data,aes(x=p,y=lGOF,color=MN)) + 
  geom_point(data=df_ad,aes(color=MN)) +
  geom_ribbon(aes(y = fit, ymin=lwr, ymax=upr,color=MN,fill=MN), alpha=0.5) +
  geom_line(aes(x=p, y=fit,color=MN)) +
  facet_wrap(~k,ncol=3) +
  scale_colour_manual(values = c("Blue", "Red")) + 
  scale_fill_manual(values = c("Blue", "Red")) +
  theme(legend.position = "bottom")
```

__Figura 14__ Logito de GOF (lGOF) e propoção de cobertura vegetal (p), por proporção de propágulos que permanece até a planta (k, o título dos quadros) e colorido pela classe de modelo neutro (MN: EI - modelo neutro de espaço implícito; EE - modelo neutro de espaço explícito). A linha central representa a média estimado e a área colorida representa o intervalo de confiança de 95%. 

-> Reunião 25 outubro 2018

- o gráfico de observado e predito com intervalo de confiança mostra que a estimativa do modelo não está sendo suficiente para 

```{r md_GOF estruturas aleatorias alternativas}
l_md <- vector("list",21)
names(l_md) <- c("l k.f 1|Site","l k.f MN|Site", "l k.z 1|Site", "l k.z MN|Site", "l k.z k.z|Site", "l k.z MN + k.z|Site", "l k.z MN * k.z|Site",
                 "p k.f 1|Site","p k.f MN|Site", "p k.z 1|Site", "p k.z MN|Site", "p k.z k.z|Site", "p k.z MN + k.z|Site", "p k.z MN * k.z|Site",
                 "c k.f 1|Site","c k.f MN|Site", "c k.z 1|Site", "c k.z MN|Site", "c k.z k.z|Site", "c k.z MN + k.z|Site", "c k.z MN * k.z|Site")
# logito #
l_md[[1]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (1|Site), family = "binomial",data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[2]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (MN|Site), family = "binomial",data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[3]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k.z * MN + (1|Site), family = "binomial",data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[4]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k.z * MN + (MN|Site), family = "binomial",data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[5]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k.z * MN + (k.z|Site), family = "binomial",data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[6]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k.z * MN + (MN+k.z|Site), family = "binomial",data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[7]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k.z * MN + (MN*k.z|Site), family = "binomial",data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
# probito #
l_md[[8]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (1|Site), family = "binomial"(link = probit),data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[9]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (MN|Site), family = "binomial"(link = probit),data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[10]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k.z * MN + (1|Site), family = "binomial"(link = probit),data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[11]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k.z * MN + (MN|Site), family = "binomial"(link = probit),data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[12]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k.z * MN + (k.z|Site), family = "binomial"(link = probit),data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[13]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k.z * MN + (MN+k.z|Site), family = "binomial"(link = probit),data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[14]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k.z * MN + (MN*k.z|Site), family = "binomial"(link = probit),data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
# # cloglog #
l_md[[15]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (1|Site), family = "binomial"(link = cloglog),data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[16]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k * MN + (MN|Site), family = "binomial"(link = cloglog),data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[17]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k.z * MN + (1|Site), family = "binomial"(link = cloglog),data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[18]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k.z * MN + (MN|Site), family = "binomial"(link = cloglog),data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[19]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k.z * MN + (k.z|Site), family = "binomial"(link = cloglog),data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[20]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k.z * MN + (MN+k.z|Site), family = "binomial"(link = cloglog),data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
l_md[[21]] <- glmer(cbind(GOF,100-GOF) ~ p.z * k.z * MN + (MN*k.z|Site), family = "binomial"(link = cloglog),data=df_resultados,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))
AICctab(l_md,weights=T)
```

- o único modelo plausível é aquele que considera k como um fator, MN|Site como estrutura aleatória e cloglog como função de ligação. Abaixo deste há a mesma estrutura mas com as funções de ligação probito e logito, respectivamente, contudo, fora do intervalo de plausibilidade. O quarto modelo mais plausível é aquele que considera k como variável contínua e a estrutura aleatória MN * k.z|Site. 

- como o objetivo é avaliar se algumas dessas opções apresenta uma melhora significativa no padrão de resíduos e capacidade de explicar a variação presente nos dados vou comparar esses 4 primeiros modelos, mesmo apenas o primeiro sendo plausível, utilizando os resíduos quantílicos e o R2

__cloglog k como categórica e MN|Site__

```{r cloglog k MN|Site diag}
residuos_cloglog <- simulateResiduals(fittedModel = l_md[[16]], n = 1000)
plot(residuos_cloglog)
```

__Figura 15.1__ Resíduos quantílicos GOF ~ modelo cheio[cloglog, k.f, MN|Site]

```{r R2 cloglog k.f MN|Site}
r.squaredGLMM(l_md[[16]])
```


__probit k como categórica e MN|Site__

```{r probit k MN|Site diag}
residuos_probit <- simulateResiduals(fittedModel = l_md[[9]], n = 1000)
plot(residuos_probit)
```

__Figura 15.2__ Resíduos quantílicos GOF ~ modelo cheio[cloglog, k.f, MN|Site]

```{r R2 probit k.f MN|Site}
r.squaredGLMM(l_md[[9]])
```


__logit k como categórica e MN|Site__

```{r cloglog k MN|Site diag}
residuos_logit <- simulateResiduals(fittedModel = l_md[[2]], n = 1000)
plot(residuos_logit)
```

__Figura 15.1__ Resíduos quantílicos GOF ~ modelo cheio[cloglog, k.f, MN|Site]

```{r R2 logit k.f MN|Site}
r.squaredGLMM(l_md[[2]])
```


__logit k como categórica e MN|Site__

```{r logit k.z MN*k.z|Site diag}
residuos_logit.k <- simulateResiduals(fittedModel = l_md[[7]], n = 1000)
plot(residuos_logit.k)
```

```{r R2 logit k.z MN*k.z|Site}
r.squaredGLMM(l_md[[7]])
```

A distribuição dos resíduos quantílicos de todos os modelos apresenta desvio significativo da uniformidade. O modelo com MN*k.z|Site e função de ligação logito apresenta uma pequena melhora na aderência dos resíduos à uniformidade, contudo, há uma piora considerável na variância explicada pela estrutura fixa do modelo em comparação com o modelo logito com k enquanto variável categórica e MN|Site. Além disso a regressão quantílica para o modelo logito MN:k.z|Site diverge mais do esperado do que o outro modelo logito MN|Site.

Os modelos com função de ligação logito são aqueles que melhor descrevem a variação dos dados (maior R2c), apesar do modelo cloglog ser o mais plausível. Como o intervalo de confiança da predição é uma qualidade importante do modelo que utilizaremos para analisar os dados vou comparar o modelo mais plausível (cloglog) com o melhor modelo logito, o modelo logito é de interesse por conta da sua facilidade de interpretação. Como a construção de intervalo de confiança utilizando bootMer é muito longo, irei utilizar o pacote merTools para uma primeira comparação entre os dois; entretanto, pelo R2 podemos esperar que a predição do modelo logito englobe a maior parte da variação dos dados.

__Comparação intervalo de predição: cloglog e logit__

```{r comparacao cloglog logit predito IC,fig.height=10}
## novo conjunto de dados: todas as combinações entre as preditoras ##
df_new.data <- expand.grid(Site = df_resultados$Site[1],
                           p.z = seq(min(df_resultados$p.z)*1.1,max(df_resultados$p.z)*1.1, length=length(unique(df_resultados$p))),
                           k = unique(df_resultados$k),
                           MN = unique(df_resultados$MN))

### Logit ###
## predicao merTools ##
df_nd.logit <- cbind(df_new.data,
                     predictInterval(l_md[[2]],newdata = df_new.data,level=0.95,n.sims = 1000,stat = "mean"))
# add de p na escala padrão #
df_nd.logit$p <- df_new.data$p.z*sd(df_resultados$p) + mean(df_resultados$p)

## remoção de 0 e 100 ##
df_logit <- df_resultados
df_logit$GOF[df_logit$GOF==0] <- 100/(1+exp(-min(df_nd.logit$lwr)))
df_logit$GOF[df_logit$GOF==100] <- 100/(1+exp(-max(df_nd.logit$upr)))
## transformação logito ##
df_logit %<>% mutate(lGOF = log( (GOF/100) / ( 1 - (GOF/100) ) ))

## Gráfico ##
l_p <- vector("list",2)
l_p[[1]] <- ggplot(data=df_nd.logit,aes(x=p,y=lGOF)) + 
  geom_point(data=df_logit) +
  geom_ribbon(aes(y = fit, ymin=lwr, ymax=upr), alpha=0.5) +
  geom_line(aes(x=p, y=fit)) +
  labs(title="logit") +
  facet_grid(k~MN)

### clogclog ###
## predicao merTools ##
df_nd.cloglog <- cbind(df_new.data,
                       predictInterval(l_md[[16]],newdata = df_new.data,level=0.95,n.sims = 1000,stat = "mean"))
# add de p na escala padrão #
df_nd.cloglog$p <- df_new.data$p.z*sd(df_resultados$p) + mean(df_resultados$p)

## remoção de 0 e 100 ##
df_cloglog <- df_resultados
df_cloglog$GOF[df_cloglog$GOF==0] <- 1-exp(-exp(min(df_nd.cloglog$lwr)))
df_cloglog$GOF[df_cloglog$GOF==100] <- 1-exp(-exp(max(df_nd.cloglog$upr)))
## transformação logito ##
df_cloglog %<>% mutate(cGOF = log(-log(100-GOF)))

## Gráfico ##
l_p[[2]] <- ggplot(data=df_nd.cloglog,aes(x=p,y=cGOF)) + 
  geom_point(data=df_cloglog) +
  geom_ribbon(aes(y = fit, ymin=lwr, ymax=upr), alpha=0.5) +
  geom_line(aes(x=p, y=fit)) +
  labs(title="cloglog") +
  facet_grid(k~MN)

### comparacao ###
do.call("grid.arrange",c(l_p,ncol=2))
```

- problemas em plotar na escala cloglog
- vou deixar rodando o bootMer

```{r IC bootMer logit GOF,fig.height=10,fig.width=5}
md_GOF <- l_md[[2]]
## novo conjunto de dados: todas as combinações entre as preditoras ##
df_new.data <- expand.grid(Site = df_resultados$Site[1],
                           p.z = seq(min(df_resultados$p.z)*1.1,max(df_resultados$p.z)*1.1, length=length(unique(df_resultados$p))),
                           k = unique(df_resultados$k),
                           MN = unique(df_resultados$MN))
# previsto considerando a estrutura fixa e aleatória #
f1 <- function(.) predict(.,newdata=df_new.data)
# previsto considerando a estrutura fixa #
f2 <- function(.) predict(.,newdata=df_new.data, re.form=~0)
## Os dois bootstraps. Ajuste o argumento ncpus para o numero de cores de seu computador
# b1 <- bootMer(md_GOF, FUN = f1, nsim=1000, parallel="multicore", ncpus=4)
# b2 <- bootMer(md_GOF, FUN = f2, nsim=1000, parallel="multicore", ncpus=4)
# save(b1,b2,file="/home/danilo/Documentos/Doutorado/artigo_mestrado/Rmd_e_dados/bootMer_md-logit-GOF.Rdata")
load(file = "/home/danilo/Documentos/Doutorado/artigo_mestrado/Rmd_e_dados/bootMer_md-logit-GOF.Rdata")
# preparacao dos dados
df_new.data$p <- df_new.data$p.z*sd(df_resultados$p) + mean(df_resultados$p) 
df_new.data$mean <- apply(b1$t,2,mean)
df_new.data$IC.low <- apply(b1$t,2,quantile, 0.025)
df_new.data$IC.upp <- apply(b1$t,2,quantile, 0.975)
df_new.data$mean.fixed <- apply(b2$t,2,mean)
df_new.data$IC.low.fixed <- apply(b2$t,2,quantile, 0.025)
df_new.data$IC.upp.fixed <- apply(b2$t,2,quantile, 0.975)
## Modificação dos dados
df_ad <- df_resultados
df_ad$GOF[df_ad$GOF==0] <- 100/(1+exp(-min(df_new.data$IC.low)))
df_ad$GOF[df_ad$GOF==100] <- 100/(1+exp(-max(df_new.data$IC.upp)))
## transformação logito ##
df_ad %<>% mutate(lGOF = log( (GOF/100) / ( 1 - (GOF/100) ) ))

df_ad %>%
    ggplot(aes(x=p,y=lGOF) ) + 
    geom_ribbon(aes(y=mean, ymin=IC.low, ymax=IC.upp), data=df_new.data, col="gray", alpha=0.5) +
    geom_ribbon(aes(y=mean, ymin=IC.low.fixed, ymax=IC.upp.fixed), data=df_new.data, col="gray", alpha=0.5) +
    geom_line(aes(x=p, y=mean.fixed), data=df_new.data) +
    geom_point() +
    facet_grid(k~MN)
```

__Figura 16__ observado e predito na escala da função de ligação 

```{r md_GOF predito e observado,fig.width=10}
# coisas a fazer: otimizar o copia e cola aqui #

# novos dados 
df_new.data <- expand.grid(Site = df_resultados$Site[1],
                           p.z = seq(min(df_resultados$p.z)*1.1,max(df_resultados$p.z)*1.1, length=length(unique(df_resultados$p))),
                           k = unique(df_resultados$k),
                           MN = unique(df_resultados$MN))
# bootMer
load(file = "/home/danilo/Documentos/Doutorado/artigo_mestrado/Rmd_e_dados/bootMer_md-logit-GOF.Rdata")
df_new.data1 <- df_new.data
df_new.data1$p <- df_new.data1$p.z*sd(df_resultados$p) + mean(df_resultados$p) 
# logit
# df_new.data1$mean <- apply(b1$t,2,mean)
# df_new.data1$IC.low <- apply(b1$t,2,quantile, 0.025)
# df_new.data1$IC.upp <- apply(b1$t,2,quantile, 0.975)
# df_new.data1$mean.fixed <- apply(b2$t,2,mean)
# df_new.data1$IC.low.fixed <- apply(b2$t,2,quantile, 0.025)
# df_new.data1$IC.upp.fixed <- apply(b2$t,2,quantile, 0.975)
#inv logit
df_new.data1$mean.invlogit <- invlogit(apply(b1$t,2,mean)) * 100
df_new.data1$IC.low.invlogit <- invlogit(apply(b1$t,2,quantile, 0.025)) * 100
df_new.data1$IC.upp.invlogit <- invlogit(apply(b1$t,2,quantile, 0.975)) * 100
df_new.data1$mean.fixed.invlogit <- invlogit(apply(b2$t,2,mean)) * 100
df_new.data1$IC.low.fixed.invlogit <- invlogit(apply(b2$t,2,quantile, 0.025)) * 100
df_new.data1$IC.upp.fixed.invlogit <- invlogit(apply(b2$t,2,quantile, 0.975)) * 100
## Modificação dos dados
# df_ad <- df_resultados
# df_ad$GOF[df_ad$GOF==0] <- 100/(1+exp(-min(df_new.data1$IC.low)))
# df_ad$GOF[df_ad$GOF==100] <- 100/(1+exp(-max(df_new.data1$IC.upp)))
# ## transformação logito ##
# df_ad %<>% mutate(lGOF = log( (GOF/100) / ( 1 - (GOF/100) ) ))
# grafico #
l_p <- vector("list",2)
l_p[[1]] <- ggplot(filter(df_resultados,k %in% levels(df_ad$k)[1:6]),aes(x=p,y=GOF) ) + 
    geom_ribbon(aes(y=mean.invlogit, ymin=IC.low.invlogit, ymax=IC.upp.invlogit), 
                data=filter(df_new.data1,k %in% levels(df_ad$k)[1:6]), 
                fill="grey15", alpha=0.5) +
    geom_ribbon(aes(y=mean.invlogit, ymin=IC.low.fixed.invlogit, ymax=IC.upp.fixed.invlogit), 
                data=filter(df_new.data1,k %in% levels(df_ad$k)[1:6]), 
                fill="white", alpha=0.5) +
    geom_line(aes(x=p, y=mean.fixed.invlogit), data=filter(df_new.data1,k %in% levels(df_ad$k)[1:6]),color="red") +
    geom_point() +
    labs(y="Número de predições não refutadas",x="% cobertura vegetal") +
    facet_grid(k~MN)
l_p[[2]] <- ggplot(filter(df_resultados,k %in% levels(df_ad$k)[7:12]),aes(x=p,y=GOF) ) + 
    geom_ribbon(aes(y=mean.invlogit, ymin=IC.low.invlogit, ymax=IC.upp.invlogit), 
                data=filter(df_new.data1,k %in% levels(df_ad$k)[7:12]), 
                fill="grey15", alpha=0.5) +
    geom_ribbon(aes(y=mean.invlogit, ymin=IC.low.fixed.invlogit, ymax=IC.upp.fixed.invlogit), 
                data=filter(df_new.data1,k %in% levels(df_ad$k)[7:12]), 
                fill="white", alpha=0.5) +
    geom_line(aes(x=p, y=mean.fixed.invlogit), data=filter(df_new.data1,k %in% levels(df_ad$k)[7:12]),color="red") +
    geom_point() +
    labs(y="",x="% cobertura vegetal") +
    theme(axis.text.y = element_blank(),axis.ticks = element_blank()) +
    facet_grid(k~MN)
do.call("grid.arrange",c(l_p,ncol=2))
```

__Figura 17__ Número de predições não refutadas a partir da SAD observada e teste de Kolmogorov-Smirnov em função da % de cobertura vegetal. Os quadros estão dividos pelo modelo neutro que gerou as predições (colunas EI e EE) e pela proporção de propágulos que permanece até a vizinhança imediata da planta progenitora (linhas 0.99,...,0.25). A linha vermelha é a probabilidade de não refutar uma predição neutra, a região em branco ao redor da linha vermelha é o intervalo de confiança de 95% marginal ao agrupamento dos dados pelo sítio de amostragem, a região em cinza é o intervalo de confiança de 95% condicional ao agrupamento dos dados pelo sítio de amostragem. 


#### Efeitos fixos

Existem pelo menos 3 maneiras de avaliar a estimativa dos parâmetros do modelo estatístico: a) dividir os dados pelas variáveis categóricas k e MN e então ajustar um glm com distribuição binomial e função de ligação logito e, se os resíduos forem similares, utilizar as estimativas dos glms como aproximações dos parâmetros utilizados; b) utilizar a amostragem a posteori disponível em merTools; c) encontrar uma maneira de estimar a partir do bootMer, que possibilita associar a estimativa com a incerteza marginal e condicional aos efeitos aleatórios.

Vou começar avaliando a opção c por ser mais completa, caso não seja possível sigo para a opção a e então a opção b.

##### bootMer 

```{r coef e intervalo de confianca bootmer parte 1 }
# funcao para aplicar e extrair coef de um lm para cada réplica
f_coef.bootMer <- function(df_=df_new.data,X){
  lm.data <- cbind(X,df_new.data)
  names(lm.data)[1] <- "replica"
  lm.object <- coef(lm(replica ~ p.z*k*MN,data = lm.data))
  return(lm.object)
}

# replicas dos coeficientes armazenados em um df
# teste <- f_coef.bootMer1(X=b1$t[1,])
# str(df_new.data)
registerDoMC(3)
df_lm.coef1 <- adply(b1$t,1,function(a) f_coef.bootMer(X=a),.parallel = TRUE) %>% select(-X1)
# summary(df_lm.coef1)
df_lm.coef2 <- adply(b2$t,1,function(a) f_coef.bootMer(X=a),.parallel = TRUE) %>% select(-X1)

# coeficientes -> parâmetros da regressão
## para os resultados marginais
l_ef1 <- vector("list",12)
l_ef1[[1]] <- data.frame(k = factor(levels(df_resultados$k)[1], levels = levels(df_resultados$k)), 
                         MN = rep(rep(levels(df_resultados$MN),2),each=1000), 
                         termo = rep(rep(c("alfa","beta"),each=2),each=1000),
                         replica = c(df_lm.coef1[,1] , #alfa EI
                                     df_lm.coef1[,1] + df_lm.coef1[,14], # alfa EE
                                     df_lm.coef1[,2], #beta EI
                                     df_lm.coef1[,2] + df_lm.coef1[,26])) #beta EE
# l_ef[[1]] %>% ddply(.,c("k","MN","termo"), summarise, mean(replica))
# md_GOF
for(i in 2:12){
l_ef1[[i]] <- data.frame(k = factor(levels(df_resultados$k)[i], levels = levels(df_resultados$k)), 
                         MN = rep(rep(levels(df_resultados$MN),2),each=1000), 
                         termo = rep(rep(c("alfa","beta"),each=2),each=1000),
                         replica = c(df_lm.coef1[,1] + df_lm.coef1[,1+i] , #alfa EI
                                     df_lm.coef1[,1] + df_lm.coef1[,1+i] + df_lm.coef1[,14] + df_lm.coef1[,25+i], # alfa EE
                                     df_lm.coef1[,2] + df_lm.coef1[,13+i], #beta EI
                                     df_lm.coef1[,2] + df_lm.coef1[,13+i] + df_lm.coef1[,26] + df_lm.coef1[,36+i])) #beta EE
}
df_ef1 <- rbind.fill(l_ef1) %>% ddply(.,c("k","MN","termo"),summarise, 
                                    media = mean(replica), mediana = median(replica), 
                                    upr = quantile(replica, 0.975), lwr = quantile(replica, 0.025)) 
# visualizacao
l_p <- vector("list",2)
l_p[[1]] <- ggplot(df_ef1,aes(x=k,y=media,ymin=lwr,ymax=upr,colour=MN)) +
  # ggplot(aes(x=k,y=estimate,ymin=value.2.5..,ymax=value.97.5..,colour=MN)) +
  # ggplot(aes(x=k,y=media,ymin=lwr,ymax=upr,color=MN)) +
  geom_hline(yintercept = 0,colour="green") +
  geom_pointrange() + 
  scale_colour_manual(values = c("Blue", "Red")) +
  facet_wrap(~termo,ncol=1,scales="free")


## para os resultados condicionais
l_ef2 <- vector("list",12)
l_ef2[[1]] <- data.frame(k = factor(levels(df_resultados$k)[1], levels = levels(df_resultados$k)), 
                         MN = rep(rep(levels(df_resultados$MN),2),each=1000), 
                         termo = rep(rep(c("alfa","beta"),each=2),each=1000),
                         replica = c(df_lm.coef2[,1] , #alfa EI
                                     df_lm.coef2[,1] + df_lm.coef2[,14], # alfa EE
                                     df_lm.coef2[,2], #beta EI
                                     df_lm.coef2[,2] + df_lm.coef2[,26])) #beta EE
# l_ef[[1]] %>% ddply(.,c("k","MN","termo"), summarise, mean(replica))
# md_GOF
for(i in 2:12){
l_ef2[[i]] <- data.frame(k = factor(levels(df_resultados$k)[i], levels = levels(df_resultados$k)), 
                         MN = rep(rep(levels(df_resultados$MN),2),each=1000), 
                         termo = rep(rep(c("alfa","beta"),each=2),each=1000),
                         replica = c(df_lm.coef2[,1] + df_lm.coef2[,1+i] , #alfa EI
                                     df_lm.coef2[,1] + df_lm.coef2[,1+i] + df_lm.coef2[,14] + df_lm.coef2[,25+i], # alfa EE
                                     df_lm.coef2[,2] + df_lm.coef2[,13+i], #beta EI
                                     df_lm.coef2[,2] + df_lm.coef2[,13+i] + df_lm.coef2[,26] + df_lm.coef2[,36+i])) #beta EE
}
df_ef2 <- rbind.fill(l_ef2) %>% ddply(.,c("k","MN","termo"),summarise, 
                                    media = mean(replica), mediana = median(replica), 
                                    upr = quantile(replica, 0.975), lwr = quantile(replica, 0.025)) 
# visualizacao
l_p[[2]] <- ggplot(df_ef2,aes(x=k,y=media,ymin=lwr,ymax=upr,colour=MN)) +
  # ggplot(aes(x=k,y=estimate,ymin=value.2.5..,ymax=value.97.5..,colour=MN)) +
  # ggplot(aes(x=k,y=media,ymin=lwr,ymax=upr,color=MN)) +
  geom_hline(yintercept = 0,colour="green") +
  geom_pointrange() + 
  scale_colour_manual(values = c("Blue", "Red")) +
  facet_wrap(~termo,ncol=1,scales="free")
do.call("grid.arrange",c(l_p,ncol=2))
```



- uma vez que o modelo plausível é de terceira ordem eu posso ajustar um glm logito glm(cbind(GOF,100-GOF) ~ p.z,family=binomial) para cada subpopulação dos dados (group_by=(MN,k)):

```{r glm by MN e k}
# modelo binomial para aplicar em cada group_by(MN,k)
fun_map <- function(df){
  glm(cbind(GOF,100-GOF) ~ p.z, family = binomial, data = df)
}

# glm(cbind(GOF,100-GOF) ~ p.z, family = binomial, data = df_resultados) %>% confint() %>% as.data.frame()

# aplicando a função do modelo binomial para cada group_by(MN,k)
df_coef.ef <- df_resultados %>% 
  group_by(MN,k) %>% nest() %>%
  mutate(md = map(data, fun_map),
         coef = map(md,tidy), # GLM binomial aplicado para cada sítio;
         IC = map(md,as.data.frame(confint)) #profile likelihood ratio CI
         ) 

# df único 
df_coef.ef %<>% select(MN,k,coef,IC) %>% 
  unnest() %>% as.data.frame() %>% 
  select(MN,k,term,estimate, value.2.5.., value.97.5..) # retornando ao formato data frame 

# transformando para a escala padrão
f_inv.logit <- function(x) 1/(1+exp(-x))
df_coef.ef %<>% mutate(media.pr = f_inv.logit(estimate),
                       lwr.pr = f_inv.logit(value.2.5..),
                       upr.pr = f_inv.logit(value.97.5..))

# calculo da deriva 
f_deriv.p <- function(X){
  alfa <- X[1,3]
  beta <- X[2,3]
}

df_coef.ef %>% select(MN,k,term,estimate,value.2.5..) %>% dcast(MN+k~term,value.var="estimate")
# ,value.2.5..,value.97.5..; ,value.var = c("estimate","value.2.5..","value.97.5..")
# gráfico das estimativas para cada subpopulação
# df_coef.ef %>% summary
df_coef.ef %>% 
  ggplot(aes(x=k,y=media.pr,ymin=lwr.pr,ymax=upr.pr,colour=MN)) +
  # ggplot(aes(x=k,y=estimate,ymin=value.2.5..,ymax=value.97.5..,colour=MN)) +
  # ggplot(aes(x=k,y=media,ymin=lwr,ymax=upr,color=MN)) +
  geom_hline(yintercept = 0,colour="green") +
  geom_pointrange() + 
  scale_colour_manual(values = c("Blue", "Red")) +
  facet_wrap(~term,ncol=1,scales="free")
```

__Figura 16.2__  Estimativas lineares da probabilidade média da


```{r efeitos fixos md_GOF}
ef_GOF <- arm::sim(md_GOF,1000)
# ef_GOF %>% str

## Avaliação visual da distribuição dos parâmetros ##
# ef_GOF@fixef %>% str
l_ef <- vector("list",12)
l_ef[[1]] <- data.frame(k = factor(levels(df_resultados$k)[1], levels = levels(df_resultados$k)), 
                        MN = rep(rep(levels(df_resultados$MN),2),each=1000), 
                        termo = rep(rep(c("alfa","beta"),each=2),each=1000),
                        replica = c(ef_GOF@fixef[,1] , #alfa EI
                                    ef_GOF@fixef[,1] + ef_GOF@fixef[,14], # alfa EE
                                    ef_GOF@fixef[,2], #beta EI
                                    ef_GOF@fixef[,2] + ef_GOF@fixef[,26])) #beta EE
# l_ef[[1]] %>% ddply(.,c("k","MN","termo"), summarise, mean(replica))
# md_GOF
for(i in 2:12){
l_ef[[i]] <- data.frame(k = factor(levels(df_resultados$k)[i], levels = levels(df_resultados$k)), 
                        MN = rep(rep(levels(df_resultados$MN),2),each=1000), 
                        termo = rep(rep(c("alfa","beta"),each=2),each=1000),
                        replica = c(ef_GOF@fixef[,1] + ef_GOF@fixef[,1+i] , #alfa EI
                                    ef_GOF@fixef[,1] + ef_GOF@fixef[,1+i] + ef_GOF@fixef[,14] + ef_GOF@fixef[,25+i], # alfa EE
                                    ef_GOF@fixef[,2] + ef_GOF@fixef[,13+i], #beta EI
                                    ef_GOF@fixef[,2] + ef_GOF@fixef[,13+i] + ef_GOF@fixef[,26] + ef_GOF@fixef[,36+i])) #beta EE
}
df_ef <- rbind.fill(l_ef) %>% ddply(.,c("k","MN","termo"),summarise, 
                                    media = mean(replica), mediana = median(replica), 
                                    upr = quantile(replica, 0.975), lwr = quantile(replica, 0.025)) 
f_inv.logit <- function(x) 1/(1+exp(-x))
df_ef %>% mutate(media.pr = f_inv.logit(media), mediana.pr = f_inv.logit(mediana), upr.pr = f_inv.logit(upr), lwr.pr = f_inv.logit(lwr)) %>% 
  ggplot(aes(x=termo,y=media.pr,ymin=lwr.pr,ymax=upr.pr,color=MN)) +
  # ggplot(aes(x=termo,y=media,ymin=lwr,ymax=upr,color=MN)) + 
  geom_pointrange() + 
  scale_colour_manual(values = c("Blue", "Red")) +
  facet_wrap(~k,ncol=3,scales="free")

# ggplot(data=rbind.fill(l_ef),aes(x=termo,y=replica,color=MN)) +
#   geom_boxplot() + 
#   scale_colour_manual(values = c("Blue", "Red")) +
#   facet_wrap(~k,ncol=3)
```


